1
00:00:23,390 --> 00:00:26,430
So what I want to do today is talk about

2
00:00:26,630 --> 00:00:28,620
a different type of learning algorithm,

3
00:00:28,790 --> 00:00:29,820
and, in particular,

4
00:00:29,970 --> 00:00:31,500
start to talk about generative learning

5
00:00:31,670 --> 00:00:33,740
algorithms and the specific algorithm

6
00:00:33,910 --> 00:00:35,590
called Gaussian Discriminant Analysis.

7
00:00:35,790 --> 00:00:39,320
Take a slight digression, talk about Gaussians,

8
00:00:39,490 --> 00:00:43,360
and I'll briefly discuss generative

9
00:00:43,530 --> 00:00:45,030
versus discriminative learning algorithms,

10
00:00:45,190 --> 00:00:47,340
and then hopefully wrap up today's lecture

11
00:00:47,510 --> 00:00:50,260
with a discussion of Naive Bayes and the Laplace

12
00:00:50,430 --> 00:00:51,190
Smoothing.

13
00:00:52,450 --> 00:00:55,190
So just to motivate our discussion

14
00:00:55,380 --> 00:00:56,810
on generative learning algorithms,

15
00:00:56,980 --> 00:00:58,400
right, so by way of contrast,

16
00:00:58,590 --> 00:01:00,330
the source of classification algorithms

17
00:01:00,470 --> 00:01:01,520
we've been talking about

18
00:01:01,710 --> 00:01:03,820
I think of algorithms that do this.

19
00:01:04,020 --> 00:01:05,570
So you're given a training set,

20
00:01:05,750 --> 00:01:12,890
and if you run an algorithm right,

21
00:01:13,000 --> 00:01:14,390
like logistic regression on those training sets.

22
00:01:14,550 --> 00:01:17,510
The way I think of logistic regression is that

23
00:01:17,670 --> 00:01:19,680
it's trying to find look at the data

24
00:01:19,810 --> 00:01:21,310
and is trying to find a straight line

25
00:01:21,440 --> 00:01:23,910
to divide the crosses and O's, right?

26
00:01:24,030 --> 00:01:25,460
So it's, sort of, trying to find a straight line.

27
00:01:25,620 --> 00:01:28,910
Let me just make the days a bit noisier.

28
00:01:29,040 --> 00:01:30,480
Trying to find a straight line

29
00:01:30,610 --> 00:01:35,270
that separates out the positive and

30
00:01:35,400 --> 00:01:38,500
the negative classes as well as possible, right?

31
00:01:38,620 --> 00:01:40,510
And, in fact, it shows it on the laptop.

32
00:01:40,630 --> 00:01:41,670
Maybe just use the screens

33
00:01:41,790 --> 00:01:43,310
or the small monitors for this.

34
00:01:43,410 --> 00:01:47,750
In fact, you can see

35
00:01:47,890 --> 00:01:51,870
there's the data set with logistic regression,

36
00:01:52,010 --> 00:01:55,870
and so I've initialized the parameters randomly,

37
00:01:55,990 --> 00:01:56,990
and so logistic regression is,

38
00:01:57,120 --> 00:01:58,950
kind of, the outputting

39
00:01:59,100 --> 00:02:02,550
it's the, kind of, hypothesis that iteration zero is that

40
00:02:02,680 --> 00:02:04,070
straight line shown in the bottom right.

41
00:02:04,210 --> 00:02:06,940
And so after one iteration under gradient ascent,

42
00:02:07,070 --> 00:02:08,370
the straight line changes a bit.

43
00:02:08,510 --> 00:02:11,400
After two iterations, three, four,

44
00:02:11,550 --> 00:02:14,350
until logistic regression converges

45
00:02:14,480 --> 00:02:16,700
and has found the straight line that,

46
00:02:16,810 --> 00:02:17,530
more or less,

47
00:02:17,700 --> 00:02:18,870
separates the positive and negative class,

48
00:02:19,040 --> 00:02:20,410
okay? So you can think of this

49
00:02:20,530 --> 00:02:22,070
as logistic regression, sort of,

50
00:02:22,190 --> 00:02:23,960
searching for a line that separates the positive

51
00:02:24,080 --> 00:02:25,100
and the negative classes.

52
00:02:25,270 --> 00:02:29,910
What I want to do today is talk about an algorithm

53
00:02:30,030 --> 00:02:31,490
that does something slightly different,

54
00:02:31,650 --> 00:02:33,570
and to motivate us,

55
00:02:33,710 --> 00:02:35,690
let's use our old example of trying to

56
00:02:35,830 --> 00:02:37,470
classify the team malignant cancer

57
00:02:37,630 --> 00:02:39,560
and benign cancer, right?

58
00:02:39,640 --> 00:02:41,730
So a patient comes in and they have a cancer,

59
00:02:41,840 --> 00:02:42,980
you want to know if it's a malignant

60
00:02:43,180 --> 00:02:44,370
or a harmful cancer,

61
00:02:44,520 --> 00:02:46,650
or if it's a benign, meaning a harmless cancer.

62
00:02:46,780 --> 00:02:50,100
So rather than trying to find the straight line

63
00:02:50,220 --> 00:02:51,250
to separate the two classes,

64
00:02:51,400 --> 00:02:52,480
here's something else we could do.

65
00:02:52,660 --> 00:02:54,880
We can go from our training set

66
00:02:55,020 --> 00:02:58,670
and look at all the cases of malignant cancers,

67
00:02:58,790 --> 00:03:00,160
go through, you know,

68
00:03:00,300 --> 00:03:01,420
look for our training set for

69
00:03:01,530 --> 00:03:03,610
all the positive examples of malignant cancers,

70
00:03:03,770 --> 00:03:05,180
and we can then build a model

71
00:03:05,300 --> 00:03:07,230
for what malignant cancer looks like.

72
00:03:07,370 --> 00:03:10,300
Then we'll go for our training set again

73
00:03:10,400 --> 00:03:12,810
and take out all of the examples of benign cancers,

74
00:03:12,930 --> 00:03:14,200
and then we'll build a model

75
00:03:14,330 --> 00:03:17,130
for what benign cancers look like, okay?

76
00:03:17,270 --> 00:03:21,280
And then when you need to classify a new example,

77
00:03:21,420 --> 00:03:22,330
when you have a new patient,

78
00:03:22,460 --> 00:03:23,280
and you want to decide is

79
00:03:23,430 --> 00:03:25,120
this cancer malignant or benign,

80
00:03:25,250 --> 00:03:26,830
you then take your new cancer,

81
00:03:26,950 --> 00:03:30,380
and you match it to your model of malignant cancers,

82
00:03:30,520 --> 00:03:32,780
and you match it to your model of benign cancers,

83
00:03:32,900 --> 00:03:35,210
and you see which model it matches better,

84
00:03:35,330 --> 00:03:36,630
and depending on which

85
00:03:36,740 --> 00:03:38,020
model it matches better to,

86
00:03:38,120 --> 00:03:41,100
you then predict whether the new cancer is

87
00:03:41,210 --> 00:03:42,410
malignant or benign, okay?

88
00:03:42,540 --> 00:03:47,870
So what I just described,

89
00:03:47,980 --> 00:03:50,300
just this class of methods

90
00:03:50,420 --> 00:03:51,830
where you build a separate model for

91
00:03:51,940 --> 00:03:53,040
malignant cancers

92
00:03:53,160 --> 00:03:54,710
and a separate model for benign cancers

93
00:03:54,850 --> 00:03:57,230
is called a generative learning algorithm,

94
00:03:57,370 --> 00:04:00,220
and let me just, kind of, formalize this.

95
00:04:00,340 --> 00:04:05,740
So in the models that we've been

96
00:04:05,870 --> 00:04:06,900
talking about previously,

97
00:04:07,080 --> 00:04:08,240
those were actually

98
00:04:08,350 --> 00:04:10,200
all discriminative learning algorithms,

99
00:04:10,340 --> 00:04:15,460
and studied more formally,

100
00:04:15,570 --> 00:04:19,140
a discriminative learning algorithm is one

101
00:04:19,250 --> 00:04:23,900
that either learns PFY given X directly,

102
00:04:24,030 --> 00:04:31,170
or even learns a hypothesis

103
00:04:31,270 --> 00:04:43,470
that outputs value 0, 1 directly, okay?

104
00:04:43,620 --> 00:04:45,430
So logistic regression is an example of

105
00:04:45,550 --> 00:04:49,030
a discriminative learning algorithm.

106
00:04:49,170 --> 00:04:51,840
In contrast, a generative learning algorithm

107
00:04:51,980 --> 00:04:59,920
of models PFX given Y.

108
00:05:00,080 --> 00:05:01,360
The probability of the features

109
00:05:01,360 --> 00:05:02,530
given the class label,

110
00:05:02,680 --> 00:05:07,750
and as a technical detail, it also models PFY,

111
00:05:07,850 --> 00:05:09,090
but that's a less important thing,

112
00:05:09,260 --> 00:05:12,930
and the interpretation of this is that

113
00:05:13,060 --> 00:05:16,850
a generative model builds a probabilistic model

114
00:05:16,990 --> 00:05:18,790
for what the features looks like,

115
00:05:18,940 --> 00:05:28,610
conditioned on the class label, okay?

116
00:05:28,640 --> 00:05:29,610
In other words, conditioned on

117
00:05:29,730 --> 00:05:31,570
whether a cancer is malignant or benign,

118
00:05:31,690 --> 00:05:34,310
it models probability distribution over

119
00:05:34,410 --> 00:05:36,300
what the features of the cancer looks like.

120
00:05:36,440 --> 00:05:38,690
Then having built this model

121
00:05:38,880 --> 00:05:41,830
having built a model for PFX given Y and PFY,

122
00:05:41,900 --> 00:05:43,850
then by Bayes rule, obviously,

123
00:05:43,890 --> 00:05:47,520
you can compute PFY given 1, conditioned on X.

124
00:05:47,520 --> 00:05:48,520
This is just PFX given Y = 1 × PFX ÷ PFX,

125
00:05:58,070 --> 00:06:00,230
and, if necessary,

126
00:06:00,350 --> 00:06:07,080
you can calculate the denominator using this, right?

127
00:06:09,560 --> 00:06:22,510
And so by modeling PFX given Y

128
00:06:22,590 --> 00:06:24,040
and modeling PFY,

129
00:06:24,200 --> 00:06:25,410
you can actually use Bayes rule

130
00:06:25,500 --> 00:06:26,860
to get back to PFY given X,

131
00:06:27,010 --> 00:06:29,130
but a generative model

132
00:06:29,250 --> 00:06:31,180
generative learning algorithm starts in

133
00:06:31,290 --> 00:06:34,450
modeling PFX given Y, rather than PFY given X, okay?

134
00:06:34,570 --> 00:06:36,040
We'll talk about some of the tradeoffs,

135
00:06:36,150 --> 00:06:38,720
and why this may be a better or worse idea

136
00:06:38,840 --> 00:06:39,900
than a discriminative model

137
00:06:39,900 --> 00:06:40,770
a bit later.

138
00:06:40,920 --> 00:06:43,640
Let's go for a specific example of

139
00:06:43,740 --> 00:06:45,180
a generative learning algorithm,

140
00:06:45,290 --> 00:06:49,830
and for this specific motivating example,

141
00:06:49,940 --> 00:06:55,240
I'm going to assume that your input feature is X

142
00:06:55,350 --> 00:07:04,800
and RN and are continuous values, okay?

143
00:07:04,960 --> 00:07:06,970
And under this assumption,

144
00:07:07,100 --> 00:07:10,310
let me describe to you a specific algorithm

145
00:07:10,440 --> 00:07:12,990
called Gaussian Discriminant Analysis,

146
00:07:13,130 --> 00:07:27,500
and the, I guess, core assumption is that

147
00:07:27,630 --> 00:07:28,690
we're going to assume

148
00:07:28,820 --> 00:07:30,560
in the Gaussian discriminant analysis model of

149
00:07:30,670 --> 00:07:36,930
that PFX given Y is Gaussian, okay?

150
00:07:37,010 --> 00:07:40,810
So actually just raise your hand,

151
00:07:40,930 --> 00:07:41,920
how many of you have seen

152
00:07:42,040 --> 00:07:43,580
a multivariate Gaussian before

153
00:07:43,730 --> 00:07:44,700
not a 1D Gaussian,

154
00:07:44,810 --> 00:07:46,060
but the higher dimensional.

155
00:07:46,180 --> 00:07:47,860
Okay, cool, like maybe half of you,

156
00:07:47,940 --> 00:07:48,950
two-thirds of you.

157
00:07:49,030 --> 00:07:52,340
So let me just say a few words

158
00:07:52,490 --> 00:07:53,580
about Gaussians,

159
00:07:53,580 --> 00:07:54,670
and for those of you that

160
00:07:54,790 --> 00:07:56,960
have seen it before, it'll be a refresher.

161
00:07:57,120 --> 00:07:58,320
So we say that

162
00:07:58,490 --> 00:08:00,570
a random variable Z is distributed Gaussian,

163
00:08:00,730 --> 00:08:02,450
multivariate Gaussian as

164
00:08:02,580 --> 00:08:06,480
and the script N for normal with parameters

165
00:08:06,610 --> 00:08:10,920
mean U and covariance sigma squared.

166
00:08:11,110 --> 00:08:31,510
If Z has a density 1 over 2 Pi, sigma 2, okay?

167
00:08:31,690 --> 00:08:33,460
That's the formula for the density

168
00:08:33,570 --> 00:08:35,310
as a generalization of the one dimension of

169
00:08:35,460 --> 00:08:37,390
Gaussians and no more the familiar bell-shape curve.

170
00:08:38,440 --> 00:08:41,430
It's a high dimension vector value random variable Z.

171
00:08:41,560 --> 00:08:44,390
Don't worry too much

172
00:08:44,510 --> 00:08:45,750
about this formula for the density.

173
00:08:45,920 --> 00:08:47,710
You rarely end up needing to use it,

174
00:08:47,850 --> 00:08:49,740
but the two key quantities are

175
00:08:49,870 --> 00:08:53,910
this vector mew is the mean of the Gaussian

176
00:08:54,080 --> 00:08:58,150
and this matrix sigma is the covariance matrix

177
00:08:58,290 --> 00:09:07,590
covariance, and so sigma will be equal to, right,

178
00:09:07,720 --> 00:09:10,010
the definition of covariance of a vector valued

179
00:09:10,150 --> 00:09:16,470
random variable is X - U, X - V conspose, okay?

180
00:09:16,590 --> 00:09:21,890
And, actually, if this doesn't look familiar to you,

181
00:09:22,040 --> 00:09:26,160
you might re-watch the discussion section

182
00:09:26,280 --> 00:09:29,290
that the TAs held last Friday or the one

183
00:09:29,430 --> 00:09:31,870
that they'll be holding later this week on,

184
00:09:32,040 --> 00:09:34,510
sort of, a recap of probability, okay?

185
00:09:34,650 --> 00:09:39,400
So multi-grade Gaussians is parameterized

186
00:09:39,510 --> 00:09:41,870
by a mean and a covariance, and let me just

187
00:09:42,040 --> 00:09:44,460
can I have the laptop displayed, please?

188
00:09:44,620 --> 00:09:48,030
I'll just go ahead and actually show you,

189
00:09:48,160 --> 00:09:49,680
you know, graphically,

190
00:09:49,800 --> 00:09:52,750
the effects of varying a Gaussian

191
00:09:52,930 --> 00:09:55,430
varying the parameters of a Gaussian.

192
00:09:55,630 --> 00:10:00,010
So what I have up here is the density

193
00:10:00,130 --> 00:10:01,810
of a zero mean Gaussian

194
00:10:01,950 --> 00:10:04,290
with covariance matrix equals the identity.

195
00:10:04,430 --> 00:10:05,760
The covariance matrix is shown

196
00:10:05,880 --> 00:10:07,360
in the upper right-hand corner of the slide,

197
00:10:07,500 --> 00:10:10,330
and there's the familiar bell-shaped curve

198
00:10:10,450 --> 00:10:11,340
in two dimensions.

199
00:10:11,550 --> 00:10:14,850
And so if I shrink the covariance matrix,

200
00:10:15,030 --> 00:10:17,790
instead of covariance your identity,

201
00:10:17,910 --> 00:10:19,260
if I shrink the covariance matrix,

202
00:10:19,400 --> 00:10:21,290
then the Gaussian becomes more peaked,

203
00:10:21,430 --> 00:10:23,340
and if I widen the covariance,

204
00:10:23,500 --> 00:10:27,010
so like same = 2, 2, then the distribution

205
00:10:27,120 --> 00:10:29,060
well, the density becomes more spread out, okay?

206
00:10:29,200 --> 00:10:32,160
Those vectors stand at normal,

207
00:10:32,360 --> 00:10:33,670
identity covariance one.

208
00:10:33,800 --> 00:10:38,280
If I increase the diagonals of a covariance matrix,

209
00:10:38,400 --> 00:10:41,130
right, if I make the variables correlated,

210
00:10:41,280 --> 00:10:43,150
and the Gaussian becomes flattened out

211
00:10:43,290 --> 00:10:44,920
in this X = Y direction,

212
00:10:45,070 --> 00:10:48,200
and increase it even further, then my variables,

213
00:10:48,360 --> 00:10:49,270
X and Y, right

214
00:10:49,430 --> 00:10:52,430
excuse me, it goes Z1 and Z2

215
00:10:52,550 --> 00:10:55,470
are my two variables on a horizontal axis

216
00:10:55,600 --> 00:10:56,790
become even more correlated.

217
00:10:56,940 --> 00:10:58,660
I'll just show the same thing in contours.

218
00:10:58,790 --> 00:11:00,880
The standard normal of distribution

219
00:11:01,030 --> 00:11:02,270
has contours that are

220
00:11:02,400 --> 00:11:03,740
they're actually circles.

221
00:11:03,880 --> 00:11:05,550
Because of the aspect ratio,

222
00:11:05,670 --> 00:11:07,200
these look like ellipses.

223
00:11:07,320 --> 00:11:08,550
These should actually be circles,

224
00:11:08,700 --> 00:11:11,110
and if you increase the off diagonals

225
00:11:11,230 --> 00:11:12,680
of the Gaussian covariance matrix,

226
00:11:12,790 --> 00:11:16,160
then it becomes ellipses aligned along the,

227
00:11:16,280 --> 00:11:19,040
sort of, 45 degree angle in this example.

228
00:11:19,170 --> 00:11:21,750
This is the same thing.

229
00:11:21,870 --> 00:11:23,640
Here's an example of a Gaussian density

230
00:11:23,750 --> 00:11:25,010
with negative covariances.

231
00:11:25,110 --> 00:11:29,240
So now the correlation goes the other way,

232
00:11:29,480 --> 00:11:31,370
so that even strong [inaudible] of covariance

233
00:11:31,500 --> 00:11:32,890
and the same thing in contours.

234
00:11:33,030 --> 00:11:34,880
This is a Gaussian with negative entries

235
00:11:35,000 --> 00:11:35,770
on the diagonals

236
00:11:35,900 --> 00:11:38,440
and even larger entries on the diagonals, okay?

237
00:11:38,580 --> 00:11:42,400
And other parameter for the Gaussian

238
00:11:42,510 --> 00:11:44,270
is the mean parameters, so if this is

239
00:11:44,410 --> 00:11:45,370
with mew0,

240
00:11:45,480 --> 00:11:46,880
and as he changed the mean parameter,

241
00:11:46,990 --> 00:11:49,570
this is mew equals 0.15,

242
00:11:49,680 --> 00:11:51,850
the location of the Gaussian

243
00:11:51,970 --> 00:11:53,190
just moves around, okay?

244
00:11:53,310 --> 00:11:57,950
All right. So that was a quick primer on

245
00:11:58,080 --> 00:11:59,100
what Gaussians look like,

246
00:11:59,240 --> 00:12:04,060
and here's as a roadmap or as a picture

247
00:12:04,190 --> 00:12:05,050
to keep in mind,

248
00:12:05,160 --> 00:12:06,110
when we described

249
00:12:06,240 --> 00:12:07,770
the Gaussian discriminant analysis algorithm,

250
00:12:07,880 --> 00:12:08,960
this is what we're going to do.

251
00:12:09,120 --> 00:12:10,330
Here's the training set,

252
00:12:10,470 --> 00:12:14,240
and in the Gaussian discriminant analysis algorithm,

253
00:12:14,360 --> 00:12:15,620
what I'm going to do is

254
00:12:15,800 --> 00:12:17,880
I'm going to look at the positive examples,

255
00:12:18,020 --> 00:12:19,040
say the crosses,

256
00:12:19,040 --> 00:12:20,040
for phi would be Sum over I, YI ÷ M,

257
00:12:19,240 --> 00:12:21,320
and just looking at only the positive examples,

258
00:12:21,470 --> 00:12:22,610
I'm gonna fit a Gaussian distribution

259
00:12:22,740 --> 00:12:24,080
to the positive examples,

260
00:12:24,240 --> 00:12:26,120
and so maybe I end up with

261
00:12:26,250 --> 00:12:27,960
a Gaussian distribution like that, okay?

262
00:12:28,080 --> 00:12:30,500
So there's PFX given Y = 1.

263
00:12:30,620 --> 00:12:32,730
And then I'll look at the negative examples,

264
00:12:32,900 --> 00:12:34,080
the O's in this figure,

265
00:12:34,200 --> 00:12:35,600
and I'll fit a Gaussian to that,

266
00:12:35,720 --> 00:12:38,280
and maybe I get a Gaussian centered over there.

267
00:12:38,370 --> 00:12:39,910
This is the concept of my second Gaussian,

268
00:12:40,020 --> 00:12:41,170
and together

269
00:12:41,320 --> 00:12:43,870
we'll say how later

270
00:12:44,000 --> 00:12:47,000
together these two Gaussian densities will

271
00:12:47,160 --> 00:12:50,690
define a separator for these two classes, okay?

272
00:12:50,820 --> 00:12:53,260
And it'll turn out that the separator will

273
00:12:53,390 --> 00:12:56,390
turn out to be a little bit different from what

274
00:12:56,500 --> 00:12:57,960
logistic regression gives you.

275
00:12:58,100 --> 00:13:00,000
If you run logistic regression,

276
00:13:00,170 --> 00:13:01,570
you actually get the division

277
00:13:01,690 --> 00:13:02,990
bound to be shown in the green line,

278
00:13:03,100 --> 00:13:04,560
whereas Gaussian discriminant analysis

279
00:13:04,670 --> 00:13:06,260
gives you the blue line, okay?

280
00:13:06,380 --> 00:13:09,110
Switch back to chalkboard, please.

281
00:13:21,960 --> 00:13:27,360
All right.

282
00:13:27,480 --> 00:13:32,020
Here's the Gaussian discriminant analysis model,

283
00:13:32,190 --> 00:13:36,360
put into model PFY

284
00:13:36,480 --> 00:13:38,110
as a Bernoulli random

285
00:13:38,110 --> 00:13:39,590
variable as usual,

286
00:13:39,710 --> 00:13:43,410
but as a Bernoulli random variable

287
00:13:43,520 --> 00:13:45,650
and parameterized by parameter phi;

288
00:13:45,740 --> 00:13:46,990
you've seen this before.

289
00:13:46,990 --> 00:13:47,990
Model PFX given Y = 0 as a Gaussian –

290
00:13:53,940 --> 00:13:58,980
oh, you know what?

291
00:13:59,110 --> 00:14:02,120
Yeah, yes, excuse me.

292
00:14:02,240 --> 00:14:06,050
I thought this looked strange.

293
00:14:06,160 --> 00:14:12,480
This should be a sigma,

294
00:14:12,600 --> 00:14:14,340
determined in a sigma to the one-

295
00:14:14,420 --> 00:14:15,620
half of the denominator there.

296
00:14:15,770 --> 00:14:17,040
It's no big deal.

297
00:14:17,230 --> 00:14:23,720
It was yeah, well, okay. Right.

298
00:14:23,870 --> 00:14:25,750
I was missing the sigma to the determining

299
00:14:25,930 --> 00:14:27,560
the sigma to the one-half on a previous board,

300
00:14:27,670 --> 00:14:28,800
excuse me.

301
00:14:28,920 --> 00:14:43,230
Okay, and so I model PFX given Y = 0

302
00:14:43,330 --> 00:14:47,450
as a Gaussian with mean mew0 and covariance sigma

303
00:14:47,540 --> 00:15:10,280
to the sigma to the minus one-half, and okay?

304
00:15:10,410 --> 00:15:15,700
And so the parameters of this model are

305
00:15:15,820 --> 00:15:22,170
phi, mew0, mew1, and sigma,

306
00:15:22,280 --> 00:15:27,480
and so I can now write down the likelihood

307
00:15:27,600 --> 00:15:29,710
of the parameters as

308
00:15:30,040 --> 00:15:31,440
oh, excuse me, actually,

309
00:15:31,560 --> 00:15:32,670
the log likelihood of the parameters

310
00:15:32,790 --> 00:15:43,970
as the log of that, right?

311
00:15:44,100 --> 00:15:46,550
So, in other words,

312
00:15:46,690 --> 00:15:47,910
if I'm given the training set,

313
00:15:48,030 --> 00:15:50,070
then they can write down the log likelihood

314
00:15:50,180 --> 00:15:52,550
of the parameters as the log of, you know,

315
00:15:52,670 --> 00:15:57,290
the probative probabilities of PFXI, YI, right?

316
00:15:57,400 --> 00:16:12,790
And this is just equal to that

317
00:16:12,950 --> 00:16:15,470
where each of these terms, PFXI given YI,

318
00:16:15,570 --> 00:16:18,590
or PFYI is then given by

319
00:16:18,730 --> 00:16:22,890
one of these three equations on top, okay?

320
00:16:23,010 --> 00:16:27,920
And I just want to contrast this again

321
00:16:28,030 --> 00:16:30,330
with discriminative learning algorithms, right?

322
00:16:30,430 --> 00:16:33,460
So to give this a name, I guess,

323
00:16:33,590 --> 00:16:34,830
this sometimes is actually

324
00:16:34,940 --> 00:16:36,640
called the Joint Data Likelihood

325
00:16:36,750 --> 00:16:38,110
the Joint Likelihood,

326
00:16:38,230 --> 00:16:43,460
and let me just contrast this with what

327
00:16:43,580 --> 00:16:44,650
we had previously

328
00:16:44,790 --> 00:16:46,970
when we're talking about logistic regression.

329
00:16:47,110 --> 00:16:49,810
Where I said with the log likelihood

330
00:16:49,920 --> 00:16:53,910
of the parameter's theater was log of a product

331
00:16:54,020 --> 00:16:55,640
I = 1 to M,

332
00:16:55,770 --> 00:17:04,140
PFYI given XI and parameterized by a theater, right?

333
00:17:04,380 --> 00:17:07,160
So back where we're fitting logistic regression models

334
00:17:07,290 --> 00:17:08,320
or generalized learning models,

335
00:17:08,440 --> 00:17:11,040
we're always modeling PFYI given XI

336
00:17:11,120 --> 00:17:12,420
and parameterized by a theater,

337
00:17:12,540 --> 00:17:22,560
and that was the conditional likelihood, okay,

338
00:17:22,680 --> 00:17:25,990
in which we're modeling PFYI given XI,

339
00:17:26,090 --> 00:17:29,240
whereas, now, regenerative learning algorithms,

340
00:17:29,350 --> 00:17:31,290
we're going to look at the joint likelihood

341
00:17:31,400 --> 00:17:33,990
which is PFXI, YI, okay?

342
00:17:34,130 --> 00:17:45,730
So let's see.

343
00:17:45,820 --> 00:17:47,760
So given the training sets

344
00:17:47,830 --> 00:17:50,500
and using the Gaussian discriminant analysis model

345
00:17:51,620 --> 00:17:52,820
to fit the parameters of the model,

346
00:17:52,940 --> 00:17:54,920
we'll do maximize likelihood estimation as usual,

347
00:17:55,030 --> 00:18:03,130
and so you maximize your L with respect

348
00:18:03,210 --> 00:18:06,860
to the parameters phi, mew0, mew1, sigma,

349
00:18:06,980 --> 00:18:11,130
and so if we find the maximum likelihood

350
00:18:11,260 --> 00:18:12,780
estimate of parameters,

351
00:18:12,780 --> 00:18:14,190
you find that phi is

352
00:18:14,340 --> 00:18:18,880
the maximum likelihood estimate

353
00:18:18,990 --> 00:18:19,840
is actually no surprise,

354
00:18:19,970 --> 00:18:21,090
and I'm writing this down mainly

355
00:18:21,210 --> 00:18:24,070
as a practice for indicating notation, all right?

356
00:18:24,190 --> 00:18:25,770
So the maximum likelihood estimate

357
00:18:29,030 --> 00:18:34,510
or written alternatively as Sum over

358
00:18:34,640 --> 00:18:36,560
all your training examples of

359
00:18:36,560 --> 00:18:37,560
indicator YI = 1 ÷ M, okay?

360
00:18:43,190 --> 00:18:43,850
In other words,

361
00:18:43,970 --> 00:18:45,790
maximum likelihood estimate

362
00:18:45,910 --> 00:18:50,310
for a newly parameter phi is just the faction of

363
00:18:50,380 --> 00:18:53,050
training examples with label one,

364
00:18:53,170 --> 00:18:59,160
with Y equals 1. Maximum likelihood estimate

365
00:18:59,270 --> 00:19:20,850
for mew0 is this, okay?

366
00:19:20,970 --> 00:19:23,250
You should stare at this for a second

367
00:19:23,370 --> 00:19:24,810
and see if it makes sense.

368
00:19:24,920 --> 00:19:27,840
Actually, I'll just write on the next one

369
00:19:27,930 --> 00:19:48,070
for mew1 while you do that. Okay?

370
00:19:48,210 --> 00:19:52,690
So what this is is what the denominator

371
00:19:52,850 --> 00:19:55,690
is sum of your training sets indicated YI = 0.

372
00:19:55,840 --> 00:20:00,380
So for every training example for which YI = 0,

373
00:20:00,510 --> 00:20:05,710
this will increment the count by one, all right?

374
00:20:05,840 --> 00:20:08,650
So the denominator is just the number

375
00:20:08,790 --> 00:20:19,510
of examples with label zero, all right?

376
00:20:19,640 --> 00:20:21,190
And then

377
00:20:21,530 --> 00:20:24,170
the numerator will be, let's see,

378
00:20:24,290 --> 00:20:25,340
Sum from I = 1 for M,

379
00:20:25,460 --> 00:20:27,520
or every time YI is equal to 0,

380
00:20:27,630 --> 00:20:29,730
this will be a one, and otherwise,

381
00:20:29,850 --> 00:20:31,090
this thing will be zero,

382
00:20:31,210 --> 00:20:33,150
and so this indicator function means that

383
00:20:33,260 --> 00:20:35,700
you're including only the terms for which

384
00:20:35,820 --> 00:20:37,170
YI is equal to one

385
00:20:37,270 --> 00:20:39,210
only the terms which Y is equal to zero

386
00:20:39,330 --> 00:20:41,250
because for all the terms

387
00:20:41,330 --> 00:20:42,820
where YI is equal to one,

388
00:20:42,930 --> 00:20:46,980
this sum and will be equal to zero,

389
00:20:47,070 --> 00:20:49,560
and then you multiply that by XI,

390
00:20:49,670 --> 00:20:56,330
and so the numerator is really the sum of

391
00:20:56,410 --> 00:21:03,050
XI's corresponding to examples

392
00:21:03,170 --> 00:21:07,030
where the class labels were zero, okay?

393
00:21:07,100 --> 00:21:09,600
Raise your hand if this makes sense.

394
00:21:09,700 --> 00:21:13,650
Okay, cool.

395
00:21:13,770 --> 00:21:16,480
So just to say this fancifully,

396
00:21:16,590 --> 00:21:19,090
this just means look for your training set,

397
00:21:19,180 --> 00:21:22,130
find all the examples for which Y = 0,

398
00:21:22,220 --> 00:21:26,380
and take the average of the value of X

399
00:21:26,490 --> 00:21:28,450
for all your examples which Y = 0.

400
00:21:28,530 --> 00:21:31,350
So take all your negative fitting examples

401
00:21:31,470 --> 00:21:35,530
and average the values for X and that's mew0, okay?

402
00:21:35,630 --> 00:21:42,860
If this notation is still a little bit cryptic

403
00:21:42,930 --> 00:21:43,870
if you're still not sure

404
00:21:44,000 --> 00:21:46,680
why this equation translates into what I just said,

405
00:21:46,790 --> 00:21:51,010
do go home and stare at it for a while

406
00:21:51,110 --> 00:21:52,250
until it just makes sense.

407
00:21:52,360 --> 00:21:54,430
This is, sort of, no surprise.

408
00:21:54,550 --> 00:21:56,130
It just says to estimate the mean

409
00:21:56,240 --> 00:21:57,390
for the negative examples,

410
00:21:57,500 --> 00:21:59,190
take all your negative examples, and average them.

411
00:21:59,300 --> 00:22:01,910
So no surprise, but this is a useful practice

412
00:22:02,020 --> 00:22:03,170
to indicator notation.

413
00:22:03,290 --> 00:22:08,660
Derive the maximum likelihood

414
00:22:08,750 --> 00:22:10,660
estimate for sigma. I won't do that.

415
00:22:10,760 --> 00:22:12,370
You can read that in the notes yourself.

416
00:22:12,490 --> 00:22:24,640
And so having fit the parameters find

417
00:22:24,770 --> 00:22:29,600
mew0, mew1, and sigma to your data,

418
00:22:29,710 --> 00:22:32,480
well, you now need to make a prediction.

419
00:22:32,610 --> 00:22:37,880
You know, when you're given a new value of X,

420
00:22:38,000 --> 00:22:39,140
when you're given a new cancer,

421
00:22:39,250 --> 00:22:40,840
you need to predict whether it's malignant or benign.

422
00:22:40,960 --> 00:22:44,750
Your prediction is then going to be, let's say,

423
00:22:44,850 --> 00:22:49,240
the most likely value of Y given X.

424
00:22:49,830 --> 00:22:52,140
I should write semicolon the parameters there.

425
00:22:52,240 --> 00:22:53,240
I'll just give that

426
00:22:53,330 --> 00:23:05,250
which is the [inaudible] of a Y by Bayes rule, all right?

427
00:23:05,350 --> 00:23:06,960
And that is, in turn,

428
00:23:07,080 --> 00:23:17,190
just that because the denominator PFX

429
00:23:17,290 --> 00:23:24,290
doesn't depend on Y, and if PFY is uniform.

430
00:23:24,400 --> 00:23:27,830
In other words,

431
00:23:27,950 --> 00:23:34,030
if each of your constants is equally likely,

432
00:23:34,150 --> 00:23:37,390
so if PFY takes the same value for all values of Y,

433
00:23:37,510 --> 00:23:44,760
then this is just arc X over Y, PFX given Y, okay?

434
00:23:44,870 --> 00:23:48,930
This happens sometimes, maybe not very often,

435
00:23:49,040 --> 00:23:51,040
so usually you end up using this formula

436
00:23:51,130 --> 00:23:55,210
where you compute PFX given Y and PFY

437
00:23:55,310 --> 00:23:58,380
using your model, okay?

438
00:23:58,510 --> 00:24:00,340
Student:Can you give us arc x?

439
00:24:00,470 --> 00:24:02,310
Instructor (Andrew Ng):Oh, let's see.

440
00:24:02,420 --> 00:24:09,740
So if you take actually let me. So the min of

441
00:24:09,880 --> 00:24:11,470
arcomatics means the value

442
00:24:11,550 --> 00:24:12,900
for Y that maximizes this.

443
00:24:13,010 --> 00:24:14,110
Student:Oh, okay.

444
00:24:14,220 --> 00:24:15,940
Instructor (Andrew Ng):So just for an example,

445
00:24:16,040 --> 00:24:19,800
the min of X - 5 squared is 0 because

446
00:24:19,910 --> 00:24:21,890
by choosing X equals 5, you can get this to be zero,

447
00:24:22,010 --> 00:24:27,080
and the argument over X of X - 5 squared

448
00:24:27,190 --> 00:24:30,040
is equal to 5 because 5 is the value of X

449
00:24:30,140 --> 00:24:33,500
that makes this minimize, okay? Cool.

450
00:24:33,640 --> 00:24:38,490
Thanks for asking that.

451
00:24:42,000 --> 00:24:44,400
Instructor (Andrew Ng):Okay.

452
00:24:44,500 --> 00:24:48,030
Actually any other questions about this? Yeah?

453
00:24:48,140 --> 00:24:50,600
Student:Why is distributive removing?

454
00:24:50,600 --> 00:24:51,600
Why isn't [inaudible] –

455
00:24:52,550 --> 00:25:02,460
Instructor (Andrew Ng):Oh, I see.

456
00:25:02,570 --> 00:25:05,420
By uniform I meant I was being loose here.

457
00:25:05,530 --> 00:25:10,090
I meant if PFY = 0 is equal to PFY = 1,

458
00:25:10,210 --> 00:25:11,860
or if Y is the uniform distribution

459
00:25:11,950 --> 00:25:14,530
over the set 0 and 1.

460
00:25:14,660 --> 00:25:15,700
Student:Oh.

461
00:25:15,810 --> 00:25:18,430
Instructor (Andrew Ng):I just meant

462
00:25:18,560 --> 00:25:23,530
yeah, if PFY = 0 zero = PFY given 1.

463
00:25:23,650 --> 00:25:28,540
That's all I mean, see? Anything else?

464
00:25:28,650 --> 00:25:39,690
All right. Okay.

465
00:25:39,790 --> 00:25:44,160
So it turns out Gaussian discriminant analysis

466
00:25:44,300 --> 00:25:46,690
has an interesting relationship

467
00:25:46,690 --> 00:25:47,970
to logistic regression.

468
00:25:48,100 --> 00:25:50,460
Let me illustrate that.

469
00:25:50,570 --> 00:25:56,260
So let's say you have a training set

470
00:25:56,660 --> 00:26:00,200
actually let me just go ahead

471
00:26:00,280 --> 00:26:01,320
and draw 1D training set,

472
00:26:01,480 --> 00:26:13,760
and that will kind of work, yes, okay.

473
00:26:13,880 --> 00:26:15,840
So let's say we have a training set comprising

474
00:26:15,930 --> 00:26:17,350
a few negative and a few positive examples,

475
00:26:17,470 --> 00:26:20,800
and let's say I run Gaussian discriminate analysis.

476
00:26:20,920 --> 00:26:22,520
So I'll fit Gaussians to each

477
00:26:22,640 --> 00:26:23,690
of these two densities

478
00:26:23,810 --> 00:26:25,220
a Gaussian density

479
00:26:25,220 --> 00:26:26,880
to each of these two

480
00:26:27,000 --> 00:26:29,280
to my positive and negative training examples,

481
00:26:29,400 --> 00:26:35,290
and so maybe my positive examples, the X's,

482
00:26:35,400 --> 00:26:37,100
are fit with a Gaussian like this,

483
00:26:37,270 --> 00:26:46,780
and my negative examples I will fit,

484
00:26:46,890 --> 00:26:50,680
and you have a Gaussian that looks like that, okay?

485
00:26:50,810 --> 00:27:02,030
Now, I hope this [inaudible]. Now,

486
00:27:02,160 --> 00:27:05,650
let's vary along the X axis,

487
00:27:05,780 --> 00:27:08,190
and what I want to do is

488
00:27:08,350 --> 00:27:11,770
I'll overlay on top of this plot.

489
00:27:11,860 --> 00:27:16,220
I'm going to plot PFY = 1

490
00:27:16,350 --> 00:27:24,010
no, actually, given X for

491
00:27:24,010 --> 00:27:28,600
a variety of values X, okay?

492
00:27:28,730 --> 00:27:32,710
So I actually realize what I should have done.

493
00:27:32,800 --> 00:27:34,940
I'm gonna call the X's the negative examples,

494
00:27:35,030 --> 00:27:36,230
and I'm gonna call

495
00:27:36,310 --> 00:27:37,470
the O's the positive examples.

496
00:27:37,560 --> 00:27:39,080
It just makes this part come in better.

497
00:27:39,200 --> 00:27:41,670
So let's take a value of X that's fairly small.

498
00:27:41,760 --> 00:27:44,660
Let's say X is this value here on a horizontal axis.

499
00:27:44,770 --> 00:27:46,510
Then what's the probability of Y

500
00:27:46,800 --> 00:27:48,190
being equal to one conditioned on X?

501
00:27:48,300 --> 00:27:49,970
Well, the way you calculate that

502
00:27:50,070 --> 00:27:54,560
is you write PFY = 1 given X, and then

503
00:27:54,670 --> 00:27:57,140
you plug in all these formulas as usual, right?

504
00:27:57,240 --> 00:27:58,600
It's PFX given Y = 1,

505
00:27:58,680 --> 00:28:00,480
which is your Gaussian density,

506
00:28:00,550 --> 00:28:04,430
times PFY = 1, you know, which is essentially

507
00:28:04,520 --> 00:28:07,040
this is just going to be equal to phi,

508
00:28:07,190 --> 00:28:10,520
and then divided by, right, PFX,

509
00:28:10,630 --> 00:28:12,200
and then this shows you how you can calculate this.

510
00:28:12,330 --> 00:28:14,480
By using these two Gaussians

511
00:28:14,610 --> 00:28:16,780
and my phi on PFY,

512
00:28:16,910 --> 00:28:20,110
I actually compute what PFY = 1 given X is,

513
00:28:20,250 --> 00:28:26,230
and in this case, if X is this small,

514
00:28:26,380 --> 00:28:28,340
clearly it belongs to the left Gaussian.

515
00:28:28,490 --> 00:28:30,710
It's very unlikely to belong to a positive class,

516
00:28:30,820 --> 00:28:32,420
and so it'll be very small;

517
00:28:32,570 --> 00:28:34,650
it'll be very close to zero say, okay?

518
00:28:34,800 --> 00:28:37,910
And then we can increment the value of X a bit,

519
00:28:38,040 --> 00:28:39,680
and study a different value of X,

520
00:28:39,820 --> 00:28:45,830
and plot what is the PFY given X PFY = 1 given X,

521
00:28:45,950 --> 00:28:47,400
and, again, it'll be pretty small.

522
00:28:47,540 --> 00:28:51,180
Let's use a point like that, right?

523
00:28:51,330 --> 00:28:53,240
At this point,

524
00:28:53,390 --> 00:28:56,270
the two Gaussian densities have equal value,

525
00:28:56,390 --> 00:29:00,550
and if I ask if X is this value, right,

526
00:29:00,700 --> 00:29:01,910
shown by the arrow,

527
00:29:02,050 --> 00:29:03,120
what's the probably of Y

528
00:29:03,270 --> 00:29:05,060
being equal to one for that value of X?

529
00:29:05,180 --> 00:29:06,100
Well, you really can't tell,

530
00:29:06,220 --> 00:29:07,470
so maybe it's about 0.5, okay?

531
00:29:07,610 --> 00:29:12,530
And if you fill in a bunch more points,

532
00:29:12,670 --> 00:29:14,520
you get a curve like that,

533
00:29:14,640 --> 00:29:17,680
and then you can keep going.

534
00:29:17,770 --> 00:29:19,290
Let's say for a point like that,

535
00:29:19,410 --> 00:29:21,240
you can ask what's the probability of X being one?

536
00:29:21,360 --> 00:29:23,520
Well, if it's that far out, then clearly,

537
00:29:23,650 --> 00:29:25,990
it belongs to this rightmost Gaussian,

538
00:29:26,100 --> 00:29:28,430
and so the probability of Y being a one

539
00:29:28,580 --> 00:29:29,370
would be very high;

540
00:29:29,540 --> 00:29:30,890
it would be almost one, okay?

541
00:29:31,040 --> 00:29:34,430
And so you can repeat

542
00:29:34,570 --> 00:29:37,310
this exercise for a bunch of points.

543
00:29:37,410 --> 00:29:40,020
All right, compute PFY equals one given X

544
00:29:40,140 --> 00:29:41,310
for a bunch of points,

545
00:29:41,440 --> 00:29:43,280
and if you connect up these points,

546
00:29:43,390 --> 00:29:49,080
you find that the curve you get [Pause]

547
00:29:49,280 --> 00:29:53,450
plotted takes a form of sigmoid function, okay?

548
00:29:53,590 --> 00:29:57,460
So, in other words,

549
00:29:57,600 --> 00:29:58,710
when you make the assumptions

550
00:29:58,840 --> 00:30:04,090
under the Gaussian discriminant analysis model,

551
00:30:04,210 --> 00:30:07,510
that PFX given Y is Gaussian,

552
00:30:07,650 --> 00:30:11,190
when you go back and compute what PFY given X is,

553
00:30:11,260 --> 00:30:12,900
you actually get back exactly

554
00:30:13,120 --> 00:30:15,390
the same sigmoid function that we're using

555
00:30:15,530 --> 00:30:18,380
which in the logistic regression, okay?

556
00:30:18,520 --> 00:30:22,300
But it turns out the key difference is that

557
00:30:22,430 --> 00:30:24,920
Gaussian discriminant analysis will end up

558
00:30:25,060 --> 00:30:30,150
choosing a different position and a steepness

559
00:30:30,290 --> 00:30:33,040
of the sigmoid than would logistic regression.

560
00:30:33,170 --> 00:30:34,490
Is there a question?

561
00:30:34,660 --> 00:30:37,420
Student:I'm just wondering,

562
00:30:37,570 --> 00:30:39,370
the Gaussian of PFY [inaudible] you do?

563
00:30:39,540 --> 00:30:40,780
Instructor (Andrew Ng):No, let's see.

564
00:30:40,870 --> 00:30:46,690
The Gaussian so this Gaussian is PFX given Y = 1,

565
00:30:46,880 --> 00:30:51,450
and this Gaussian is PFX given Y = 0;

566
00:30:51,600 --> 00:30:54,680
does that make sense? Anything else?

567
00:30:54,830 --> 00:30:58,300
Student:Okay.

568
00:30:58,440 --> 00:31:00,090
Instructor (Andrew Ng):Yeah?

569
00:31:00,240 --> 00:31:02,040
Student:When you drawing all the dots,

570
00:31:02,200 --> 00:31:04,770
how did you decide what Y given PFX was?

571
00:31:04,920 --> 00:31:07,350
Instructor (Andrew Ng):What say that again.

572
00:31:07,500 --> 00:31:08,500
Student:I'm sorry.

573
00:31:08,640 --> 00:31:09,650
Could you go over

574
00:31:09,800 --> 00:31:11,430
how you figured out where to draw each dot?

575
00:31:11,610 --> 00:31:13,280
Instructor (Andrew Ng):Let's see, okay.

576
00:31:13,420 --> 00:31:17,490
So the computation is as follows, right?

577
00:31:17,620 --> 00:31:20,040
The steps are I have the training sets,

578
00:31:20,200 --> 00:31:21,580
and so given my training set,

579
00:31:21,720 --> 00:31:22,490
I'm going to

580
00:31:22,630 --> 00:31:24,770
fit a Gaussian discriminant analysis model to it,

581
00:31:24,960 --> 00:31:26,360
and what that means is

582
00:31:26,540 --> 00:31:30,050
I'll build a model for PFX given Y = 1.

583
00:31:30,190 --> 00:31:32,530
I'll build a model for PFX given Y = 0,

584
00:31:32,690 --> 00:31:35,390
and I'll also fit a Bernoulli

585
00:31:35,390 --> 00:31:38,090
distribution to PFY, okay?

586
00:31:38,240 --> 00:31:40,340
So, in other words, given my training set,

587
00:31:40,480 --> 00:31:43,960
I'll fit PFX given Y and PFY to my data,

588
00:31:44,130 --> 00:31:45,910
and now I've chosen my parameters of

589
00:31:46,040 --> 00:31:51,020
find mew0, mew1, and the sigma, okay?

590
00:31:51,150 --> 00:31:53,480
Then this is the process

591
00:31:53,610 --> 00:31:56,660
I went through to plot all these dots, right?

592
00:31:56,790 --> 00:31:58,380
It's just I pick a point in the X axis,

593
00:31:58,520 --> 00:32:04,320
and then I compute PFY given X for that value of X,

594
00:32:04,500 --> 00:32:07,290
and PFY given 1 conditioned on X

595
00:32:07,430 --> 00:32:09,240
will be some value between zero and one.

596
00:32:09,410 --> 00:32:10,630
It'll be some real number,

597
00:32:10,750 --> 00:32:11,920
and whatever that real number is,

598
00:32:12,030 --> 00:32:15,130
I then plot it on the vertical axis, okay?

599
00:32:15,240 --> 00:32:17,210
And the way I compute PFY = 1

600
00:32:17,370 --> 00:32:22,760
conditioned on X is I would use these quantities.

601
00:32:22,900 --> 00:32:27,300
I would use PFX given Y and PFY, and, sort of,

602
00:32:27,430 --> 00:32:28,760
plug them into Bayes rule,

603
00:32:28,870 --> 00:32:31,540
and that allows me to compute PFY given X

604
00:32:31,680 --> 00:32:33,720
from these three quantities;

605
00:32:33,850 --> 00:32:34,980
does that make sense?

606
00:32:35,120 --> 00:32:36,510
Student:Yeah.

607
00:32:36,630 --> 00:32:37,420
Instructor (Andrew Ng):Was there

608
00:32:37,600 --> 00:32:38,680
something more that

609
00:32:38,830 --> 00:32:41,390
Student:And how did you model PFX; is that

610
00:32:41,520 --> 00:32:43,700
Instructor (Andrew Ng):Oh, okay. Yeah, so

611
00:32:43,840 --> 00:32:46,240
well, got this right here.

612
00:32:46,330 --> 00:32:49,260
So PFX can be written as, right,

613
00:32:49,370 --> 00:32:58,440
so PFX given Y = 0 × PFY = 0 + PFX given Y = 1,

614
00:32:58,570 --> 00:33:04,620
PFY = 1, right? And so each of these terms,

615
00:33:04,740 --> 00:33:06,300
PFX given Y and PFY,

616
00:33:06,450 --> 00:33:09,040
these are terms I can get out of, directly,

617
00:33:09,190 --> 00:33:10,900
from my Gaussian discriminant analysis model.

618
00:33:11,020 --> 00:33:13,340
Each of these terms is something that

619
00:33:13,460 --> 00:33:15,240
my model gives me directly,

620
00:33:15,360 --> 00:33:17,700
so plugged in as the denominator,

621
00:33:17,810 --> 00:33:19,180
and by doing that,

622
00:33:19,300 --> 00:33:22,460
that's how I compute PFY = 1 given X, make sense?

623
00:33:22,560 --> 00:33:24,180
Student:Thank you.

624
00:33:24,400 --> 00:33:26,120
Instructor (Andrew Ng):Okay. Cool.

625
00:33:26,260 --> 00:33:56,150
So let's talk a little bit about the advantages

626
00:33:56,280 --> 00:33:57,390
and disadvantages of

627
00:33:57,530 --> 00:33:59,700
using a generative learning algorithm, okay?

628
00:33:59,820 --> 00:34:01,900
So in the particular case of

629
00:34:02,050 --> 00:34:03,700
Gaussian discriminant analysis,

630
00:34:03,830 --> 00:34:08,900
we assume that X conditions on Y is Gaussian,

631
00:34:09,040 --> 00:34:15,130
and the argument I showed

632
00:34:15,260 --> 00:34:16,330
on the previous chalkboard,

633
00:34:16,460 --> 00:34:17,510
I didn't prove it formally,

634
00:34:17,680 --> 00:34:19,200
but you can actually go back

635
00:34:19,320 --> 00:34:20,860
and prove it yourself is that

636
00:34:20,940 --> 00:34:23,290
if you assume X given Y is Gaussian,

637
00:34:23,440 --> 00:34:29,750
then that implies that when you plot Y given X,

638
00:34:29,930 --> 00:34:32,030
you find that

639
00:34:32,160 --> 00:34:40,010
well, let me just write logistic posterior, okay?

640
00:34:40,130 --> 00:34:41,980
And the argument I showed just now,

641
00:34:42,100 --> 00:34:43,130
which I didn't prove;

642
00:34:43,260 --> 00:34:44,420
you can go home and prove it yourself,

643
00:34:44,550 --> 00:34:46,710
is that if you assume X given Y is Gaussian,

644
00:34:46,820 --> 00:34:50,530
then that implies that the posterior distribution

645
00:34:50,640 --> 00:34:56,540
or the form of PFY = 1 given X

646
00:34:56,680 --> 00:34:58,850
is going to be a logistic function,

647
00:34:58,980 --> 00:35:06,350
and it turns out this implication

648
00:35:06,500 --> 00:35:10,880
in the opposite direction does not hold true, okay?

649
00:35:11,020 --> 00:35:13,810
In particular, it actually turns out

650
00:35:13,970 --> 00:35:16,270
this is actually, kind of, cool.

651
00:35:16,400 --> 00:35:19,600
It turns out that if you're seeing that

652
00:35:19,670 --> 00:35:27,760
X given Y = 1 is Poisson with parameter lambda 1,

653
00:35:27,910 --> 00:35:30,650
and X given Y = 0,

654
00:35:30,830 --> 00:35:38,240
is Poisson with parameter lambda 0.

655
00:35:38,390 --> 00:35:40,900
It turns out if you assumed this,

656
00:35:41,070 --> 00:35:44,610
then that also implies that

657
00:35:44,800 --> 00:35:53,890
PFY given X is logistic, okay?

658
00:35:54,020 --> 00:35:56,810
So there are lots of assumptions on X given Y

659
00:35:56,960 --> 00:36:02,070
that will lead to PFY given X being logistic, and,

660
00:36:02,160 --> 00:36:07,310
therefore, this,

661
00:36:07,450 --> 00:36:09,860
the assumption that X given Y being Gaussian is

662
00:36:10,010 --> 00:36:14,030
the stronger assumption than the assumption

663
00:36:14,170 --> 00:36:15,610
that Y given X is logistic, okay?

664
00:36:15,750 --> 00:36:17,870
Because this implies this, right?

665
00:36:18,010 --> 00:36:19,730
That means that this is a stronger assumption

666
00:36:19,890 --> 00:36:23,170
than this because this,

667
00:36:23,310 --> 00:36:24,980
the logistic posterior holds

668
00:36:25,100 --> 00:36:26,460
whenever X given Y is

669
00:36:26,460 --> 00:36:27,620
Gaussian but not vice versa.

670
00:36:27,810 --> 00:36:32,490
And so this leaves some of the tradeoffs

671
00:36:32,600 --> 00:36:34,370
between Gaussian discriminant analysis

672
00:36:34,490 --> 00:36:36,820
and logistic regression, right?

673
00:36:36,970 --> 00:36:38,320
Gaussian discriminant analysis makes

674
00:36:38,430 --> 00:36:40,290
a much stronger assumption that

675
00:36:40,430 --> 00:36:41,770
X given Y is Gaussian,

676
00:36:41,880 --> 00:36:44,720
and so when this assumption is true,

677
00:36:44,850 --> 00:36:46,900
when this assumption approximately holds,

678
00:36:47,040 --> 00:36:50,290
if you plot the data, and if X given Y is, indeed,

679
00:36:50,420 --> 00:36:51,600
approximately Gaussian,

680
00:36:51,740 --> 00:36:53,860
then if you make this assumption,

681
00:36:53,970 --> 00:36:55,480
explicit to the algorithm,

682
00:36:55,600 --> 00:36:57,590
then the algorithm will do better

683
00:36:57,690 --> 00:36:59,850
because it's as if the algorithm

684
00:36:59,970 --> 00:37:01,860
is making use of more information about the data.

685
00:37:01,970 --> 00:37:04,660
The algorithm knows that the data is Gaussian, right?

686
00:37:04,760 --> 00:37:07,060
And so if the Gaussian assumption, you know,

687
00:37:07,120 --> 00:37:08,910
holds or roughly holds,

688
00:37:09,030 --> 00:37:11,600
then Gaussian discriminant analysis may

689
00:37:11,690 --> 00:37:12,910
do better than logistic regression.

690
00:37:13,030 --> 00:37:14,890
If, conversely,

691
00:37:14,960 --> 00:37:17,410
if you're actually not sure what X given Y is,

692
00:37:17,540 --> 00:37:19,960
then logistic regression,

693
00:37:20,070 --> 00:37:23,050
the discriminant algorithm may do better, and,

694
00:37:23,290 --> 00:37:24,800
in particular, use logistic regression,

695
00:37:24,920 --> 00:37:26,770
and maybe you see [inaudible]

696
00:37:26,880 --> 00:37:28,470
before the data was Gaussian,

697
00:37:28,570 --> 00:37:30,910
but it turns out the data was actually Poisson, right?

698
00:37:31,030 --> 00:37:33,790
Then logistic regression will still do perfectly fine

699
00:37:33,910 --> 00:37:36,870
because if the data were actually Poisson,

700
00:37:36,970 --> 00:37:38,970
then PFY = 1 given X will be logistic,

701
00:37:39,040 --> 00:37:40,520
and it'll do perfectly fine,

702
00:37:40,630 --> 00:37:42,330
but if you assumed it was Gaussian,

703
00:37:42,440 --> 00:37:44,170
then the algorithm may go off

704
00:37:44,230 --> 00:37:46,640
and do something that's not as good, okay?

705
00:37:46,730 --> 00:37:55,930
So it turns out that right.

706
00:37:56,040 --> 00:37:57,720
So it's slightly different.

707
00:37:57,820 --> 00:38:03,090
It turns out the real advantage of

708
00:38:03,190 --> 00:38:04,760
generative learning algorithms is often that

709
00:38:04,860 --> 00:38:08,380
it requires less data, and, in particular,

710
00:38:08,460 --> 00:38:09,970
data is never really

711
00:38:09,970 --> 00:38:12,240
exactly Gaussian, right?

712
00:38:12,370 --> 00:38:14,020
Because data is often approximately Gaussian;

713
00:38:14,140 --> 00:38:15,580
it's never exactly Gaussian.

714
00:38:15,690 --> 00:38:18,210
And it turns out, generative learning algorithms

715
00:38:18,290 --> 00:38:20,490
often do surprisingly well even when

716
00:38:20,590 --> 00:38:22,800
these modeling assumptions are not met,

717
00:38:22,930 --> 00:38:26,420
but one other tradeoff is that

718
00:38:26,510 --> 00:38:31,190
by making stronger assumptions about the data,

719
00:38:31,300 --> 00:38:35,710
Gaussian discriminant analysis often needs less data

720
00:38:35,840 --> 00:38:37,950
in order to fit, like, an okay model,

721
00:38:38,060 --> 00:38:39,770
even if there's less training data.

722
00:38:39,890 --> 00:38:41,410
Whereas, in contrast,

723
00:38:41,550 --> 00:38:44,080
logistic regression by making less assumption

724
00:38:44,220 --> 00:38:47,970
is more robust to your modeling assumptions

725
00:38:48,060 --> 00:38:49,580
because you're making a weaker assumption;

726
00:38:49,690 --> 00:38:50,850
you're making less assumptions,

727
00:38:50,980 --> 00:38:52,970
but sometimes it takes a slightly larger training set

728
00:38:53,080 --> 00:38:56,330
to fit than Gaussian discriminant analysis.

729
00:38:56,450 --> 00:38:57,630
Question?

730
00:38:57,750 --> 00:39:00,280
Student:In order to meet any assumption

731
00:39:00,390 --> 00:39:02,290
about the number [inaudible],

732
00:39:02,450 --> 00:39:05,260
plus here we assume that PFY = 1,

733
00:39:05,360 --> 00:39:10,860
equal two number of. [Inaudible]. Is true

734
00:39:10,970 --> 00:39:14,110
when the number of samples is marginal?

735
00:39:14,230 --> 00:39:16,890
Instructor (Andrew Ng):Okay. So let's see.

736
00:39:17,010 --> 00:39:21,400
So there's a question of is this true

737
00:39:21,520 --> 00:39:22,450
what was that?

738
00:39:22,570 --> 00:39:24,350
Let me translate that differently.

739
00:39:24,470 --> 00:39:27,570
So the modeling assumptions are made independently

740
00:39:27,680 --> 00:39:29,020
of the size of your training set, right?

741
00:39:29,150 --> 00:39:31,990
So, like, in least square regression

742
00:39:32,110 --> 00:39:34,460
well, in all of these models I'm assuming that

743
00:39:34,570 --> 00:39:37,200
these are random variables flowing from

744
00:39:37,330 --> 00:39:38,940
some distribution, and then, finally,

745
00:39:39,050 --> 00:39:41,630
I'm giving a single training set and that

746
00:39:41,760 --> 00:39:44,330
as for the parameters of the distribution, right?

747
00:39:44,440 --> 00:39:49,330
Student:So what's the probability of Y = 1?

748
00:39:49,440 --> 00:39:52,840
Instructor (Andrew Ng):Probability of Y + 1?

749
00:39:52,990 --> 00:39:54,990
Student:Yeah, you used the

750
00:39:55,230 --> 00:39:57,850
Instructor (Andrew Ng):Sort of, this like

751
00:39:57,950 --> 00:40:00,830
back to the philosophy of

752
00:40:00,940 --> 00:40:01,980
maximum likelihood estimation, right?

753
00:40:02,070 --> 00:40:05,630
I'm assuming that they're PFY

754
00:40:05,750 --> 00:40:07,660
is equal to phi to the Y,

755
00:40:07,790 --> 00:40:11,000
Y - phi to the Y or Y - Y.

756
00:40:11,150 --> 00:40:11,990
So I'm assuming that

757
00:40:12,090 --> 00:40:14,870
there's some true value of Y generating all my data,

758
00:40:15,000 --> 00:40:20,730
and then well, when I write this, I guess,

759
00:40:20,860 --> 00:40:22,620
maybe what I should write isn't

760
00:40:22,760 --> 00:40:26,520
so when I write this,

761
00:40:26,650 --> 00:40:29,350
I guess there are already two values of phi.

762
00:40:29,440 --> 00:40:32,370
One is there's a true underlying value of phi that

763
00:40:32,480 --> 00:40:34,380
guards the use to generate the data,

764
00:40:34,520 --> 00:40:36,820
and then there's the maximum likelihood estimate

765
00:40:36,920 --> 00:40:38,380
of the value of phi,

766
00:40:38,520 --> 00:40:40,870
and so when I was writing those formulas earlier,

767
00:40:40,970 --> 00:40:44,010
those formulas are writing for phi, and mew0,

768
00:40:44,120 --> 00:40:45,590
and mew1 were really the maximum likelihood

769
00:40:45,700 --> 00:40:47,240
estimates for phi, mew0, and mew1,

770
00:40:47,290 --> 00:40:50,100
and that's different from the true underlying values

771
00:40:50,200 --> 00:40:51,750
of phi, mew0, and mew1, but

772
00:40:52,130 --> 00:40:53,480
Student:[Off mic].

773
00:40:53,620 --> 00:40:55,390
Instructor (Andrew Ng):Yeah, right.

774
00:40:55,520 --> 00:40:56,450
So maximum likelihood estimate

775
00:40:56,550 --> 00:40:58,480
comes from the data, and there's some, sort of,

776
00:40:58,590 --> 00:41:00,630
true underlying value of phi that

777
00:41:00,740 --> 00:41:01,910
I'm trying to estimate,

778
00:41:02,030 --> 00:41:03,120
and my maximum likelihood estimate

779
00:41:03,300 --> 00:41:04,840
is my attempt to estimate the true value,

780
00:41:04,960 --> 00:41:06,070
but, you know,

781
00:41:06,230 --> 00:41:08,910
by notational and convention often are just right

782
00:41:09,040 --> 00:41:11,190
as that as well without bothering to distinguish

783
00:41:11,310 --> 00:41:13,310
between the maximum likelihood value a

784
00:41:13,430 --> 00:41:14,590
nd the true underlying value that

785
00:41:14,680 --> 00:41:15,880
I'm assuming is out there,

786
00:41:16,000 --> 00:41:18,140
and that I'm only hoping to estimate.

787
00:41:18,270 --> 00:41:24,510
Actually, yeah,

788
00:41:24,630 --> 00:41:27,320
so for the sample of questions like these

789
00:41:27,430 --> 00:41:28,810
about maximum likelihood and so on,

790
00:41:28,940 --> 00:41:32,970
I hope to tease to the Friday discussion section

791
00:41:33,090 --> 00:41:38,020
as a good time to ask questions about, sort of,

792
00:41:38,140 --> 00:41:39,920
probabilistic definitions like these as well.

793
00:41:40,070 --> 00:41:42,300
Are there any other questions?

794
00:41:42,420 --> 00:41:50,360
No, great. Okay.

795
00:41:50,470 --> 00:42:01,790
So, great. Oh, it turns out,

796
00:42:01,890 --> 00:42:03,780
just to mention one more thing that's, kind of, cool.

797
00:42:03,900 --> 00:42:10,740
I said that if X given Y is Poisson,

798
00:42:10,850 --> 00:42:12,910
and you also go logistic posterior,

799
00:42:13,030 --> 00:42:14,330
it actually turns out

800
00:42:14,430 --> 00:42:15,840
there's a more general version of this.

801
00:42:15,940 --> 00:42:18,180
If you assume X given Y = 1

802
00:42:18,270 --> 00:42:25,950
is exponential family with parameter A to 1,

803
00:42:26,080 --> 00:42:29,490
and then you assume X given Y = 0

804
00:42:29,610 --> 00:42:35,350
is exponential family with parameter A to 0,

805
00:42:35,460 --> 00:42:41,170
then this implies that PFY = 1 given X

806
00:42:41,260 --> 00:42:43,350
is also logistic, okay?

807
00:42:43,480 --> 00:42:44,890
And that's, kind of, cool.

808
00:42:45,010 --> 00:42:47,310
It means that Y given X could be

809
00:42:47,460 --> 00:42:49,130
I don't know, some strange thing.

810
00:42:49,220 --> 00:42:50,440
It could be gamma

811
00:42:50,600 --> 00:42:52,190
because we've seen Gaussian

812
00:42:52,200 --> 00:42:53,300
right next to the

813
00:42:53,410 --> 00:42:55,450
I don't know, gamma exponential.

814
00:42:55,630 --> 00:42:58,150
They're actually a beta.

815
00:42:58,270 --> 00:43:00,600
I'm just rattling off my mental list of

816
00:43:00,720 --> 00:43:01,760
exponential family extrusions.

817
00:43:01,890 --> 00:43:03,060
It could be any one of those things,

818
00:43:03,200 --> 00:43:05,030
so [inaudible]

819
00:43:05,100 --> 00:43:06,320
the same exponential family distribution

820
00:43:06,470 --> 00:43:07,740
for the two classes

821
00:43:07,870 --> 00:43:09,230
with different natural parameters

822
00:43:09,390 --> 00:43:14,460
than the posterior PFY given 1 given X PFY = 1

823
00:43:14,530 --> 00:43:15,410
given X would be logistic,

824
00:43:15,560 --> 00:43:17,520
and so this shows the robustness

825
00:43:17,650 --> 00:43:20,170
of logistic regression to the choice

826
00:43:20,290 --> 00:43:21,260
of modeling assumptions

827
00:43:21,380 --> 00:43:23,340
because it could be that the data was actually,

828
00:43:23,460 --> 00:43:24,440
you know, gamma distributed,

829
00:43:24,560 --> 00:43:26,780
and just still turns out to be logistic.

830
00:43:26,880 --> 00:43:30,470
So it's the robustness of logistic regression

831
00:43:30,580 --> 00:43:31,600
to modeling assumptions.

832
00:43:31,750 --> 00:43:42,140
And this is the density.

833
00:43:42,250 --> 00:43:45,280
I think, early on I promised two justifications

834
00:43:45,390 --> 00:43:47,500
for where I pulled the logistic function

835
00:43:47,630 --> 00:43:48,730
out of the hat, right?

836
00:43:48,820 --> 00:43:50,670
So one was the exponential family derivation

837
00:43:50,780 --> 00:43:52,210
we went through last time,

838
00:43:52,300 --> 00:43:53,590
and this is, sort of, the second one.

839
00:43:53,700 --> 00:43:54,850
That all of these modeling assumptions

840
00:43:54,980 --> 00:43:58,330
also lead to the logistic function. Yeah?

841
00:43:58,450 --> 00:43:59,530
Student:[Off mic].

842
00:43:59,660 --> 00:44:05,800
Instructor (Andrew Ng):Oh,

843
00:44:05,930 --> 00:44:07,390
that Y = 1 given as the logistic

844
00:44:07,500 --> 00:44:08,780
then this implies that, no.

845
00:44:08,850 --> 00:44:10,340
This is also not true, right?

846
00:44:10,460 --> 00:44:13,140
Yeah, so this exponential family distribution

847
00:44:13,370 --> 00:44:15,470
implies Y = 1 is logistic,

848
00:44:15,570 --> 00:44:17,960
but the reverse assumption is also not true.

849
00:44:18,100 --> 00:44:19,460
There are actually all sorts of

850
00:44:19,540 --> 00:44:23,350
really bizarre distributions for X that

851
00:44:23,440 --> 00:44:26,420
would give rise to logistic function, okay?

852
00:44:26,540 --> 00:44:30,650
Okay. So let's talk about

853
00:44:30,730 --> 00:44:33,180
those are first generative learning algorithm.

854
00:44:33,290 --> 00:44:34,420
Maybe I'll talk about

855
00:44:34,540 --> 00:44:35,860
the second generative learning algorithm,

856
00:44:35,980 --> 00:44:38,870
and the motivating example,

857
00:44:38,970 --> 00:44:41,220
actually this is called a Naive Bayes algorithm,

858
00:44:41,350 --> 00:44:46,830
and the motivating example that

859
00:44:46,920 --> 00:44:49,440
I'm gonna use will be spam classification.

860
00:44:49,540 --> 00:44:51,220
All right. So let's say that

861
00:44:51,310 --> 00:44:52,630
you want to build a spam classifier

862
00:44:52,710 --> 00:44:53,960
to take your incoming stream of email

863
00:44:54,070 --> 00:45:00,460
and decide if it's spam or not. So let's see.

864
00:45:00,570 --> 00:45:08,880
Y will be 0 or 1, with 1 being spam email

865
00:45:08,980 --> 00:45:10,000
and 0 being non-spam,

866
00:45:10,120 --> 00:45:13,640
and the first decision we need to make is,

867
00:45:13,800 --> 00:45:15,360
given a piece of email,

868
00:45:15,460 --> 00:45:18,770
how do you represent a piece of email

869
00:45:18,860 --> 00:45:21,160
using a feature vector X, right?

870
00:45:21,270 --> 00:45:22,890
So email is just a piece of text, right?

871
00:45:23,000 --> 00:45:26,120
Email is like a list of words

872
00:45:26,230 --> 00:45:27,540
or a list of ASCII characters.

873
00:45:27,660 --> 00:45:28,840
So I can represent email

874
00:45:28,850 --> 00:45:30,030
as a feature of vector X.

875
00:45:30,140 --> 00:45:33,440
So we'll use a couple of different representations,

876
00:45:33,550 --> 00:45:35,490
but the one I'll use today is

877
00:45:35,610 --> 00:45:39,400
we will construct the vector X as follows.

878
00:45:39,540 --> 00:45:42,260
I'm gonna go through my dictionary, and, sort of,

879
00:45:42,380 --> 00:45:44,900
make a listing of all the words in my dictionary, okay?

880
00:45:45,010 --> 00:45:46,420
So the first word is RA.

881
00:45:46,540 --> 00:45:48,350
The second word in my dictionary is Aardvark,

882
00:45:48,460 --> 00:45:54,350
ausworth, okay?

883
00:45:54,460 --> 00:45:56,770
You know, and somewhere along the way

884
00:45:56,880 --> 00:45:58,980
you see the word "buy" in the spam email

885
00:45:59,060 --> 00:46:00,140
telling you to buy stuff.

886
00:46:00,260 --> 00:46:02,920
Tell you how you collect your list of words,

887
00:46:03,040 --> 00:46:06,980
you know, you won't find CS229, right,

888
00:46:07,090 --> 00:46:08,170
course number in a dictionary,

889
00:46:08,280 --> 00:46:10,290
but if you collect a list of words

890
00:46:10,400 --> 00:46:12,240
via other emails you've gotten,

891
00:46:12,350 --> 00:46:14,440
you have this list somewhere as well, and then

892
00:46:14,520 --> 00:46:18,560
the last word in my dictionary was zymurgy,

893
00:46:18,670 --> 00:46:24,110
which pertains to the technological chemistry that

894
00:46:24,230 --> 00:46:26,420
deals with the fermentation process in brewing.

895
00:46:26,530 --> 00:46:32,180
So say I get a piece of email,

896
00:46:32,280 --> 00:46:34,500
and what I'll do is I'll then

897
00:46:34,610 --> 00:46:36,360
scan through this list of words,

898
00:46:36,490 --> 00:46:38,980
and wherever a certain word

899
00:46:39,070 --> 00:46:40,740
appears in my email, I'll put a 1 there.

900
00:46:40,890 --> 00:46:43,060
So if a particular email has the word "aid"

901
00:46:43,200 --> 00:46:44,500
then that's 1.

902
00:46:44,640 --> 00:46:45,950
You know, my email doesn't have the words

903
00:46:46,050 --> 00:46:47,900
ausworth or aardvark, so it gets zeros.

904
00:46:48,020 --> 00:46:50,380
And again, a piece of email,

905
00:46:50,510 --> 00:46:51,770
they want me to buy something,

906
00:46:51,890 --> 00:46:54,300
CS229 doesn't occur, and so on, okay?

907
00:46:54,410 --> 00:47:00,300
So this would be one way of creating

908
00:47:00,420 --> 00:47:06,380
a feature vector to represent a piece of email.

909
00:47:06,580 --> 00:47:12,150
Now, let's throw the generative model out for this.

910
00:47:12,260 --> 00:47:19,900
Actually, let's use this.

911
00:47:20,000 --> 00:47:23,770
In other words, I want to model PFX given Y.

912
00:47:23,880 --> 00:47:27,130
The given Y = 0 or Y = 1, all right?

913
00:47:27,240 --> 00:47:31,550
And my feature vectors are going to be 0,

914
00:47:31,660 --> 00:47:32,680
1 to the N.

915
00:47:32,790 --> 00:47:34,080
It's going to be these split vectors,

916
00:47:34,180 --> 00:47:35,210
binary value vectors.

917
00:47:35,320 --> 00:47:36,560
They're N dimensional.

918
00:47:36,660 --> 00:47:41,480
Where N may be on the order of, say, 50,000,

919
00:47:41,600 --> 00:47:43,370
if you have 50,000 words in your dictionary,

920
00:47:43,480 --> 00:47:45,180
which is not atypical.

921
00:47:45,290 --> 00:47:46,590
So values from

922
00:47:46,700 --> 00:47:48,130
I don't know,

923
00:47:48,250 --> 00:47:50,640
mid-thousands to tens of thousands

924
00:47:50,740 --> 00:47:53,260
is very typical for problems like these.

925
00:47:53,380 --> 00:47:54,920
And, therefore,

926
00:47:55,040 --> 00:47:59,760
there two to the 50,000 possible values for X, right?

927
00:47:59,880 --> 00:48:02,260
So two to 50,000 possible bit vectors

928
00:48:02,370 --> 00:48:07,970
of length 50,000, and so one way to model

929
00:48:08,100 --> 00:48:10,000
this is the multinomial distribution,

930
00:48:10,100 --> 00:48:12,500
but because there are two to the 50,000

931
00:48:12,620 --> 00:48:13,770
possible values for X,

932
00:48:13,890 --> 00:48:16,360
I would need two to the 50,000,

933
00:48:16,500 --> 00:48:20,710
but maybe -1 parameters, right?

934
00:48:20,830 --> 00:48:22,580
Because you have this sum to 1, right?

935
00:48:22,700 --> 00:48:23,580
So -1.

936
00:48:23,740 --> 00:48:26,260
And this is clearly way too many parameters

937
00:48:26,360 --> 00:48:29,840
to model using the multinomial distribution

938
00:48:29,950 --> 00:48:32,730
over all two to 50,000 possibilities.

939
00:48:32,850 --> 00:48:37,580
So in a Naive Bayes algorithm,

940
00:48:37,710 --> 00:48:43,810
we're going to make a very strong assumption

941
00:48:43,930 --> 00:48:47,640
on PFX given Y, and, in particular,

942
00:48:47,750 --> 00:48:49,170
I'm going to assume

943
00:48:49,290 --> 00:48:51,310
let me just say what it's called;

944
00:48:51,400 --> 00:48:52,690
then I'll write out what it means.

945
00:48:52,780 --> 00:48:53,770
I'm going to assume that

946
00:48:53,880 --> 00:49:07,980
the XI's are conditionally independent given Y, okay?

947
00:49:08,100 --> 00:49:09,140
Let me say what this means.

948
00:49:09,260 --> 00:49:15,200
So I have that PFX1, X2, up to X50,000,

949
00:49:15,320 --> 00:49:19,800
right, given the Y.

950
00:49:19,920 --> 00:49:22,330
By the chain rule of probability,

951
00:49:22,440 --> 00:49:28,240
this is PFX1 given Y times PFX2 given Y,

952
00:49:28,360 --> 00:49:34,000
X1 times PF I'll just put dot, dot, dot.

953
00:49:34,090 --> 00:49:41,400
I'll just write 1, 1 × dot, dot, dot up to,

954
00:49:41,560 --> 00:49:43,530
you know, well whatever.

955
00:49:43,630 --> 00:49:46,120
You get the idea, up to PFX50,000, okay?

956
00:49:46,240 --> 00:49:48,030
So this is the chain were of probability.

957
00:49:48,150 --> 00:49:49,310
This always holds.

958
00:49:49,430 --> 00:49:52,970
I've not made any assumption yet, and now,

959
00:49:53,090 --> 00:49:55,420
we're gonna meet what's called

960
00:49:55,550 --> 00:49:56,880
the Naive Bayes assumption,

961
00:49:57,000 --> 00:49:58,610
or this assumption that

962
00:49:58,720 --> 00:50:00,070
X defies a conditionally independent given Y.

963
00:50:00,180 --> 00:50:03,190
Going to assume that

964
00:50:03,310 --> 00:50:05,540
well, nothing changes for the first term,

965
00:50:05,630 --> 00:50:08,500
but I'm gonna assume that PFX3 given Y,

966
00:50:08,620 --> 00:50:12,380
X1 is equal to PFX2 given the Y.

967
00:50:12,500 --> 00:50:14,220
I'm gonna assume that

968
00:50:14,340 --> 00:50:17,690
that term's equal to PFX3 given the Y,

969
00:50:17,810 --> 00:50:23,940
and so on, up to PFX50,000 given Y, okay?

970
00:50:24,070 --> 00:50:26,540
Or just written more compactly,

971
00:50:26,650 --> 00:50:36,410
means assume that PFX1, PFX50,000 given Y is the product

972
00:50:36,550 --> 00:50:42,720
from I = 1 to 50,000 or PFXI given the Y, okay?

973
00:50:42,840 --> 00:50:47,260
And stating informally what this means is that

974
00:50:47,370 --> 00:50:48,630
I'm, sort of, assuming that

975
00:50:48,740 --> 00:50:51,020
so as you know the cost label Y,

976
00:50:51,160 --> 00:50:52,220
so as as you know whether

977
00:50:52,330 --> 00:50:53,360
this is spam or not spam,

978
00:50:53,500 --> 00:50:56,720
then knowing whether the word "A"

979
00:50:56,860 --> 00:51:00,740
appears in email does not affect the probability of

980
00:51:00,870 --> 00:51:04,910
whether the word "Ausworth" appears in the email,

981
00:51:05,040 --> 00:51:08,020
all right? And, in other words,

982
00:51:08,100 --> 00:51:10,180
there's assuming once you know whether

983
00:51:10,270 --> 00:51:11,910
an email is spam or not spam,

984
00:51:12,040 --> 00:51:13,900
then knowing whether other words

985
00:51:14,000 --> 00:51:16,140
appear in the email won't help you predict whether

986
00:51:16,250 --> 00:51:18,740
any other word appears in the email, okay?

987
00:51:18,840 --> 00:51:23,220
And, obviously, this assumption is false, right?

988
00:51:23,340 --> 00:51:24,940
This assumption can't possibly be true.

989
00:51:25,070 --> 00:51:27,130
I mean, if you see the word

990
00:51:27,250 --> 00:51:29,180
I don't know, CS229 in an email,

991
00:51:29,280 --> 00:51:31,390
you're much more likely to see my name in the email,

992
00:51:31,500 --> 00:51:32,550
or the TA's names,

993
00:51:32,550 --> 00:51:33,150
or whatever.

994
00:51:33,260 --> 00:51:35,360
So this assumption

995
00:51:35,490 --> 00:51:38,970
is normally just false under English, right,

996
00:51:39,080 --> 00:51:40,630
for normal written English,

997
00:51:40,760 --> 00:51:45,150
but it turns out that despite this assumption being,

998
00:51:45,250 --> 00:51:47,660
sort of, false in the literal sense,

999
00:51:47,780 --> 00:51:51,540
the Naive Bayes algorithm is, sort of,

1000
00:51:51,690 --> 00:51:53,980
an extremely effective algorithm for

1001
00:51:54,070 --> 00:51:55,360
classifying text documents

1002
00:51:55,360 --> 00:51:56,760
into spam or not spam,

1003
00:51:56,870 --> 00:51:59,840
for classifying your emails into different emails

1004
00:51:59,950 --> 00:52:01,590
for your automatic view,

1005
00:52:01,680 --> 00:52:02,630
for looking at web pages

1006
00:52:02,740 --> 00:52:04,680
and classifying whether this webpage

1007
00:52:04,790 --> 00:52:06,000
is trying to sell something or whatever.

1008
00:52:06,130 --> 00:52:08,600
It turns out, this assumption works very well

1009
00:52:08,680 --> 00:52:10,030
for classifying text documents

1010
00:52:10,170 --> 00:52:12,010
and for other applications too that

1011
00:52:12,120 --> 00:52:13,380
I'll talk a bit about later.

1012
00:52:15,600 --> 00:52:19,030
As a digression that'll make sense

1013
00:52:19,030 --> 00:52:20,640
only to some of you.

1014
00:52:20,770 --> 00:52:23,480
Let me just say that if you're

1015
00:52:23,570 --> 00:52:26,280
familiar with Bayesian network, say graphical models,

1016
00:52:26,370 --> 00:52:32,020
the Bayesian network associated

1017
00:52:32,120 --> 00:52:33,630
with this model looks like this,

1018
00:52:33,740 --> 00:52:35,490
and you're assuming that

1019
00:52:35,590 --> 00:52:37,020
this is random variable Y that

1020
00:52:37,130 --> 00:52:41,090
then generates X1, X2, through X50,000, okay?

1021
00:52:41,200 --> 00:52:43,130
If you've not seen the Bayes Net before,

1022
00:52:43,250 --> 00:52:44,240
if you don't know your graphical model,

1023
00:52:44,360 --> 00:52:45,320
just ignore this.

1024
00:52:45,420 --> 00:52:46,690
It's not important to our purposes,

1025
00:52:46,810 --> 00:52:48,420
but if you've seen it before,

1026
00:52:48,530 --> 00:52:49,520
that's what it will look like.

1027
00:52:49,600 --> 00:53:16,160
Okay. So the parameters of the model are

1028
00:53:16,270 --> 00:53:21,050
as follows with phi FI given Y = 1,

1029
00:53:21,160 --> 00:53:26,930
which is probably FX = 1 or XI = 1 given Y = 1,

1030
00:53:27,040 --> 00:53:39,480
phi I given Y = 0, and phi Y, okay?

1031
00:53:39,590 --> 00:53:44,080
So these are the parameters of the model, and,

1032
00:53:44,260 --> 00:53:49,110
therefore, to fit the parameters of the model,

1033
00:53:49,230 --> 00:53:55,980
you can write down the joint likelihood, right,

1034
00:53:56,110 --> 00:54:18,330
is equal to, as usual, okay?

1035
00:54:18,780 --> 00:54:20,140
So given the training sets,

1036
00:54:20,280 --> 00:54:28,000
you can write down the joint likelihood

1037
00:54:28,160 --> 00:54:43,910
of the parameters, and then

1038
00:54:44,020 --> 00:54:46,330
when you do maximum likelihood estimation,

1039
00:54:46,470 --> 00:54:48,870
you find that the maximum likelihood

1040
00:54:48,980 --> 00:54:50,430
estimate of the parameters are

1041
00:54:50,560 --> 00:54:52,580
they're really, pretty much, what you'd expect.

1042
00:54:52,740 --> 00:54:54,750
Maximum likelihood estimate

1043
00:54:54,850 --> 00:55:00,210
for phi J given Y = 1 is sum from I = 1 to M,

1044
00:55:00,310 --> 00:55:17,750
indicator XIJ = 1, YI = 1, okay?

1045
00:55:17,830 --> 00:55:22,550
And this is just a, I guess, stated more simply,

1046
00:55:22,660 --> 00:55:24,300
the numerator just says,

1047
00:55:24,390 --> 00:55:26,270
"Run for your entire training set,

1048
00:55:26,390 --> 00:55:27,510
some [inaudible] examples,

1049
00:55:27,630 --> 00:55:29,500
and count up the number of times

1050
00:55:29,610 --> 00:55:33,040
you saw word "j" in a piece of email for which

1051
00:55:33,150 --> 00:55:34,800
the label Y was equal to 1."

1052
00:55:34,910 --> 00:55:36,210
So, in other words,

1053
00:55:36,320 --> 00:55:37,490
look through all your spam emails

1054
00:55:37,590 --> 00:55:39,200
and count the number of emails in which

1055
00:55:39,320 --> 00:55:41,950
the word "j" appeared out of all your spam emails,

1056
00:55:42,080 --> 00:55:44,390
and the denominator is, you know,

1057
00:55:44,510 --> 00:55:47,150
sum from I = 1 to M, the number of spam.

1058
00:55:47,230 --> 00:55:48,980
The denominator is just the number of

1059
00:55:49,090 --> 00:55:50,400
spam emails you got.

1060
00:55:50,530 --> 00:55:55,620
And so this ratio is in all your spam emails

1061
00:55:55,790 --> 00:55:57,080
in your training set,

1062
00:55:57,180 --> 00:55:59,200
what fraction of these emails

1063
00:55:59,340 --> 00:56:03,550
did the word "j" appear in

1064
00:56:03,730 --> 00:56:04,590
did the, "j"

1065
00:56:04,690 --> 00:56:06,090
you wrote in your dictionary appear in?

1066
00:56:06,210 --> 00:56:07,780
And that's the maximum likelihood

1067
00:56:07,900 --> 00:56:11,150
estimate for the probability of seeing the word "j"

1068
00:56:11,250 --> 00:56:16,340
conditions on the piece of email being spam, okay?

1069
00:56:16,470 --> 00:56:22,570
And similar to your maximum likelihood

1070
00:56:22,690 --> 00:56:25,830
estimate for phi Y is pretty much

1071
00:56:25,940 --> 00:56:36,890
what you'd expect, right? Okay?

1072
00:56:37,010 --> 00:56:44,690
And so having estimated all these parameters,

1073
00:56:44,820 --> 00:56:49,590
when you're given a new piece of email that

1074
00:56:49,710 --> 00:56:51,600
you want to classify, you can then

1075
00:56:51,700 --> 00:56:55,470
compute PFY given X using Bayes rule, right?

1076
00:56:55,600 --> 00:56:57,040
Same as before

1077
00:56:57,160 --> 00:56:59,450
because together these parameters

1078
00:56:59,550 --> 00:57:03,260
gives you a model for PFX given Y and for PFY,

1079
00:57:03,360 --> 00:57:06,530
and by using Bayes rule, given these two terms,

1080
00:57:06,670 --> 00:57:09,980
you can compute PFX given Y,

1081
00:57:10,080 --> 00:57:13,630
and there's your spam classifier, okay?

1082
00:57:13,780 --> 00:57:16,320
Turns out we need

1083
00:57:16,430 --> 00:57:17,440
one more elaboration

1084
00:57:17,440 --> 00:57:18,260
to this idea,

1085
00:57:18,370 --> 00:57:19,370
but let me check

1086
00:57:19,470 --> 00:57:20,870
if there are questions about this so far.

1087
00:57:21,020 --> 00:57:26,620
Student:So does this model depend on the

1088
00:57:26,710 --> 00:57:27,890
number of inputs?

1089
00:57:27,980 --> 00:57:30,020
Instructor (Andrew Ng):What do you mean,

1090
00:57:30,130 --> 00:57:32,010
number of inputs, the number of features?

1091
00:57:32,130 --> 00:57:34,740
Student:No, number of samples.

1092
00:57:34,830 --> 00:57:35,790
Instructor (Andrew Ng):Well,

1093
00:57:35,870 --> 00:57:37,150
N is the number of training examples,

1094
00:57:37,250 --> 00:57:39,560
so this given M training examples,

1095
00:57:39,640 --> 00:57:41,230
this is the formula for the maximum likelihood

1096
00:57:41,320 --> 00:57:43,600
estimate of the parameters, right?

1097
00:57:43,670 --> 00:57:49,110
So other questions, does it make sense?

1098
00:57:49,220 --> 00:57:50,700
Or M is the number of training examples,

1099
00:57:50,790 --> 00:57:52,190
so when you have M training examples,

1100
00:57:52,280 --> 00:57:53,830
you plug them into this formula,

1101
00:57:53,920 --> 00:57:55,200
and that's how you compute

1102
00:57:55,280 --> 00:57:56,300
the maximum likelihood estimates.

1103
00:57:56,400 --> 00:57:59,480
Student:Is training examples

1104
00:57:59,580 --> 00:58:01,210
you mean M is the number of emails?

1105
00:58:01,310 --> 00:58:02,760
Instructor (Andrew Ng):Yeah, right. So, right.

1106
00:58:02,890 --> 00:58:05,030
So it's, kind of, your training set.

1107
00:58:05,120 --> 00:58:06,650
I would go through all the email

1108
00:58:06,760 --> 00:58:08,270
I've gotten in the last two months

1109
00:58:08,380 --> 00:58:10,720
and label them as spam or not spam,

1110
00:58:10,820 --> 00:58:14,310
and so you have I don't know, like,

1111
00:58:14,360 --> 00:58:17,910
a few hundred emails labeled as spam or not spam,

1112
00:58:18,020 --> 00:58:21,380
and that will comprise your training sets for

1113
00:58:21,450 --> 00:58:28,340
X1 and Y1 through XM, YM,

1114
00:58:28,480 --> 00:58:30,980
where X is one of those vectors representing

1115
00:58:31,100 --> 00:58:32,600
which words appeared in the email

1116
00:58:32,670 --> 00:58:34,490
and Y is 0, 1 depending on whether

1117
00:58:34,580 --> 00:58:35,230
they equal spam or

1118
00:58:35,230 --> 00:58:35,880
not spam, okay?

1119
00:58:36,090 --> 00:58:41,720
Student:So you are saying that

1120
00:58:41,810 --> 00:58:44,510
this model depends on the number of examples,

1121
00:58:44,600 --> 00:58:48,100
but the last model doesn't

1122
00:58:48,180 --> 00:58:49,660
depend on the models,

1123
00:58:49,780 --> 00:58:53,110
but your phi is the same for either one.

1124
00:58:53,230 --> 00:58:54,500
Instructor (Andrew Ng):They're different things,

1125
00:58:54,580 --> 00:58:56,270
right? There's the model which is

1126
00:58:56,380 --> 00:59:01,340
the modeling assumptions aren't made very well.

1127
00:59:01,420 --> 00:59:02,260
I'm assuming that

1128
00:59:02,380 --> 00:59:03,680
I'm making the Naive Bayes assumption.

1129
00:59:03,820 --> 00:59:07,470
So the probabilistic model is an assumption

1130
00:59:07,580 --> 00:59:09,770
on the joint distribution of X and Y.

1131
00:59:09,850 --> 00:59:12,660
That's what the model is, and then

1132
00:59:12,770 --> 00:59:14,530
I'm given a fixed number of training examples.

1133
00:59:14,620 --> 00:59:17,020
I'm given M training examples, and then it's,

1134
00:59:17,160 --> 00:59:19,070
like, after I'm given the training sets,

1135
00:59:19,180 --> 00:59:20,610
I'll then go in to write the maximum likelihood

1136
00:59:20,690 --> 00:59:22,310
estimate of the parameters, right?

1137
00:59:22,430 --> 00:59:24,220
So that's, sort of,

1138
00:59:24,290 --> 00:59:26,620
maybe we should take that offline for

1139
00:59:26,730 --> 00:59:29,390
yeah, ask a question?

1140
00:59:30,070 --> 00:59:31,540
Student:Then how would you do this, like,

1141
00:59:31,590 --> 00:59:32,800
if this [inaudible] didn't work?

1142
00:59:32,920 --> 00:59:34,640
Instructor (Andrew Ng):Say that again.

1143
00:59:34,730 --> 00:59:36,760
Student:How would you do it, say,

1144
00:59:36,870 --> 00:59:37,990
like the 50,000 words

1145
00:59:38,090 --> 00:59:39,160
Instructor (Andrew Ng):Oh, okay.

1146
00:59:39,260 --> 00:59:40,600
How to do this with the 50,000 words, yeah.

1147
00:59:40,690 --> 00:59:43,310
So it turns out this is, sort of,

1148
00:59:43,380 --> 00:59:44,520
a very practical question, really.

1149
00:59:44,640 --> 00:59:45,760
How do I count this list of words?

1150
00:59:45,850 --> 00:59:47,130
One common way to do this

1151
00:59:47,240 --> 00:59:51,040
is to actually find some way to count a list of words,

1152
00:59:51,120 --> 00:59:52,420
like go through all your emails,

1153
00:59:52,560 --> 00:59:53,770
go through all the

1154
00:59:53,890 --> 00:59:56,530
in practice, one common way to count a list of words

1155
00:59:56,650 --> 00:59:58,150
is to just take all the words that

1156
00:59:58,250 --> 00:59:59,440
appear in your training set.

1157
00:59:59,540 --> 01:00:00,930
That's one fairly common way to do it,

1158
01:00:01,050 --> 01:00:04,480
or if that turns out to be too many words,

1159
01:00:04,590 --> 01:00:06,090
you can take all words that appear

1160
01:00:06,180 --> 01:00:08,950
at least three times in your training set.

1161
01:00:09,010 --> 01:00:12,040
So words that you didn't even see three times

1162
01:00:12,130 --> 01:00:15,230
in the emails you got in the last two months,

1163
01:00:15,350 --> 01:00:16,710
you discard. So those are

1164
01:00:16,820 --> 01:00:18,720
I was talking about going through a dictionary,

1165
01:00:18,810 --> 01:00:20,140
which is a nice way of thinking about it,

1166
01:00:20,240 --> 01:00:21,180
but in practice,

1167
01:00:21,320 --> 01:00:23,090
you might go through your training set

1168
01:00:23,200 --> 01:00:24,330
and then just take the union of all the words

1169
01:00:24,430 --> 01:00:25,520
that appear in it.

1170
01:00:25,640 --> 01:00:28,300
In some of the tests I've even, by the way,

1171
01:00:28,400 --> 01:00:29,400
said select these features,

1172
01:00:29,520 --> 01:00:30,280
but this is one way

1173
01:00:30,400 --> 01:00:33,200
to think about creating your feature vector,

1174
01:00:33,320 --> 01:00:36,480
right, as zero and one values, okay?

1175
01:00:36,590 --> 01:00:42,850
Moving on, yeah. Okay. Ask a question?

1176
01:00:42,960 --> 01:00:44,730
Student:I'm getting, kind of,

1177
01:00:44,840 --> 01:00:46,790
confused on how you compute all those parameters.

1178
01:00:46,880 --> 01:00:49,590
Instructor (Andrew Ng):On how

1179
01:00:49,680 --> 01:00:50,710
I came up with the parameters?

1180
01:00:50,820 --> 01:00:51,840
Student:Correct.

1181
01:00:51,940 --> 01:00:53,630
Instructor (Andrew Ng):Let's see.

1182
01:00:53,760 --> 01:00:55,650
So in Naive Bayes, what I need to do

1183
01:00:55,780 --> 01:00:56,840
the question was

1184
01:00:56,930 --> 01:00:58,050
how did I come up with the parameters, right?

1185
01:00:58,160 --> 01:01:00,460
In Naive Bayes, I need to build a model

1186
01:01:00,590 --> 01:01:05,680
for PFX given Y and for PFY, right?

1187
01:01:05,820 --> 01:01:07,260
So this is, I mean,

1188
01:01:07,370 --> 01:01:08,590
in generative learning algorithms,

1189
01:01:08,680 --> 01:01:10,430
I need to come up with models for these.

1190
01:01:10,550 --> 01:01:12,340
So how'd I model PFY?

1191
01:01:12,490 --> 01:01:13,840
Well, I just those to model it

1192
01:01:13,950 --> 01:01:15,560
using a Bernoulli distribution,

1193
01:01:15,840 --> 01:01:21,010
and so PFY will be parameterized by that, all right?

1194
01:01:21,120 --> 01:01:22,020
Student:Okay.

1195
01:01:22,130 --> 01:01:22,960
Instructor (Andrew Ng):And then

1196
01:01:23,070 --> 01:01:24,500
how'd I model PFX given Y?

1197
01:01:24,610 --> 01:01:27,570
Well, let's keep changing bullets.

1198
01:01:27,680 --> 01:01:30,050
My model for PFX given Y

1199
01:01:30,180 --> 01:01:31,960
under the Naive Bayes assumption,

1200
01:01:32,070 --> 01:01:34,210
I assume that PFX given Y

1201
01:01:34,330 --> 01:01:36,150
is the product of these probabilities,

1202
01:01:36,280 --> 01:01:40,300
and so I'm going to need parameters to tell me

1203
01:01:40,440 --> 01:01:42,560
what's the probability of each word occurring,

1204
01:01:42,670 --> 01:01:44,450
you know,

1205
01:01:44,530 --> 01:01:45,590
of each word occurring or not occurring,

1206
01:01:45,690 --> 01:01:47,760
conditions on the email

1207
01:01:47,880 --> 01:01:50,830
being spam or not spam email, okay?

1208
01:01:50,940 --> 01:01:54,620
Student:How is that Bernoulli?

1209
01:01:54,740 --> 01:01:55,380
Instructor (Andrew Ng):Oh,

1210
01:01:55,530 --> 01:01:58,290
because X is either zero or one, right?

1211
01:01:58,400 --> 01:01:59,760
By the way I defined the feature vectors,

1212
01:01:59,870 --> 01:02:02,490
XI is either one or zero,

1213
01:02:02,590 --> 01:02:03,520
depending on whether

1214
01:02:03,650 --> 01:02:05,460
words I appear as in the email, right?

1215
01:02:05,570 --> 01:02:07,250
So by the way I define the feature vectors,

1216
01:02:07,370 --> 01:02:13,090
XI the XI is always zero or one.

1217
01:02:13,190 --> 01:02:16,260
So that by definition, if XI, you know,

1218
01:02:16,360 --> 01:02:17,960
is either zero or one, then it has to be

1219
01:02:18,020 --> 01:02:19,780
a Bernoulli distribution, right?

1220
01:02:19,890 --> 01:02:20,910
If XI would continue as

1221
01:02:21,030 --> 01:02:23,640
then you might model this as Gaussian

1222
01:02:23,750 --> 01:02:25,620
and say you end up like we did

1223
01:02:25,710 --> 01:02:26,760
in Gaussian discriminant analysis.

1224
01:02:26,870 --> 01:02:27,880
It's just that the way

1225
01:02:27,980 --> 01:02:29,160
I constructed my features for email,

1226
01:02:29,250 --> 01:02:30,680
XI is always binary value,

1227
01:02:30,780 --> 01:02:32,600
and so you end up with

1228
01:02:32,600 --> 01:02:34,420
a Bernoulli here, okay?

1229
01:02:34,540 --> 01:02:36,330
All right. I should move on.

1230
01:02:36,420 --> 01:02:44,940
So it turns out that this idea almost works.

1231
01:02:45,070 --> 01:02:47,070
Now, here's the problem.

1232
01:02:47,190 --> 01:02:50,070
So let's say you complete this class

1233
01:02:50,190 --> 01:02:52,830
and you start to do, maybe do the class project,

1234
01:02:52,950 --> 01:02:55,910
and you keep working on your class project for a bit,

1235
01:02:56,020 --> 01:02:57,270
and it becomes really good,

1236
01:02:57,390 --> 01:02:58,740
and you want to submit your class project

1237
01:02:58,850 --> 01:03:00,030
to a conference, right?

1238
01:03:00,110 --> 01:03:01,930
So, you know, around

1239
01:03:02,010 --> 01:03:04,230
I don't know, June every year

1240
01:03:04,570 --> 01:03:07,070
is the conference deadline for the next conference.

1241
01:03:07,160 --> 01:03:09,110
It's just the name of the conference;

1242
01:03:09,220 --> 01:03:10,460
it's an acronym.

1243
01:03:10,550 --> 01:03:13,920
And so maybe you send your project partners

1244
01:03:14,470 --> 01:03:15,740
or senior friends even, and say,

1245
01:03:15,830 --> 01:03:16,910
"Hey, let's work on a project

1246
01:03:17,010 --> 01:03:18,280
and submit it to the NIPS conference."

1247
01:03:18,380 --> 01:03:19,690
And so you're getting these emails

1248
01:03:19,790 --> 01:03:21,460
with the word "NIPS" in them,

1249
01:03:21,540 --> 01:03:22,950
which you've probably never seen before,

1250
01:03:23,060 --> 01:03:28,860
and so a piece of email

1251
01:03:28,940 --> 01:03:30,800
comes from your project partner,

1252
01:03:30,880 --> 01:03:31,920
and so you go,

1253
01:03:32,020 --> 01:03:34,470
"Let's send a paper to the NIPS conference."

1254
01:03:34,580 --> 01:03:39,430
And then your stamp classifier will say PFX

1255
01:03:39,580 --> 01:03:42,510
let's say NIPS is the 30,000th word

1256
01:03:42,630 --> 01:03:43,980
in your dictionary, okay?

1257
01:03:44,090 --> 01:03:48,190
So X30,000 given the 1,

1258
01:03:48,310 --> 01:03:53,830
given Y = 1 will be equal to 0.

1259
01:03:53,910 --> 01:03:55,700
That's the maximum likelihood of this, right?

1260
01:03:55,790 --> 01:03:57,190
Because you've never seen the word NIPS before

1261
01:03:57,300 --> 01:03:58,160
in your training set,

1262
01:03:58,270 --> 01:03:59,920
so maximum likelihood of the parameter is that

1263
01:04:00,070 --> 01:04:01,700
probably have seen the word NIPS is zero,

1264
01:04:01,820 --> 01:04:10,120
and, similarly, you know, in, I guess, non-spam mail,

1265
01:04:10,200 --> 01:04:11,510
the chance of seeing the word NIPS

1266
01:04:11,650 --> 01:04:15,490
is also estimated as zero.

1267
01:04:15,600 --> 01:04:36,770
So when your spam classifier goes to

1268
01:04:36,880 --> 01:04:38,850
compute PFY = 1 given X,

1269
01:04:38,960 --> 01:04:47,420
it will compute this right here × PFY over

1270
01:04:47,530 --> 01:05:09,100
well, all right.

1271
01:05:09,210 --> 01:05:12,980
And so you look at that terms, say,

1272
01:05:13,090 --> 01:05:17,010
this will be product from I = 1 to 50,000,

1273
01:05:17,130 --> 01:05:23,520
PFXI given Y, and one of those probabilities

1274
01:05:23,630 --> 01:05:24,850
will be equal to zero

1275
01:05:24,930 --> 01:05:32,000
because PFX30,000 = 1 given Y = 1 is equal to zero.

1276
01:05:32,090 --> 01:05:33,930
So you have a zero in this product,

1277
01:05:34,050 --> 01:05:35,450
and so the numerator is zero,

1278
01:05:35,590 --> 01:05:37,730
and in the same way,

1279
01:05:37,830 --> 01:05:39,980
it turns out the denominator will also be zero,

1280
01:05:40,080 --> 01:05:41,750
and so you end up with

1281
01:05:41,840 --> 01:05:44,550
actually all of these terms end up being zero.

1282
01:05:44,660 --> 01:05:49,040
So you end up with PFY = 1 given X is 0 over 0 + 0,

1283
01:05:49,130 --> 01:05:50,200
okay, which is undefined.

1284
01:05:50,310 --> 01:05:52,730
And the problem with this is that

1285
01:05:52,850 --> 01:05:58,230
it's just statistically a bad idea to say that

1286
01:05:58,380 --> 01:06:03,970
PFX30,000 given Y is 0, right?

1287
01:06:04,090 --> 01:06:05,660
Just because you haven't seen the word NIPS

1288
01:06:05,750 --> 01:06:07,610
in your last two months worth of email,

1289
01:06:07,690 --> 01:06:10,220
it's also statistically not sound to say that,

1290
01:06:10,330 --> 01:06:11,730
therefore, the chance of ever

1291
01:06:11,810 --> 01:06:14,250
seeing this word is zero, right?

1292
01:06:14,370 --> 01:06:24,810
And so is this idea that just

1293
01:06:24,910 --> 01:06:26,220
because you haven't seen something before,

1294
01:06:26,330 --> 01:06:29,650
that may mean that that event is unlikely,

1295
01:06:29,760 --> 01:06:31,460
but it doesn't mean that it's impossible,

1296
01:06:31,600 --> 01:06:32,620
and just saying that

1297
01:06:32,750 --> 01:06:34,160
if you've never seen the word NIPS before,

1298
01:06:34,290 --> 01:06:36,220
then it is impossible to ever see the word NIPS

1299
01:06:36,320 --> 01:06:38,290
in future emails; the chance of that is just zero.

1300
01:06:38,410 --> 01:06:41,530
So we're gonna fix this,

1301
01:06:41,650 --> 01:06:52,080
and to motivate the fix I'll talk about

1302
01:06:52,200 --> 01:06:56,430
the example we're gonna use is let's say that

1303
01:06:56,530 --> 01:06:59,800
you've been following the Stanford basketball team

1304
01:06:59,920 --> 01:07:02,560
for all of their away games, and been, sort of,

1305
01:07:02,650 --> 01:07:05,510
tracking their wins and losses to gather statistics,

1306
01:07:05,620 --> 01:07:07,060
and, maybe I don't know,

1307
01:07:07,160 --> 01:07:08,390
form a betting pool about whether

1308
01:07:08,510 --> 01:07:09,450
they're likely to win or

1309
01:07:09,460 --> 01:07:10,400
lose the next game, okay?

1310
01:07:10,500 --> 01:07:19,640
So these are some of the statistics.

1311
01:07:19,730 --> 01:07:26,010
So on, I guess, the 8th of February last season they

1312
01:07:26,090 --> 01:07:30,190
played Washington State, and they did not win.

1313
01:07:30,290 --> 01:07:37,380
On the 11th of February,

1314
01:07:37,490 --> 01:07:45,090
they play Washington, 22nd they played USC,

1315
01:07:45,210 --> 01:07:56,160
played UCLA, played USC again,

1316
01:07:56,270 --> 01:08:06,300
and now you want to estimate what's the chance

1317
01:08:06,390 --> 01:08:08,810
that they'll win or lose against Louisville, right?

1318
01:08:08,910 --> 01:08:13,210
So find the four guys last year or five times

1319
01:08:13,290 --> 01:08:14,820
and they weren't good in their away games,

1320
01:08:14,930 --> 01:08:16,420
but it seems awfully harsh to say that

1321
01:08:16,520 --> 01:08:20,250
so it seems awfully harsh to say there's zero chance

1322
01:08:21,130 --> 01:08:22,630
that they'll win in the last in the 5th game.

1323
01:08:22,700 --> 01:08:39,190
So here's the idea behind Laplace smoothing

1324
01:08:39,240 --> 01:08:46,000
which is that we're estimate the probably

1325
01:08:46,120 --> 01:08:47,870
of Y being equal to one, right?

1326
01:08:48,020 --> 01:08:52,150
Normally, the maximum likelihood [inaudible]

1327
01:08:52,320 --> 01:08:58,270
is the number of ones divided by the number

1328
01:08:58,340 --> 01:09:04,570
of zeros plus the number of ones, okay?

1329
01:09:04,680 --> 01:09:07,380
I hope this informal notation makes sense, right?

1330
01:09:07,470 --> 01:09:08,970
Knowing the maximum likelihood

1331
01:09:09,060 --> 01:09:10,200
estimate for, sort of,

1332
01:09:10,310 --> 01:09:11,740
a win or loss for Bernoulli random variable

1333
01:09:11,860 --> 01:09:17,050
is just the number of ones you saw divided

1334
01:09:17,180 --> 01:09:18,670
by the total number of examples.

1335
01:09:18,790 --> 01:09:20,420
So it's the number of zeros you saw

1336
01:09:20,500 --> 01:09:21,510
plus the number of ones you saw.

1337
01:09:21,630 --> 01:09:24,840
So in the Laplace Smoothing we're going to

1338
01:09:24,940 --> 01:09:27,380
just take each of these terms,

1339
01:09:27,470 --> 01:09:29,760
the number of ones and, sort of,

1340
01:09:29,860 --> 01:09:30,590
add one to that,

1341
01:09:30,710 --> 01:09:32,140
the number of zeros and add one to that,

1342
01:09:32,270 --> 01:09:33,660
the number of ones and add one to that,

1343
01:09:33,770 --> 01:09:35,390
and so in our example,

1344
01:09:35,500 --> 01:09:39,330
instead of estimating the probability of

1345
01:09:39,330 --> 01:09:40,330
winning the next game to be 0 ÷ 5 + 0,

1346
01:09:44,380 --> 01:09:47,020
we'll add one to all of these counts,

1347
01:09:47,130 --> 01:09:52,100
and so we say that the chance of their winning

1348
01:09:52,250 --> 01:09:54,790
the next game is 1/7th, okay?

1349
01:09:54,900 --> 01:09:57,040
Which is that having seen them lose, you know,

1350
01:09:57,100 --> 01:09:58,200
five away games in a row,

1351
01:09:58,310 --> 01:09:59,560
we aren't terribly

1352
01:09:59,670 --> 01:10:00,820
we don't think it's terribly likely

1353
01:10:00,930 --> 01:10:02,130
they'll win the next game,

1354
01:10:02,250 --> 01:10:03,740
but at least we're not saying it's impossible.

1355
01:10:03,880 --> 01:10:06,980
As a historical side note,

1356
01:10:07,110 --> 01:10:09,730
the Laplace actually came up with the method.

1357
01:10:09,840 --> 01:10:11,370
It's called the Laplace smoothing after him.

1358
01:10:11,480 --> 01:10:20,190
When he was trying to estimate the probability that

1359
01:10:20,340 --> 01:10:21,730
the sun will rise tomorrow,

1360
01:10:21,810 --> 01:10:24,100
and his rationale was in a lot of days now,

1361
01:10:24,210 --> 01:10:25,110
we've seen the sun rise,

1362
01:10:25,230 --> 01:10:27,070
but that doesn't mean we can be absolutely certain

1363
01:10:27,180 --> 01:10:28,480
the sun will rise tomorrow.

1364
01:10:28,570 --> 01:10:30,620
He was using this to estimate the probability that

1365
01:10:30,730 --> 01:10:31,720
the sun will rise tomorrow.

1366
01:10:31,820 --> 01:10:33,290
This is, kind of, cool.

1367
01:10:33,400 --> 01:10:37,590
So, and more generally,

1368
01:10:37,690 --> 01:10:54,690
if Y takes on K possible of values,

1369
01:10:54,730 --> 01:10:57,220
if you're trying to estimate the parameter

1370
01:10:57,330 --> 01:11:03,040
of the multinomial, then you estimate PFY = 1.

1371
01:11:03,120 --> 01:11:06,200
Let's see.

1372
01:11:06,320 --> 01:11:07,730
So the maximum likelihood estimate

1373
01:11:07,840 --> 01:11:10,170
will be Sum from J = 1 to M,

1374
01:11:10,170 --> 01:11:11,170
indicator YI = J ÷ M, right?

1375
01:11:19,650 --> 01:11:21,020
That's the maximum likelihood estimate

1376
01:11:21,130 --> 01:11:25,060
of a multinomial probability of Y being equal to

1377
01:11:25,170 --> 01:11:29,290
oh, excuse me, Y = J. All right.

1378
01:11:29,370 --> 01:11:30,730
That's the maximum likelihood estimate

1379
01:11:30,840 --> 01:11:31,930
for the probability of Y = J,

1380
01:11:32,040 --> 01:11:35,120
and so when you apply Laplace smoothing to that,

1381
01:11:37,150 --> 01:11:38,790
you add one to the numerator,

1382
01:11:38,890 --> 01:11:41,750
and add K to the denominator,

1383
01:11:41,790 --> 01:11:46,680
if Y can take up K possible values, okay?

1384
01:11:46,810 --> 01:12:09,840
So for Naive Bayes, what that gives us is

1385
01:12:09,980 --> 01:12:39,180
shoot. Right?

1386
01:12:39,290 --> 01:12:40,630
So that was the maximum likelihood estimate,

1387
01:12:40,710 --> 01:12:41,880
and what you end up doing

1388
01:12:41,960 --> 01:12:45,290
is adding oneto the numerator

1389
01:12:45,370 --> 01:12:46,980
and adding two to the denominator,

1390
01:12:47,060 --> 01:12:49,050
and this solves the problem

1391
01:12:49,150 --> 01:12:50,540
of the zero probabilities,

1392
01:12:50,650 --> 01:12:52,250
and when your friend sends you email

1393
01:12:52,360 --> 01:12:53,500
about the NIPS conference,

1394
01:12:53,610 --> 01:12:59,690
your spam filter will still be able

1395
01:12:59,810 --> 01:13:04,080
to make a meaningful prediction, all right?

1396
01:13:04,210 --> 01:13:14,060
Okay. Shoot. Any questions about this? Yeah?

1397
01:13:14,140 --> 01:13:15,290
Student:So that's what doesn't makes sense

1398
01:13:15,390 --> 01:13:16,940
because, for instance,

1399
01:13:17,020 --> 01:13:23,590
if you take the games on the right,

1400
01:13:23,700 --> 01:13:25,950
it's liberal assumptions that

1401
01:13:26,090 --> 01:13:31,420
the probability of winning is very close to zero,

1402
01:13:31,530 --> 01:13:32,520
so, I mean,

1403
01:13:32,610 --> 01:13:35,810
the prediction should be equal to PF, 0.

1404
01:13:35,910 --> 01:13:36,680
Instructor (Andrew Ng):Right.

1405
01:13:36,770 --> 01:13:37,430
I would say that

1406
01:13:37,540 --> 01:13:38,480
in this case the prediction is 1/7th, right?

1407
01:13:38,570 --> 01:13:39,620
We don't have a lot of

1408
01:13:39,740 --> 01:13:41,220
if you see somebody lose five games in a row,

1409
01:13:41,310 --> 01:13:43,510
you may not have a lot of faith in them,

1410
01:13:43,610 --> 01:13:45,730
but as an extreme example,

1411
01:13:45,850 --> 01:13:48,810
suppose you saw them lose one game, right?

1412
01:13:48,920 --> 01:13:50,350
It's just not reasonable to say that

1413
01:13:50,450 --> 01:13:52,180
the chances of winning the next game is zero,

1414
01:13:52,290 --> 01:13:54,510
but that's what maximum likelihood estimate will say.

1415
01:13:54,620 --> 01:13:55,440
Student:Yes.

1416
01:13:55,540 --> 01:13:56,770
Instructor (Andrew Ng):And

1417
01:13:56,870 --> 01:13:58,590
Student:In such a case anywhere

1418
01:13:58,590 --> 01:13:59,590
the learning algorithm [inaudible] or –

1419
01:14:03,690 --> 01:14:07,220
Instructor (Andrew Ng):So some questions of,

1420
01:14:07,340 --> 01:14:09,350
you know, given just five training examples,

1421
01:14:09,430 --> 01:14:11,530
what's a reasonable estimate for the chance

1422
01:14:11,650 --> 01:14:15,380
of winning the next game, and 1/7th is, I think,

1423
01:14:15,490 --> 01:14:16,460
is actually pretty reasonable.

1424
01:14:16,570 --> 01:14:17,930
It's less than 1/5th for instance.

1425
01:14:18,050 --> 01:14:19,160
We're saying the chances

1426
01:14:19,250 --> 01:14:20,890
of winning the next game is less than 1/5th.

1427
01:14:20,990 --> 01:14:23,730
It turns out, under a certain set of assumptions

1428
01:14:24,700 --> 01:14:26,120
under a certain set of Bayesian assumptions

1429
01:14:26,210 --> 01:14:27,410
about the prior and posterior,

1430
01:14:27,500 --> 01:14:30,240
this Laplace smoothing actually

1431
01:14:30,240 --> 01:14:31,240
I won't go into –

1432
01:14:30,330 --> 01:14:31,610
gives the optimal estimate,

1433
01:14:31,720 --> 01:14:33,650
in a certain sense I won't go into of

1434
01:14:33,780 --> 01:14:35,750
what's the chance of winning the next game,

1435
01:14:35,870 --> 01:14:37,270
and so under a certain assumption

1436
01:14:37,370 --> 01:14:40,180
about the Bayesian prior on the parameter.

1437
01:14:40,300 --> 01:14:41,670
So I don't know.

1438
01:14:41,730 --> 01:14:43,090
It actually seems like

1439
01:14:43,190 --> 01:14:44,370
a pretty reasonable assumption to me.

1440
01:14:44,480 --> 01:14:47,380
Although, I should say, it actually turned out

1441
01:14:47,500 --> 01:14:50,920
No, I'm just being mean.

1442
01:14:51,030 --> 01:14:53,060
We actually are a pretty good basketball team,

1443
01:14:53,180 --> 01:14:54,510
but I chose a losing streak

1444
01:14:54,610 --> 01:14:59,800
because it's funnier that way. Let's see. Shoot.

1445
01:14:59,900 --> 01:15:00,930
Does someone want to

1446
01:15:01,040 --> 01:15:03,330
are there other questions about this?

1447
01:15:03,440 --> 01:15:10,010
No, yeah. Okay. So there's more that

1448
01:15:10,100 --> 01:15:11,770
I want to say about Naive Bayes,

1449
01:15:11,850 --> 01:15:14,210
but we'll do that in the next lecture.

1450
01:15:14,330 --> 01:15:16,390
So let's wrap it for today.

