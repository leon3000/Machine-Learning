1
00:00:24,230 --> 00:00:26,370
So what I want to do today in this

2
00:00:26,510 --> 00:00:30,390
lecture is talk a little bit more about learning theory.

3
00:00:30,570 --> 00:00:32,220
In particular, I'll talk about VC dimension

4
00:00:32,970 --> 00:00:37,730
and building on the issues of bias variance

5
00:00:37,900 --> 00:00:39,660
tradeoffs of under fitting and over fitting;

6
00:00:39,840 --> 00:00:42,030
that we've been seeing in the previous lecture,

7
00:00:42,190 --> 00:00:43,380
and then we'll see in this one.

8
00:00:43,600 --> 00:00:45,710
I then want to talk about model selection

9
00:00:45,860 --> 00:00:49,110
algorithms for automatically making

10
00:00:49,280 --> 00:00:52,890
decisions for this bias variance tradeoff,

11
00:00:53,040 --> 00:00:54,840
that we started to talk about in the previous lecture.

12
00:00:55,060 --> 00:00:56,970
And depending on how much time,

13
00:00:57,160 --> 00:00:57,910
I actually may not

14
00:00:58,060 --> 00:00:59,330
get to Bayesian, [inaudible].

15
00:00:59,470 --> 00:01:01,220
But if I don't get to this today,

16
00:01:01,410 --> 00:01:03,910
I'll get to this in next week's lecture.

17
00:01:07,300 --> 00:01:10,540
To recap: the result we proved

18
00:01:10,770 --> 00:01:11,920
at the previous lecture

19
00:01:12,100 --> 00:01:15,940
was that if you have a finite hypothesis class

20
00:01:16,120 --> 00:01:18,410
if h is a set of k hypotheses,

21
00:01:24,130 --> 00:01:26,820
and suppose you have some fixed parameters,

22
00:01:26,890 --> 00:01:41,630
gamma and delta, then in order to guarantee that this holds

23
00:01:41,790 --> 00:01:49,990
we're probability at least one minus delta.

24
00:01:51,230 --> 00:02:02,970
It suffices that n is greater and equal to that; okay?

25
00:02:04,300 --> 00:02:06,940
And using big-O notations,

26
00:02:07,630 --> 00:02:08,770
just learning dropped constants,

27
00:02:08,990 --> 00:02:14,090
I can also write this as that; okay?

28
00:02:14,490 --> 00:02:16,140
So just to quickly remind you of what all

29
00:02:16,330 --> 00:02:17,660
of the notation means,

30
00:02:18,180 --> 00:02:20,420
we talked about empirical risk minimization,

31
00:02:21,200 --> 00:02:23,260
which was the simplified modern

32
00:02:23,450 --> 00:02:27,620
machine learning that has a hypothesis class of script h.

33
00:02:28,180 --> 00:02:30,530
And what the empirical risk minimization-learning

34
00:02:30,720 --> 00:02:33,220
algorithm does is it just chooses the hypothesis

35
00:02:33,530 --> 00:02:37,050
that attains the smallest error on the training set.

36
00:02:37,680 --> 00:02:40,210
And so this symbol, epsilon,

37
00:02:40,390 --> 00:02:42,460
just denoted generalization error; right?

38
00:02:42,630 --> 00:02:45,620
This is the probability of a hypothesis h

39
00:02:45,800 --> 00:02:47,250
[inaudible] misclassifying a new

40
00:02:47,430 --> 00:02:49,030
example drawn from the same

41
00:02:49,190 --> 00:02:50,630
distribution as the training set.

42
00:02:50,970 --> 00:02:57,840
And so this says that in order to guarantee that the

43
00:03:03,280 --> 00:03:07,820
generalization error of the hypothesis h [inaudible] output

44
00:03:08,780 --> 00:03:10,760
by empirical risk minimization that this is less and equal

45
00:03:10,910 --> 00:03:13,080
to the best possible generalization error

46
00:03:13,730 --> 00:03:17,820
use it in your hypothesis class plus two times gamma

47
00:03:18,050 --> 00:03:19,660
two times this error threshold.

48
00:03:19,990 --> 00:03:21,410
We want to guarantee that this holds a

49
00:03:21,570 --> 00:03:23,430
probability at least one minus delta.

50
00:03:24,310 --> 00:03:28,520
We show that it suffices for your training set size m

51
00:03:29,070 --> 00:03:31,100
to be greater than equal to this; okay?

52
00:03:31,300 --> 00:03:34,160
One over two gamma square log two k over delta;

53
00:03:34,350 --> 00:03:36,790
where again, k is the size of your hypothesis class.

54
00:03:37,270 --> 00:03:41,130
And so this is some complexity result

55
00:03:41,340 --> 00:03:43,120
because it gives us a bound in the number of

56
00:03:43,290 --> 00:03:45,400
training examples we need in order to

57
00:03:45,640 --> 00:03:49,280
give a guarantee on something on the error; okay?

58
00:03:49,480 --> 00:03:51,600
So this is a sample complexity result.

59
00:03:51,880 --> 00:03:55,710
So what I want to do now is

60
00:03:55,930 --> 00:03:58,510
take this result, and try to generalize it

61
00:03:58,730 --> 00:04:02,140
to the case of infinite hypothesis classes.

62
00:04:02,300 --> 00:04:05,100
So here, we said that the set script h is

63
00:04:05,360 --> 00:04:07,780
sort of just k specific functions,

64
00:04:08,090 --> 00:04:09,950
when you want to use a model

65
00:04:10,140 --> 00:04:11,320
like logistic regression,

66
00:04:11,500 --> 00:04:13,480
which is actually parameterized by real numbers.

67
00:04:13,790 --> 00:04:16,180
So I'm actually first going to give an argument

68
00:04:16,340 --> 00:04:18,150
that's sort of formally broken

69
00:04:18,390 --> 00:04:20,080
just sort of technically somewhat broken,

70
00:04:20,320 --> 00:04:21,800
but conveys useful intuition.

71
00:04:22,120 --> 00:04:24,310
And then I'll give the more correct argument,

72
00:04:24,590 --> 00:04:26,000
but without proving.

73
00:04:26,150 --> 00:04:27,680
It's as if, full proof is somewhat involved.

74
00:04:27,850 --> 00:04:29,590
So here's a somewhat broken argument.

75
00:04:29,820 --> 00:04:31,430
Let's say I want to apply this

76
00:04:31,640 --> 00:04:33,590
result analyzing logistic regression.

77
00:04:35,280 --> 00:04:40,630
So let's say your hypothesis class is

78
00:04:40,840 --> 00:04:43,520
because of all linear division boundaries; right?

79
00:04:43,710 --> 00:04:58,480
So say script h is parameterized by d real numbers; okay?

80
00:04:58,730 --> 00:05:01,120
So for example, if you're applying logistic

81
00:05:01,300 --> 00:05:03,640
regression with over [inaudible],

82
00:05:03,810 --> 00:05:04,880
then d would be endless

83
00:05:05,080 --> 00:05:06,330
one with logistic regression

84
00:05:06,480 --> 00:05:07,960
to find the linear position boundary,

85
00:05:08,450 --> 00:05:11,070
parameterized by endless one real numbers.

86
00:05:11,840 --> 00:05:15,290
When you think about how your hypothesis class

87
00:05:15,460 --> 00:05:17,230
is really represented in a computer

88
00:05:17,410 --> 00:05:20,970
computers use zero one bits to represent real numbers.

89
00:05:21,310 --> 00:05:25,900
And so if you use like a normal standard computer,

90
00:05:26,200 --> 00:05:27,580
it normally will represent real numbers

91
00:05:27,790 --> 00:05:30,390
by what's called double position floating point numbers.

92
00:05:30,650 --> 00:05:33,320
And what that means is that each real number is

93
00:05:33,500 --> 00:05:37,030
represented by or a 64-bit representation; right?

94
00:05:37,240 --> 00:05:40,490
So really you know what floating point is in a computer.

95
00:05:40,690 --> 00:05:42,090
So a 64-bit floating point is what

96
00:05:42,300 --> 00:05:44,230
almost all of us use routinely.

97
00:05:44,460 --> 00:05:46,580
And so this parameterized by d real numbers,

98
00:05:46,810 --> 00:05:53,250
that's really as if it's parameterized by 64 times d bits.

99
00:05:54,170 --> 00:05:55,840
Computers can't represent real numbers.

100
00:05:56,030 --> 00:05:58,220
They only represent used to speed things.

101
00:05:58,420 --> 00:06:03,710
And so the size of your hypothesis

102
00:06:03,900 --> 00:06:05,860
class in your computer representation

103
00:06:06,200 --> 00:06:10,050
you have 64 times d bits that you can flip.

104
00:06:10,430 --> 00:06:14,110
And so the number of possible values for your 62 to 64

105
00:06:14,290 --> 00:06:19,950
d bits is really just to the power of 64 d; okay?

106
00:06:21,080 --> 00:06:22,150
Because that's the number of ways

107
00:06:22,330 --> 00:06:24,790
you can flip the 64 d bits.

108
00:06:25,970 --> 00:06:30,620
And so this is why it's important that

109
00:06:30,780 --> 00:06:32,380
we that we had log k there; right?

110
00:06:32,560 --> 00:06:36,000
So k is therefore, to the 64 d.

111
00:06:36,240 --> 00:06:39,140
And if I plug it into this equation over here,

112
00:06:40,290 --> 00:06:44,960
what you find is that in order to get this sort of guarantee,

113
00:06:50,020 --> 00:06:57,010
it suffices that m is great and equal to on the order of

114
00:06:57,620 --> 00:07:00,470
one of the gamma square log

115
00:07:00,800 --> 00:07:11,600
it's just a 64 d over delta, which is that; okay?

116
00:07:13,570 --> 00:07:14,980
So just to be clear,

117
00:07:15,300 --> 00:07:19,110
in order to guarantee that there's only one,

118
00:07:19,110 --> 00:07:20,110
instead of the same complexity result as we had before –so

119
00:07:21,620 --> 00:07:25,290
the question is: suppose, you want a guarantee that a

120
00:07:25,490 --> 00:07:28,510
hypotheses returned by empirical risk minimization will

121
00:07:28,850 --> 00:07:31,850
have a generalization error that's within two gamma or the

122
00:07:32,030 --> 00:07:34,360
best hypotheses in your hypotheses class.

123
00:07:35,030 --> 00:07:37,290
Then what this result suggests is that,

124
00:07:37,820 --> 00:07:38,680
you know, in order to give that

125
00:07:38,860 --> 00:07:40,450
sort of error bound guarantee,

126
00:07:40,850 --> 00:07:43,340
it suffices that m is greater and equal to this.

127
00:07:43,510 --> 00:07:44,580
In other words,

128
00:07:44,750 --> 00:07:47,020
that your number of training examples has to be on the

129
00:07:47,210 --> 00:07:50,560
order of d over gamma square; 10, 12, 1 over delta. Okay?

130
00:07:52,550 --> 00:07:55,460
And the intuition that this conveys is actually,

131
00:07:55,620 --> 00:07:56,920
roughly right.

132
00:07:57,090 --> 00:07:58,000
This says,

133
00:07:58,160 --> 00:07:59,210
that the number of training examples

134
00:07:59,350 --> 00:08:02,000
you need is roughly linear in the number of parameters

135
00:08:02,180 --> 00:08:04,110
of your hypothesis class.

136
00:08:04,480 --> 00:08:06,530
That m has [inaudible] on the order of something linear,

137
00:08:06,720 --> 00:08:08,630
That intuition is actually, roughly right.

138
00:08:09,330 --> 00:08:10,820
I'll say more about this later.

139
00:08:22,290 --> 00:08:24,280
This result is clearly, slightly broken,

140
00:08:24,440 --> 00:08:26,090
in the sense that it relies on a 64-bit

141
00:08:26,260 --> 00:08:28,360
representation of 14-point numbers.

142
00:08:28,640 --> 00:08:31,840
So let me actually go ahead and outline the

143
00:08:32,200 --> 00:08:35,150
"right way" to show this more formally; all right?

144
00:08:35,330 --> 00:08:37,220
And it turns out the "right way" to

145
00:08:37,400 --> 00:08:39,830
show this more formally involves a much longer

146
00:08:40,280 --> 00:08:44,480
because the proof is extremely involved,

147
00:08:44,660 --> 00:08:46,180
so I'm just actually going to state the result,

148
00:08:46,390 --> 00:08:47,460
and not prove it.

149
00:08:47,660 --> 00:08:49,470
Farther proof be a source of learning theory balance,

150
00:08:49,660 --> 00:08:51,640
infinite hypothesis classes.

151
00:08:52,030 --> 00:08:55,600
This definition

152
00:08:56,500 --> 00:08:59,470
given a set of d points,

153
00:09:18,540 --> 00:09:29,920
we say, a hypothesis class h shatters the set s,

154
00:09:30,650 --> 00:09:35,680
if h can realize

155
00:09:35,860 --> 00:09:47,050
any labeling on it; okay?

156
00:09:47,530 --> 00:09:49,510
And what I mean by realizing any labeling on it

157
00:09:49,860 --> 00:09:51,660
the informal way of thinking about this is:

158
00:09:53,150 --> 00:09:55,230
if a hypothesis class has shattered the set s,

159
00:09:55,400 --> 00:09:57,350
what that means is that I can take these d points,

160
00:09:58,380 --> 00:10:00,780
and I can associate these d points with

161
00:10:00,950 --> 00:10:03,840
any caught set of labels y; right?

162
00:10:04,150 --> 00:10:07,640
So choose any set of labeling y for each of these d points.

163
00:10:09,940 --> 00:10:12,460
And if your hypothesis class shatters s,

164
00:10:12,710 --> 00:10:15,580
then that means that there will be a hypothesis

165
00:10:16,110 --> 00:10:20,140
that labels those d examples perfectly; okay?

166
00:10:20,310 --> 00:10:21,400
That's what shattering means.

167
00:10:21,580 --> 00:10:23,730
So let me just illustrate those in an example.

168
00:10:23,920 --> 00:10:25,380
So let's say h is the class of

169
00:10:25,560 --> 00:10:32,330
all linear classifiers into e,

170
00:10:35,490 --> 00:10:39,980
and let's say that s is this [inaudible]

171
00:10:41,010 --> 00:10:43,890
comprising two points; okay?

172
00:10:44,080 --> 00:10:47,020
So there are four possible labelings that

173
00:10:47,180 --> 00:10:48,560
computes with these two points.

174
00:10:48,730 --> 00:10:50,920
You can choose to label both positive;

175
00:10:51,170 --> 00:10:55,040
one positive, one negative, one negative, one positive

176
00:10:56,350 --> 00:10:58,480
or you can label both of them negative.

177
00:10:59,090 --> 00:11:02,440
And if the hypothesis class h classed

178
00:11:02,610 --> 00:11:04,670
all linear classifiers into the then,

179
00:11:04,890 --> 00:11:06,350
for each of these training sets,

180
00:11:06,530 --> 00:11:10,100
I can sort of find a linear classifier that

181
00:11:10,380 --> 00:11:13,990
attains zero training error on each of these.

182
00:11:14,230 --> 00:11:15,720
Then on all possible labelings

183
00:11:15,880 --> 00:11:17,800
of this set of two points.

184
00:11:17,980 --> 00:11:21,660
And so I'll say that the hypothesis class script

185
00:11:21,820 --> 00:11:27,240
h shatters this set s of two points; okay?

186
00:11:27,480 --> 00:11:39,860
One more example show you a larger example.

187
00:11:40,390 --> 00:11:43,790
Suppose my set s is now this set of three points; right?

188
00:11:43,970 --> 00:11:45,990
Then, I now have eight possible

189
00:11:46,190 --> 00:12:03,250
labelings for these three points; okay?

190
00:12:11,180 --> 00:12:12,470
And so for these three points,

191
00:12:12,650 --> 00:12:14,340
I now have eight possible labelings.

192
00:12:14,620 --> 00:12:18,090
And once again, I can for each of these labelings,

193
00:12:18,270 --> 00:12:20,830
I can find the hypothesis in the

194
00:12:21,020 --> 00:12:24,520
hypothesis class that labels these examples correctly.

195
00:12:25,560 --> 00:12:29,020
And so once again, I see that by definition, say,

196
00:12:29,190 --> 00:12:33,280
that my hypothesis class also shatters this set s.

197
00:12:33,940 --> 00:12:35,770
Instructor (Andrew Ng):And then that that terminology

198
00:12:35,960 --> 00:12:37,710
h can realize any labeling on s.

199
00:12:37,920 --> 00:12:39,240
That's obviously [inaudible].

200
00:12:39,460 --> 00:12:41,240
Give it any set of labels and

201
00:12:41,550 --> 00:12:42,640
you can find a hypothesis that

202
00:12:42,820 --> 00:12:44,160
perfectly separates the positive

203
00:12:44,350 --> 00:12:47,000
and negative examples; okay?

204
00:12:47,290 --> 00:12:52,310
So how about this set?

205
00:12:57,440 --> 00:13:00,380
Suppose s is now this set of four points, then,

206
00:13:01,030 --> 00:13:02,350
you know, there are lots of labels.

207
00:13:02,730 --> 00:13:04,580
There are now 16 labelings we can choose on this;

208
00:13:04,800 --> 00:13:07,440
right?That's one for instance, and this is another one;

209
00:13:08,470 --> 00:13:12,270
right? And so I can realize some labelings. But there's no

210
00:13:12,470 --> 00:13:15,770
linear division boundary that can realize this labeling, and

211
00:13:15,960 --> 00:13:19,170
so h does not shatter this set of four points; okay?

212
00:13:20,120 --> 00:13:22,870
And I'm not really going to prove it here,

213
00:13:23,030 --> 00:13:26,340
but it turns out that you can show that in two dimensions,

214
00:13:26,690 --> 00:13:28,630
there is no set of four points that

215
00:13:28,890 --> 00:13:33,380
the class of all linear classifiers can shatter; okay?

216
00:13:36,770 --> 00:13:47,090
So here's another definition.

217
00:13:48,720 --> 00:13:51,420
When I say that the well, it's called the VC dimension.

218
00:13:51,690 --> 00:13:53,190
These two people,

219
00:13:53,380 --> 00:13:55,580
Vapnik and Chervonenkis

220
00:14:06,750 --> 00:14:08,210
so given a hypothesis class,

221
00:14:10,120 --> 00:14:12,710
the Vapnik and Chervonenkis dimension of h,

222
00:14:14,180 --> 00:14:18,190
which we usually write as VC of script h, is the size of

223
00:14:18,400 --> 00:14:38,840
the larger set that is shattered by this set by h.

224
00:14:39,940 --> 00:14:42,530
And if a hypothesis class can shatter

225
00:14:42,770 --> 00:14:44,070
arbitrarily large sets,

226
00:14:44,270 --> 00:14:45,870
then the VC dimension is infinite.

227
00:14:47,180 --> 00:14:49,190
So just as a kind of good example:

228
00:14:49,710 --> 00:14:58,200
if h is the class of all linear classifiers into d,

229
00:14:59,310 --> 00:15:04,990
then the VC dimension of the set is equal to three

230
00:15:05,360 --> 00:15:07,990
because we saw just now that there is a size of

231
00:15:08,480 --> 00:15:11,980
there was a set s of size three that it could shatter,

232
00:15:12,190 --> 00:15:14,200
and I don't really prove it.

233
00:15:14,470 --> 00:15:15,420
But it turns out there is no

234
00:15:15,590 --> 00:15:17,760
sets of size four that it can shatter.

235
00:15:18,520 --> 00:15:22,570
And therefore, the VC dimension of this is three. Yeah?

236
00:15:23,070 --> 00:15:26,340
Student:But there are sets of sizethree that

237
00:15:26,580 --> 00:15:28,370
cannot shatter; right? [Inaudible] was your point.

238
00:15:28,540 --> 00:15:29,890
Instructor (Andrew Ng):Yes, absolutely.

239
00:15:30,060 --> 00:15:34,010
So it turns out that if I choose a set like this

240
00:15:34,250 --> 00:15:35,750
it's actually set s,

241
00:15:35,960 --> 00:15:38,300
then there are labelings on this they cannot realize.

242
00:15:38,470 --> 00:15:40,720
And so, h cannot shatter this set.

243
00:15:41,120 --> 00:15:42,800
But that's okay because right

244
00:15:42,950 --> 00:15:44,530
there definitely is there exists some

245
00:15:44,690 --> 00:15:46,320
other set of size three being shattered.

246
00:15:46,510 --> 00:15:48,040
So the VC dimension is three.

247
00:15:48,230 --> 00:15:50,400
And then there is no set of size four

248
00:15:50,600 --> 00:15:52,510
that can shatter. Yeah?

249
00:15:56,220 --> 00:15:57,560
Instructor (Andrew Ng):Not according to this definition

250
00:15:57,760 --> 00:16:00,440
No. Right. So again, let's see,

251
00:16:00,750 --> 00:16:04,310
I can choose my set s to be to be a

252
00:16:04,660 --> 00:16:07,280
set of three points that are all over lapping.

253
00:16:07,630 --> 00:16:09,810
Three points in exactly the same place.

254
00:16:09,990 --> 00:16:11,800
And clearly, I can't shatter this set,

255
00:16:11,990 --> 00:16:12,960
but that's okay.

256
00:16:13,140 --> 00:16:15,040
And I can't shatter this set, either,

257
00:16:15,310 --> 00:16:16,440
but that's okay because there are some

258
00:16:16,630 --> 00:16:19,690
other sets of size three that I can shatter.

259
00:16:23,990 --> 00:16:27,900
And it turns out this result holds true into the

260
00:16:28,410 --> 00:16:36,060
more generally, in any dimensions

261
00:16:39,970 --> 00:16:44,950
the VC dimension of the class of linear classifiers

262
00:16:49,740 --> 00:16:54,310
in any dimensions is equal to n plus one. Okay?

263
00:16:54,510 --> 00:16:55,980
So this is in [inaudible],

264
00:16:56,150 --> 00:16:57,350
and if you have linear classifiers over

265
00:16:57,530 --> 00:16:59,070
in any dimensional feature space,

266
00:16:59,270 --> 00:17:00,790
the VC dimension in any dimensions;

267
00:17:01,000 --> 00:17:03,710
whereas, n d is equal to n plus one.

268
00:17:04,490 --> 00:17:13,470
So maybe you wanna write it down:

269
00:17:13,660 --> 00:17:17,730
what is arguably the best-known

270
00:17:17,940 --> 00:17:26,940
result in all of learning theory, I guess; which is that.

271
00:17:29,110 --> 00:17:31,880
Let a hypothesis class be given,

272
00:17:37,730 --> 00:17:42,020
and let the VC dimension of h be equal to d.

273
00:17:45,760 --> 00:17:48,610
Then we're in probability of one minus delta.

274
00:17:50,350 --> 00:17:53,140
We have that

275
00:18:30,950 --> 00:18:33,540
the formula on the right looks a bit complicated,

276
00:18:33,760 --> 00:18:34,560
but don't worry about it.

277
00:18:34,730 --> 00:18:36,880
I'll point out the essential aspects of it later.

278
00:18:37,060 --> 00:18:38,470
But the key to this result is that

279
00:18:38,690 --> 00:18:41,690
if you have a hypothesis class with VC dimension d,

280
00:18:42,010 --> 00:18:44,280
and now this can be an infinite hypothesis class,

281
00:18:44,890 --> 00:18:50,270
what Vapnik and Chervonenkis show is that

282
00:18:50,800 --> 00:18:53,060
we're probability of at least one minus delta.

283
00:18:53,290 --> 00:18:57,860
You enjoy this sort of uniform conversions results; okay?

284
00:18:58,080 --> 00:19:00,480
We have that for all hypotheses h

285
00:19:02,390 --> 00:19:07,960
that for all the hypotheses in your hypothesis class,

286
00:19:08,170 --> 00:19:10,510
you have that the generalization error

287
00:19:10,710 --> 00:19:15,030
of h minus the training error of h.

288
00:19:15,450 --> 00:19:17,110
So the difference between these two things

289
00:19:17,280 --> 00:19:19,620
is bounded above by some

290
00:19:19,810 --> 00:19:22,150
complicated formula like this; okay?

291
00:19:22,370 --> 00:19:31,230
And thus, with probably one minus delta.

292
00:19:31,450 --> 00:19:36,540
We also have that

293
00:19:45,980 --> 00:19:51,020
have the same thing; okay?

294
00:19:56,670 --> 00:19:59,230
And going from this step to this step; right?

295
00:19:59,420 --> 00:20:02,040
Going from this step to this step is actually

296
00:20:02,210 --> 00:20:03,600
something that you saw yourself;

297
00:20:03,790 --> 00:20:05,820
that we actually proved earlier.

298
00:20:05,980 --> 00:20:07,330
Because you remember,

299
00:20:07,520 --> 00:20:08,530
in the previous lecture we proved

300
00:20:08,680 --> 00:20:10,180
that if you have uniform conversions,

301
00:20:10,660 --> 00:20:12,320
then that implies that

302
00:20:12,540 --> 00:20:15,540
it appears actually that we showed that

303
00:20:15,700 --> 00:20:16,830
if generalization error and

304
00:20:17,020 --> 00:20:18,460
training error are close to each other;

305
00:20:18,680 --> 00:20:20,370
within gamma of each other,

306
00:20:20,650 --> 00:20:22,160
then the generalization error of

307
00:20:22,340 --> 00:20:23,760
the hypotheses you pick will be

308
00:20:23,920 --> 00:20:27,390
within two gamma times the best generalization error.

309
00:20:28,130 --> 00:20:31,070
So this is really generalization error of h

310
00:20:31,250 --> 00:20:33,050
[inaudible] best possible generalization

311
00:20:33,240 --> 00:20:35,010
error plus two times gamma.

312
00:20:35,180 --> 00:20:36,710
And just the two constants in front here

313
00:20:36,880 --> 00:20:39,600
that I've absorbed into the big-O notation.

314
00:20:43,870 --> 00:20:46,240
So that formula is slightly more complicated.

315
00:20:46,650 --> 00:20:49,310
Let me just rewrite this as a corollary,

316
00:20:49,520 --> 00:20:59,630
which is that in order to guarantee that this holds,

317
00:21:04,400 --> 00:21:06,690
we're probability of one minus delta.

318
00:21:08,520 --> 00:21:09,880
We're probably at least one minus delta,

319
00:21:10,060 --> 00:21:18,030
I should say. It suffices that I'm gonna write this this

320
00:21:18,250 --> 00:21:23,230
way: I'm gonna write m equals big-O of d, and I'm going

321
00:21:23,410 --> 00:21:28,880
to put gamma and delta in as a subscript error to denote

322
00:21:29,120 --> 00:21:32,890
that. Let's see,

323
00:21:33,100 --> 00:21:35,250
if we treat gamma and delta as constants,

324
00:21:35,460 --> 00:21:36,900
so they allow me to absorb turns

325
00:21:37,110 --> 00:21:38,210
that depend on gamma and

326
00:21:38,400 --> 00:21:40,250
delta into the big-O notation,

327
00:21:40,470 --> 00:21:43,160
then in order to guarantee this holds,

328
00:21:43,410 --> 00:21:45,500
it suffices that m is on the order

329
00:21:45,710 --> 00:21:48,120
of the VC dimension and

330
00:21:48,670 --> 00:21:51,470
hypotheses class; okay?

331
00:21:53,210 --> 00:21:56,880
So let's see.

332
00:21:58,890 --> 00:22:00,970
So what we conclude from this is that

333
00:22:01,780 --> 00:22:04,310
if you have a learning algorithm that tries to

334
00:22:04,560 --> 00:22:06,360
for empirical risk minimization algorithms

335
00:22:06,530 --> 00:22:08,040
in other words, less formally,

336
00:22:08,360 --> 00:22:09,450
for learning algorithms,

337
00:22:09,630 --> 00:22:11,420
they try to minimize training error.

338
00:22:11,690 --> 00:22:14,190
The intuition to take away from this is that

339
00:22:14,420 --> 00:22:16,400
the number of training examples you need

340
00:22:16,630 --> 00:22:20,390
is therefore, roughly, linear in the VC dimension

341
00:22:20,740 --> 00:22:22,270
of the hypotheses class.

342
00:22:22,890 --> 00:22:25,130
And more formally,

343
00:22:25,340 --> 00:22:28,140
this shows that sample complexity is upper

344
00:22:28,320 --> 00:22:30,540
bounded by the VC dimension;

345
00:22:30,730 --> 00:22:35,010
okay? It turns out that

346
00:22:35,250 --> 00:22:37,550
for most reasonable hypothesis classes,

347
00:22:37,760 --> 00:22:43,350
it turns out that the VC dimension is sort of very similar,

348
00:22:43,630 --> 00:22:46,760
I guess, to the number of parameters you model.

349
00:22:47,160 --> 00:22:48,780
So for example,

350
00:22:49,010 --> 00:22:50,540
you have model and logistic regression

351
00:22:50,760 --> 00:22:52,150
linear classification.

352
00:22:52,340 --> 00:22:54,660
In any dimensions logistic regression

353
00:22:54,860 --> 00:22:57,050
in any dimensions is endless one parameters.

354
00:22:57,320 --> 00:22:58,810
And the VC dimension of which is the

355
00:22:58,990 --> 00:23:01,970
of class of linear classifiers is always the endless one.

356
00:23:02,240 --> 00:23:03,240
So it turns out that

357
00:23:03,430 --> 00:23:07,030
for most reasonable hypothesis classes,

358
00:23:07,280 --> 00:23:09,070
the VC dimension is usually

359
00:23:09,300 --> 00:23:11,620
linear in the number of parameters of your model.

360
00:23:11,800 --> 00:23:14,020
Wherein, is most sense of low other polynomial;

361
00:23:14,240 --> 00:23:16,580
in the number of parameters of your model.

362
00:23:16,830 --> 00:23:21,180
And so this the takeaway intuition from this is that the

363
00:23:21,360 --> 00:23:23,130
number of training examples you need to fit in those

364
00:23:23,300 --> 00:23:26,130
models is going to be let's say, roughly, linear in the

365
00:23:26,310 --> 00:23:29,700
number of parameters in your model; okay?

366
00:23:29,860 --> 00:23:31,050
There are some somewhat strange examples

367
00:23:31,230 --> 00:23:32,450
where what I just said is not true.

368
00:23:32,620 --> 00:23:33,970
There are some strange examples

369
00:23:34,150 --> 00:23:35,210
where you have very few parameters,

370
00:23:35,390 --> 00:23:37,030
but the VC dimension is enormous.

371
00:23:37,510 --> 00:23:38,630
But I actually know of

372
00:23:38,820 --> 00:23:39,770
all of the examples I know

373
00:23:39,980 --> 00:23:41,310
of that fall into that regime are

374
00:23:41,480 --> 00:23:43,420
somewhat strange and degenerate.

375
00:23:43,620 --> 00:23:44,780
So somewhat unusual,

376
00:23:44,930 --> 00:23:46,030
and not the source

377
00:23:46,180 --> 00:23:48,370
of not learning algorithms you usually use.

378
00:23:50,520 --> 00:23:52,840
Let's see, just other things.

379
00:23:53,110 --> 00:23:54,550
It turns out that

380
00:23:55,100 --> 00:23:56,770
so this result shows the sample complexity

381
00:23:56,950 --> 00:23:58,590
is upper bounded by VC dimension.

382
00:23:58,920 --> 00:24:00,890
But if you have a number of training examples that

383
00:24:01,050 --> 00:24:02,940
are on the order of the VC dimension,

384
00:24:03,120 --> 00:24:04,470
then you find

385
00:24:04,790 --> 00:24:06,460
it turns out that in the worse case

386
00:24:06,970 --> 00:24:14,970
some complexity is also lower bounded by VC dimension.

387
00:24:15,590 --> 00:24:17,500
And what that means is that if

388
00:24:17,770 --> 00:24:20,390
you have a perfectly nasty learning problem,

389
00:24:20,580 --> 00:24:24,580
say, then if the number of training examples

390
00:24:24,750 --> 00:24:26,810
you have is less than on the order of the VC dimension;

391
00:24:27,290 --> 00:24:31,540
then it is not possible to prove this bound.

392
00:24:31,780 --> 00:24:33,030
So I guess in the worse case,

393
00:24:33,270 --> 00:24:34,830
sample complexity in the

394
00:24:35,020 --> 00:24:36,400
number of training examples you need is upper

395
00:24:36,590 --> 00:24:38,670
bounded and lower bounded by the VC dimension.

396
00:24:41,670 --> 00:24:48,890
Let's see, questions about this?

397
00:24:52,030 --> 00:24:54,290
Student:Does the proof of this assume any

398
00:24:54,560 --> 00:24:56,790
sort of finites of, like, finite [inaudible] like you

399
00:24:56,940 --> 00:24:59,910
have to just [inaudible] real numbers and [inaudible]?

400
00:25:00,090 --> 00:25:01,270
Instructor (Andrew Ng):Let's see.

401
00:25:01,430 --> 00:25:02,570
The proof is not, no.

402
00:25:02,750 --> 00:25:05,660
I've actually stated the entirety of the theorem.

403
00:25:05,850 --> 00:25:08,320
This is true. It turns out in the proof

404
00:25:08,580 --> 00:25:11,050
well, somewhere, regardless of the proof there's

405
00:25:11,200 --> 00:25:13,180
a step reconstruction called an epsilon net,

406
00:25:13,340 --> 00:25:14,310
which is a very clever [inaudible].

407
00:25:14,490 --> 00:25:16,350
It' sort of in regardless of the proof,

408
00:25:16,490 --> 00:25:20,230
it is not an assumption that you need.

409
00:25:20,390 --> 00:25:23,170
In someway that sort of proof that's one-step that uses

410
00:25:23,390 --> 00:25:24,770
a very clever [inaudible] to prove this.

411
00:25:24,980 --> 00:25:28,250
But that's not needed;

412
00:25:28,530 --> 00:25:31,420
it's an assumption.

413
00:25:32,410 --> 00:25:33,710
I'd like to say,

414
00:25:33,890 --> 00:25:35,270
back when I was a Ph.D. student,

415
00:25:35,480 --> 00:25:36,710
when I was working through this proof,

416
00:25:36,880 --> 00:25:39,240
there was sort of a solid week where I would wake up,

417
00:25:39,530 --> 00:25:40,940
and go to the office at 9:00 a.m.

418
00:25:41,120 --> 00:25:44,040
Then I'd start reading the book that led up to this proof.

419
00:25:44,230 --> 00:25:46,930
And then I'd read from 9:00 a.m. to 6:00 p.m.

420
00:25:47,150 --> 00:25:48,480
And then I'd go home, and then the next day,

421
00:25:48,670 --> 00:25:49,620
I'd pick up where I left off.

422
00:25:49,830 --> 00:25:51,390
And it sort of took me a whole week that way,

423
00:25:51,590 --> 00:25:53,470
to understand this proof,

424
00:25:53,640 --> 00:25:55,340
so I thought I would inflict that on you.

425
00:25:59,060 --> 00:26:05,100
Just to tie a couple of loose ends:

426
00:26:07,580 --> 00:26:08,480
what I'm about to do is,

427
00:26:08,660 --> 00:26:13,200
I'm about to just mention a few things that will maybe,

428
00:26:13,380 --> 00:26:14,920
feel a little bit like random facts.

429
00:26:15,150 --> 00:26:17,140
But I'm just gonna tie up just a couple of loose ends.

430
00:26:17,380 --> 00:26:21,820
And so let's see,

431
00:26:24,060 --> 00:26:25,850
it turns out that

432
00:26:26,880 --> 00:26:28,790
just so it will be more strong with you

433
00:26:28,970 --> 00:26:31,310
so this bound was proved for an algorithm

434
00:26:31,510 --> 00:26:33,950
that uses empirical risk minimization,

435
00:26:34,210 --> 00:26:37,280
for an algorithm that minimizes 0-1 training error.

436
00:26:45,090 --> 00:26:50,040
So one question that some of you ask is

437
00:26:53,270 --> 00:26:54,660
how about support vector machines; right?

438
00:26:54,840 --> 00:26:56,590
How come SVM's don't over fit?

439
00:26:57,090 --> 00:26:59,600
And in the sequel of

440
00:26:59,760 --> 00:27:02,810
remember our discussion on support

441
00:27:03,030 --> 00:27:04,780
vector machines said that you use kernels,

442
00:27:04,950 --> 00:27:06,890
and map the features in infinite dimensional feature space.

443
00:27:07,080 --> 00:27:09,650
And so it seems like the VC dimension should be infinite;

444
00:27:10,110 --> 00:27:12,330
n plus one and n is infinite.

445
00:27:12,520 --> 00:27:15,100
So it turns out that the

446
00:27:15,370 --> 00:27:17,260
class of linear separators with large

447
00:27:17,480 --> 00:27:19,830
margin actually has low VC dimension.

448
00:27:20,140 --> 00:27:22,490
I wanna say this very quickly, and informally.

449
00:27:22,670 --> 00:27:24,760
It's actually, not very important for you

450
00:27:24,920 --> 00:27:26,370
to understand the details,

451
00:27:26,890 --> 00:27:29,350
but I'm going to say it very informally.

452
00:27:29,530 --> 00:27:31,630
It turns out that I will give you a set of points.

453
00:27:31,820 --> 00:27:35,010
And if I ask you to consider only

454
00:27:35,170 --> 00:27:37,340
the course of lines that separate these points

455
00:27:37,550 --> 00:27:38,980
of a large margin [inaudible],

456
00:27:39,170 --> 00:27:41,300
so my hypothesis class will comprise

457
00:27:41,470 --> 00:27:46,130
only the linear position boundaries that

458
00:27:46,310 --> 00:27:48,160
separate the points of a large margin.

459
00:27:48,350 --> 00:27:51,980
Say with a margin, at least gamma; okay.

460
00:27:52,560 --> 00:27:55,390
And so I won't allow a point that comes closer.

461
00:27:56,410 --> 00:27:57,800
Like, I won't allow that line because it

462
00:27:58,000 --> 00:28:00,080
comes too close to one of my points.

463
00:28:00,410 --> 00:28:11,400
It turns out that if I consider my data

464
00:28:11,600 --> 00:28:17,780
points all lie within some sphere of radius r,

465
00:28:18,630 --> 00:28:20,790
and if I consider only the course of

466
00:28:20,980 --> 00:28:23,780
linear separators is separate to data with a

467
00:28:24,180 --> 00:28:26,220
margin of at least gamma,

468
00:28:26,950 --> 00:28:30,870
then the VC dimension of this course is less than or equal

469
00:28:31,110 --> 00:28:37,170
to r squared over four gamma squared plus one; okay?

470
00:28:37,560 --> 00:28:42,450
So this funny symbol here, that just means rounding up.

471
00:28:42,680 --> 00:28:44,650
This is a ceiling symbol;

472
00:28:44,860 --> 00:28:46,710
it means rounding up x.

473
00:28:47,040 --> 00:28:49,320
And it turns out you prove

474
00:28:49,530 --> 00:28:51,480
and there are some strange things about this

475
00:28:51,670 --> 00:28:54,100
result that I'm deliberately not gonna to talk about

476
00:28:54,300 --> 00:28:57,300
but turns they can prove that the VC dimension of the class

477
00:28:57,510 --> 00:29:00,310
of linear classifiers with large margins is actually bounded

478
00:29:01,230 --> 00:29:02,490
The surprising thing about this is that

479
00:29:02,780 --> 00:29:04,580
this is the bound on VC dimension that

480
00:29:04,770 --> 00:29:07,650
has no dependents on the dimension of the points x.

481
00:29:08,050 --> 00:29:09,470
So in other words,

482
00:29:09,670 --> 00:29:12,120
your data points x combine an infinite dimensional space,

483
00:29:12,430 --> 00:29:14,470
but so long as you restrict attention to

484
00:29:14,680 --> 00:29:16,710
the class of your separators

485
00:29:16,940 --> 00:29:18,230
with large margin,

486
00:29:18,440 --> 00:29:20,010
the VC dimension is bounded.

487
00:29:20,230 --> 00:29:23,440
And so in trying to find a

488
00:29:23,630 --> 00:29:25,270
large margin separator

489
00:29:25,710 --> 00:29:27,900
in trying to find the line that separates your

490
00:29:28,080 --> 00:29:29,230
positive and your negative

491
00:29:29,430 --> 00:29:31,140
examples with large margin,

492
00:29:32,640 --> 00:29:34,180
it turns out therefore,

493
00:29:35,300 --> 00:29:37,360
that the support vector machine is automatically trying

494
00:29:37,550 --> 00:29:41,310
to find a hypothesis class with small VC dimension.

495
00:29:41,660 --> 00:29:50,100
And therefore, it does not over fit. Alex?

496
00:29:51,500 --> 00:29:52,700
Student:What is the [inaudible]?

497
00:29:52,880 --> 00:29:54,460
Instructor (Andrew Ng):It is actually defined the same

498
00:29:54,630 --> 00:29:56,580
way as finite dimensional spaces.

499
00:29:56,750 --> 00:29:58,500
So you know, suppose you have infinite

500
00:29:58,700 --> 00:30:00,960
actually, these are constantly infinite dimensional vectors;

501
00:30:01,110 --> 00:30:07,270
not [inaudible] to the infinite dimensional vectors.

502
00:30:07,700 --> 00:30:09,890
Normally, the 2 to 1 squared is equal to some equals

503
00:30:10,070 --> 00:30:11,880
110 xi squared,

504
00:30:12,030 --> 00:30:13,840
so if x is infinite dimensional,

505
00:30:14,000 --> 00:30:19,080
you just appoint it like that. [Inaudible]. [Crosstalk]

506
00:30:20,100 --> 00:30:21,820
Instructor (Andrew Ng):Now, say that again.

507
00:30:23,230 --> 00:30:25,210
Instructor (Andrew Ng):Yes. Although, I assume that

508
00:30:25,310 --> 00:30:26,160
this is bounded by r.

509
00:30:26,220 --> 00:30:27,070
Student:Oh.

510
00:30:27,110 --> 00:30:27,640
Instructor (Andrew Ng):It's a yeah so this

511
00:30:27,700 --> 00:30:28,510
insures that conversions.

512
00:30:33,500 --> 00:30:36,360
So just something people sometimes wonder about.

513
00:30:37,160 --> 00:30:41,700
And last, the actually tie empirical risk minimization

514
00:30:42,000 --> 00:30:44,060
back a little more strongly to the source of

515
00:30:44,250 --> 00:30:45,870
algorithms we've talked about.

516
00:30:46,890 --> 00:31:11,340
It turns out that so the theory was about,

517
00:31:11,570 --> 00:31:13,840
and so far, was really for empirical risk minimization.

518
00:31:14,050 --> 00:31:20,210
So that view's so we focus on just one training example.

519
00:31:21,690 --> 00:31:24,800
Let me draw a function, you know, a zero here

520
00:31:25,280 --> 00:31:26,820
jumps to one, and it looks like that.

521
00:31:27,880 --> 00:31:31,120
And so this for once, this training example,

522
00:31:31,880 --> 00:31:45,280
this may be indicator h where x axis is

523
00:31:45,580 --> 00:31:49,360
z equals theta transpose x; okay?

524
00:31:49,520 --> 00:31:51,220
But one training example

525
00:31:51,490 --> 00:31:54,720
your training example will be positive or negative.

526
00:31:54,980 --> 00:31:58,520
And depending on what the value of this data transpose x

527
00:31:58,710 --> 00:32:00,040
is, you either get it right or wrong.

528
00:32:00,230 --> 00:32:02,060
And so you know,

529
00:32:02,290 --> 00:32:03,610
I guess if your training example

530
00:32:03,810 --> 00:32:05,620
if you have a positive example,

531
00:32:05,830 --> 00:32:10,600
then when z is positive, you get it right.

532
00:32:18,500 --> 00:32:19,970
Suppose you have a negative example,

533
00:32:20,140 --> 00:32:22,160
so y equals 0; right?

534
00:32:22,670 --> 00:32:24,980
Then if z, which is data transpose x

535
00:32:25,250 --> 00:32:28,910
if this is positive, then you will get this example wrong;

536
00:32:29,710 --> 00:32:32,770
whereas, if z is negative then you'd get this example right.

537
00:32:33,040 --> 00:32:35,210
And so this is a part of indicator h

538
00:32:35,420 --> 00:32:38,870
subscript x not equals y; okay?

539
00:32:39,190 --> 00:32:48,190
You know, it's equal to g of data transpose x; okay?

540
00:32:49,480 --> 00:32:53,110
And so it turns out that

541
00:32:53,350 --> 00:32:55,720
so what you really like to do is choose

542
00:32:55,930 --> 00:32:59,130
parameters data so as to minimize this step function; right?

543
00:32:59,800 --> 00:33:01,150
You'd like to choose parameters data,

544
00:33:01,330 --> 00:33:05,610
so that you end up with a correct classification on

545
00:33:05,800 --> 00:33:07,150
setting your training example,

546
00:33:07,350 --> 00:33:10,380
and so you'd like indicator h of x not equal y.

547
00:33:10,910 --> 00:33:12,890
You'd like this indicator function to be 0.

548
00:33:13,840 --> 00:33:16,020
It turns out this

549
00:33:16,200 --> 00:33:18,210
step function is clearly a non-convex function.

550
00:33:18,470 --> 00:33:21,010
And so it turns out that just the linear classifiers

551
00:33:21,380 --> 00:33:24,280
minimizing the training error is an empty heart problem.

552
00:33:24,910 --> 00:33:26,960
It turns out that both logistic regression,

553
00:33:27,140 --> 00:33:28,910
and support vector machines can be viewed as

554
00:33:29,170 --> 00:33:32,380
using a convex approximation for this problem.

555
00:33:32,690 --> 00:33:37,520
And in particular and draw a function like that

556
00:33:41,780 --> 00:33:51,210
it turns out that logistic regression

557
00:33:51,380 --> 00:33:53,090
is trying to maximize likelihood.

558
00:33:53,410 --> 00:33:54,740
And so it's tying to minimize the

559
00:33:54,930 --> 00:33:56,560
minus of the logged likelihood.

560
00:33:56,780 --> 00:33:57,810
And if you plot the minus

561
00:33:58,020 --> 00:33:58,960
of the logged likelihood,

562
00:33:59,150 --> 00:34:01,090
it actually turns out it'll be a function that looks like this.

563
00:34:01,280 --> 00:34:04,400
And this line that I just drew,

564
00:34:04,570 --> 00:34:05,570
you can think of it as a rough

565
00:34:05,760 --> 00:34:07,290
approximation to this step function;

566
00:34:07,470 --> 00:34:08,950
which is maybe what you're really trying to minimize,

567
00:34:09,140 --> 00:34:10,650
so you want to minimize training error.

568
00:34:10,850 --> 00:34:12,170
So you can actually think of logistic regression

569
00:34:12,390 --> 00:34:15,390
as trying to approximate empirical risk minimization.

570
00:34:16,140 --> 00:34:17,390
Where instead of using this step function,

571
00:34:17,640 --> 00:34:18,820
which is non-convex,

572
00:34:19,100 --> 00:34:20,390
and gives you a hard optimization problem,

573
00:34:20,680 --> 00:34:23,650
it uses this line above this curve above.

574
00:34:23,830 --> 00:34:25,180
So approximate it,

575
00:34:25,390 --> 00:34:27,560
so you have a convex optimization problem

576
00:34:28,290 --> 00:34:30,400
you can find the maximum likelihood

577
00:34:30,590 --> 00:34:32,590
it's in the parameters for logistic regression.

578
00:34:33,510 --> 00:34:34,860
And it turns out,

579
00:34:35,040 --> 00:34:36,220
support vector machine also

580
00:34:36,440 --> 00:34:38,260
can be viewed as approximated dysfunction

581
00:34:38,530 --> 00:34:39,970
to only a little bit different

582
00:34:40,220 --> 00:34:42,600
let's see, support vector machine turns out,

583
00:34:42,880 --> 00:34:44,520
can be viewed as trying to approximate this

584
00:34:44,700 --> 00:34:46,750
step function two over different

585
00:34:46,930 --> 00:34:49,690
approximation that's linear,

586
00:34:49,910 --> 00:34:52,450
and then that sort of linear that

587
00:34:52,660 --> 00:34:55,010
our results goes this [inaudible] there,

588
00:34:55,520 --> 00:34:57,660
and then it goes up as a linear function there.

589
00:34:57,870 --> 00:34:59,910
And that's that is called the hinge class.

590
00:35:00,180 --> 00:35:01,690
And so you can think of logistic regression

591
00:35:01,850 --> 00:35:02,750
and the support vector machine

592
00:35:02,920 --> 00:35:05,550
as different approximations to try to minimize

593
00:35:05,810 --> 00:35:09,400
this step function; okay?

594
00:35:10,780 --> 00:35:15,150
And that's why I guess, all the theory we developed

595
00:35:15,430 --> 00:35:18,150
even though SVM's and logistic regression

596
00:35:18,330 --> 00:35:20,670
aren't exactly due to empirical risk minimization,

597
00:35:20,930 --> 00:35:24,890
the theory we develop often gives the completely

598
00:35:25,080 --> 00:35:27,290
appropriate intuitions for SVM's,

599
00:35:27,460 --> 00:35:31,380
and logistic regression; okay.

600
00:35:32,870 --> 00:35:35,030
So that was the last of the loose ends.

601
00:35:35,250 --> 00:35:37,540
And if you didn't get this, don't worry too much about it.

602
00:35:38,190 --> 00:35:39,400
It's a high-level message.

603
00:35:39,610 --> 00:35:41,790
It's just that SVM's and logistic regression

604
00:35:42,010 --> 00:35:44,240
are reasonable to think of as approximations

605
00:35:44,520 --> 00:35:46,690
empirical risk minimization algorithms.

606
00:35:46,930 --> 00:35:48,710
What I want to do next is move

607
00:35:48,940 --> 00:35:50,630
on to talk about model selection.

608
00:35:50,860 --> 00:35:52,070
Before I do that, let me just check

609
00:35:52,230 --> 00:36:02,970
for questions about this. Okay. Cool.

610
00:36:33,410 --> 00:36:50,700
Okay. So in the theory that we

611
00:36:50,940 --> 00:36:52,840
started to develop in the previous lecture,

612
00:36:53,030 --> 00:36:54,210
and that we sort of wrapped up

613
00:36:54,410 --> 00:36:56,290
with a discussion on VC dimension,

614
00:36:57,440 --> 00:36:57,960
we saw that there's

615
00:36:58,300 --> 00:36:59,110
often a trade-off

616
00:36:59,330 --> 00:37:00,700
between bias and variance.

617
00:37:00,930 --> 00:37:03,810
And in particular, so it is important not to choose

618
00:37:04,100 --> 00:37:08,270
a hypothesis that's either too simple or too complex.

619
00:37:08,500 --> 00:37:11,380
So if your data has sort of a quadratic structure to it,

620
00:37:11,720 --> 00:37:14,680
then if you choose a linear function to

621
00:37:14,880 --> 00:37:16,710
try to approximate it, then you would under fit.

622
00:37:17,060 --> 00:37:19,060
So you have a hypothesis with high bias.

623
00:37:20,140 --> 00:37:21,260
And conversely, we choose a

624
00:37:21,450 --> 00:37:22,860
hypothesis that's too complex,

625
00:37:23,110 --> 00:37:24,740
and you have high variance.

626
00:37:24,900 --> 00:37:26,900
And you'll also fail to fit.

627
00:37:27,080 --> 00:37:28,400
Then you would over fit the data,

628
00:37:28,600 --> 00:37:30,240
and you'd also fail to generalize well.

629
00:37:31,800 --> 00:37:35,530
So model selection algorithms provide

630
00:37:35,930 --> 00:37:38,720
a class of methods to automatically trade

631
00:37:38,950 --> 00:37:40,430
make these tradeoffs between bias

632
00:37:40,610 --> 00:37:42,090
and variance; right?

633
00:37:42,290 --> 00:37:43,900
So remember the cartoon I drew

634
00:37:44,080 --> 00:37:46,480
last time of generalization error?

635
00:37:54,410 --> 00:37:55,670
I drew this last time.

636
00:37:55,880 --> 00:37:59,550
Where on the x-axis was model complexity,

637
00:38:01,590 --> 00:38:03,200
meaning the number of

638
00:38:03,500 --> 00:38:05,450
the degree of the polynomial;

639
00:38:05,670 --> 00:38:08,320
the [inaudible] regression function or whatever.

640
00:38:08,570 --> 00:38:10,060
And if you have too simple a model,

641
00:38:10,270 --> 00:38:11,480
you have high generalization error,

642
00:38:11,790 --> 00:38:12,710
those under fitting.

643
00:38:12,940 --> 00:38:14,860
And you if have too complex a model,

644
00:38:15,310 --> 00:38:18,410
like 15 or 14-degree polynomial to five data points,

645
00:38:18,680 --> 00:38:20,580
then you also have high generalization error,

646
00:38:20,800 --> 00:38:22,360
and you're over fitting.

647
00:38:22,690 --> 00:38:27,340
So what I wanna do now is actually just talk about

648
00:38:27,520 --> 00:38:29,140
model selection in the abstract; all right?

649
00:38:32,980 --> 00:38:34,720
well, I'll run the example of

650
00:38:34,720 --> 00:38:35,720
Some examples of model selection problems will include –

651
00:38:34,950 --> 00:38:37,890
let's say you're trying to choose

652
00:38:38,390 --> 00:38:44,380
the degree of a polynomial; right?

653
00:38:45,790 --> 00:38:47,620
What degree polynomial do you want to choose?

654
00:38:47,840 --> 00:38:51,150
Another example of a model selection problem would be i

655
00:38:51,390 --> 00:38:53,410
if you're trying to choose the parameter [inaudible],

656
00:38:53,940 --> 00:38:56,100
which was the bandwidth parameter

657
00:38:57,680 --> 00:39:02,780
in locally awaited linear regression or

658
00:39:04,860 --> 00:39:06,670
in some sort of local way to regression.

659
00:39:06,910 --> 00:39:10,600
Yet, another model selection problem is

660
00:39:10,850 --> 00:39:12,630
if you're trying to choose the parameter c

661
00:39:12,850 --> 00:39:16,960
[inaudible] and as the [inaudible]; right?

662
00:39:17,700 --> 00:39:20,890
And so one known soft margin is the

663
00:39:21,110 --> 00:39:23,390
we had this

664
00:39:23,600 --> 00:39:28,150
optimization objective; right?

665
00:39:28,640 --> 00:39:32,080
And the parameter c controls the tradeoff between

666
00:39:32,320 --> 00:39:35,090
how much you want to set for your example.

667
00:39:35,360 --> 00:39:36,990
So a large margin versus how much

668
00:39:37,160 --> 00:39:40,540
you want to penalize in this class [inaudible] example.

669
00:39:40,720 --> 00:39:43,210
So these are three specific examples

670
00:39:43,470 --> 00:39:46,530
of model selection problems.

671
00:39:47,610 --> 00:39:48,860
And let's come up with a method

672
00:39:49,110 --> 00:39:57,000
for semantically choosing them.

673
00:40:13,890 --> 00:40:16,110
Let's say you have some finite set of models,

674
00:40:16,470 --> 00:40:19,310
and let's write these as m1, m2, m3, and so on.

675
00:40:19,780 --> 00:40:21,810
For example, this may be

676
00:40:22,310 --> 00:40:24,770
the linear classifier

677
00:40:25,000 --> 00:40:26,760
or this may be the quadratic classifier,

678
00:40:28,130 --> 00:40:30,990
and so on; okay?

679
00:40:31,530 --> 00:40:34,620
Or this may also be you may

680
00:40:34,820 --> 00:40:36,600
also take the bandwidth parameter [inaudible]

681
00:40:36,860 --> 00:40:39,500
and discretize it into a range of values,

682
00:40:39,820 --> 00:40:41,410
and you're trying to choose from the most

683
00:40:41,610 --> 00:40:43,210
discrete of the values.

684
00:40:43,540 --> 00:40:44,710
So let's talk about how you would

685
00:40:44,890 --> 00:40:47,060
select an appropriate model; all right?

686
00:40:47,320 --> 00:40:49,370
Well, one thing you could do is

687
00:40:49,980 --> 00:40:51,480
you can pick all of these models,

688
00:40:51,720 --> 00:40:53,890
and train them on you're training set.

689
00:40:54,110 --> 00:40:56,550
And then see which model has the lowest training error.

690
00:40:57,240 --> 00:40:59,170
So that's a terrible idea,

691
00:40:59,450 --> 00:41:00,750
and why's that?

692
00:41:05,870 --> 00:41:07,100
Instructor (Andrew Ng):Right. Cool.

693
00:41:07,280 --> 00:41:09,060
Because of the over fit; right.

694
00:41:09,240 --> 00:41:11,110
And those some of you are laughing that I asked that.

695
00:41:11,280 --> 00:41:13,300
So that'd be a terrible idea to choose a

696
00:41:13,490 --> 00:41:15,460
model by looking at your training set because well,

697
00:41:15,630 --> 00:41:16,920
obviously, you end up choosing

698
00:41:17,100 --> 00:41:19,070
the most complex model; right?

699
00:41:19,220 --> 00:41:20,390
And you choose a 10th degree polynomial

700
00:41:20,540 --> 00:41:21,820
because that's what fits the training set.

701
00:41:25,430 --> 00:41:27,330
So we come to model selection in a training set

702
00:41:27,600 --> 00:41:30,510
several standard procedures to do this.

703
00:41:30,800 --> 00:41:32,780
One is hold out cross validation,

704
00:41:38,800 --> 00:41:40,610
and in hold out cross validation,

705
00:41:40,890 --> 00:41:42,140
we teach a training set.

706
00:41:42,760 --> 00:41:48,140
And we randomly split the training set into two subsets.

707
00:41:48,700 --> 00:41:51,810
We call it subset

708
00:41:52,150 --> 00:41:53,720
take all the data you have and

709
00:41:53,910 --> 00:41:56,080
randomly split it into two subsets.

710
00:41:56,300 --> 00:41:57,830
And we'll call it the training set,

711
00:41:58,100 --> 00:42:02,490
and the hold out cross validation subset.

712
00:42:03,100 --> 00:42:08,530
And then, you know, you train each model

713
00:42:12,040 --> 00:42:14,680
on just trading subset of it,

714
00:42:15,200 --> 00:42:20,510
and test it on your hold out cross validation set.

715
00:42:22,550 --> 00:42:26,330
And you pick the model with the lowest error

716
00:42:33,270 --> 00:42:35,690
on the hold out cross validation subset; okay?

717
00:42:35,890 --> 00:42:38,280
So this is sort of a relatively straightforward procedure,

718
00:42:38,470 --> 00:42:40,390
and it's commonly used where you

719
00:42:40,570 --> 00:42:42,240
train on 70 percent of the data.

720
00:42:42,420 --> 00:42:43,320
Then test all of your models.

721
00:42:43,530 --> 00:42:45,020
And 30 percent, you can

722
00:42:45,190 --> 00:42:46,610
take whatever has the smallest hold

723
00:42:46,850 --> 00:42:49,400
out cross validation error.

724
00:42:51,150 --> 00:42:52,550
And after this

725
00:42:52,770 --> 00:42:54,080
you actually have a chose.

726
00:42:54,380 --> 00:42:55,750
You can actually having taken all

727
00:42:55,910 --> 00:42:58,320
of these hypothesis trained on 70 percent of the data,

728
00:42:58,760 --> 00:43:00,910
you can actually just output the hypothesis

729
00:43:01,120 --> 00:43:02,800
that has the lowest error on your hold out cross

730
00:43:02,960 --> 00:43:05,940
validation set. And optionally, you can actually

731
00:43:06,110 --> 00:43:09,100
take the model that you selected and go back,

732
00:43:09,370 --> 00:43:10,810
and retrain it on all 100

733
00:43:11,020 --> 00:43:13,570
percent of the data; okay?

734
00:43:13,740 --> 00:43:15,870
So both versions are actually done and used really often.

735
00:43:16,030 --> 00:43:17,280
You can either, you know, just take the best

736
00:43:17,440 --> 00:43:19,320
hypothesis that was trained on 70 percent of the data,

737
00:43:19,960 --> 00:43:21,270
and just output that as you find the

738
00:43:21,440 --> 00:43:22,640
hypothesis or

739
00:43:22,820 --> 00:43:24,270
you can use this to say,

740
00:43:24,470 --> 00:43:26,400
having chosen the degree of the polynomial

741
00:43:26,560 --> 00:43:27,440
you want to fit,

742
00:43:27,610 --> 00:43:28,520
you can then go back and retrain

743
00:43:28,690 --> 00:43:31,120
the model on the entire 100 percent of your data.

744
00:43:31,440 --> 00:43:32,440
And both of these are commonly done.

745
00:43:50,700 --> 00:43:53,500
How about a cross validation does sort of work straight?

746
00:43:54,070 --> 00:43:56,610
And sometimes we're working with

747
00:43:56,800 --> 00:44:01,380
a company or application or something.

748
00:44:01,640 --> 00:44:04,850
The many machine-learning applications

749
00:44:05,070 --> 00:44:07,120
we have very little data or where,

750
00:44:07,420 --> 00:44:09,360
you know, every training example you have

751
00:44:09,610 --> 00:44:12,550
was painfully acquired at great cost; right?

752
00:44:12,830 --> 00:44:17,180
Sometimes your data is acquired by medical experiments,

753
00:44:17,510 --> 00:44:20,020
and each of these each training example represents a sick

754
00:44:20,180 --> 00:44:22,010
man in amounts of physical human pain or something.

755
00:44:22,230 --> 00:44:24,450
So we talk and say,

756
00:44:24,640 --> 00:44:26,660
"Well, I'm going to hold out 30 percent of your data set,

757
00:44:26,940 --> 00:44:28,320
just to select my model."

758
00:44:28,530 --> 00:44:31,170
If people were who sometimes that causes unhappiness,

759
00:44:31,720 --> 00:44:33,050
and so maybe you wanna use

760
00:44:33,300 --> 00:44:35,250
not have to leave out 30 percent of

761
00:44:35,480 --> 00:44:37,440
your data just to do model selection.

762
00:44:37,810 --> 00:44:40,630
So there are a couple of other variations on

763
00:44:40,800 --> 00:44:43,460
hold out cross validation that makes sometimes,

764
00:44:43,660 --> 00:44:45,310
slightly more efficient use of the data.

765
00:44:45,860 --> 00:44:50,840
And one is called k-fold cross validation.

766
00:44:51,580 --> 00:44:53,000
And here's the idea:

767
00:44:54,220 --> 00:44:55,750
I'm gonna take all of my data s;

768
00:44:56,140 --> 00:44:58,900
so imagine, I'm gonna

769
00:44:59,100 --> 00:45:01,090
draw this box s,

770
00:45:01,290 --> 00:45:03,790
as to note the entirety of all the data I have.

771
00:45:04,100 --> 00:45:08,900
And I'll then divide it into k pieces,

772
00:45:09,180 --> 00:45:11,460
and this is five pieces in what I've drawn.

773
00:45:11,750 --> 00:45:14,300
Then what'll I'll do is I will

774
00:45:14,490 --> 00:45:19,080
repeatedly train on k minus one pieces.

775
00:45:23,430 --> 00:45:27,880
Test on the remaining one test on the

776
00:45:28,090 --> 00:45:30,710
remaining piece, I guess; right?

777
00:45:30,920 --> 00:45:37,450
And then you average over the k result.

778
00:45:37,710 --> 00:45:44,320
So another way, we'll just hold out

779
00:45:44,580 --> 00:45:49,850
I will hold out say, just 1/5 of my data

780
00:45:50,480 --> 00:45:52,440
and I'll train on the remaining 4/5,

781
00:45:52,620 --> 00:45:53,620
and I'll test on the first one.

782
00:45:53,830 --> 00:45:57,160
And then I'll then go and hold out the second 1/5

783
00:45:57,330 --> 00:45:59,270
from my [inaudible] for the remaining pieces

784
00:45:59,470 --> 00:46:00,620
test on this,

785
00:46:00,800 --> 00:46:02,690
you remove the third piece,

786
00:46:02,900 --> 00:46:03,890
train on the 4/5;

787
00:46:04,060 --> 00:46:05,500
I'm gonna do this five times.

788
00:46:05,850 --> 00:46:08,780
And then I'll take the five error measures I have

789
00:46:08,970 --> 00:46:10,430
and I'll average them.

790
00:46:10,690 --> 00:46:12,950
And this then gives me an estimate of

791
00:46:13,140 --> 00:46:15,860
the generalization error of my model; okay?

792
00:46:16,050 --> 00:46:18,810
And then, again, when you do k-fold cross validation,

793
00:46:19,050 --> 00:46:21,130
usually you then go back and

794
00:46:21,330 --> 00:46:24,200
retrain the model you selected on the

795
00:46:24,390 --> 00:46:26,400
entirety of your training set.

796
00:46:27,740 --> 00:46:29,990
So I drew five pieces here because

797
00:46:30,190 --> 00:46:32,610
that was easier for me to draw,

798
00:46:32,910 --> 00:46:38,690
but k equals 10 is very common; okay?

799
00:46:39,400 --> 00:46:43,290
I should say k equals 10 is the fairly common choice

800
00:46:43,790 --> 00:46:45,980
to do 10 fold cross validation.

801
00:46:46,240 --> 00:46:49,930
And the advantage of the over hold out cross option is that

802
00:46:50,310 --> 00:46:51,790
you switch the data into ten pieces.

803
00:46:52,120 --> 00:46:55,210
Then each time you're only holding out 1/10 of your data,

804
00:46:55,520 --> 00:46:57,900
rather than, you know, say, 30 percent of your data.

805
00:46:59,570 --> 00:47:00,760
I must say, in standard hold out

806
00:47:00,950 --> 00:47:02,870
in simple hold out cross validation,

807
00:47:03,140 --> 00:47:05,140
a 30 70 split is fairly common.

808
00:47:05,430 --> 00:47:07,690
Sometimes like 2/3 1/3 or

809
00:47:07,920 --> 00:47:09,510
a 70 30 split is fairly common.

810
00:47:09,810 --> 00:47:11,180
And if you use k-fold cross validation,

811
00:47:11,400 --> 00:47:13,860
k equals 5 or more commonly k equals 10,

812
00:47:14,140 --> 00:47:15,420
and is the most common choice.

813
00:47:15,650 --> 00:47:18,350
The disadvantage of k-fold cross validation is

814
00:47:18,540 --> 00:47:20,540
that it can be much more computationally expensive.

815
00:47:20,880 --> 00:47:24,040
In particular, to validate your model,

816
00:47:24,280 --> 00:47:26,080
you now need to train your model ten times,

817
00:47:26,320 --> 00:47:27,440
instead of just once.

818
00:47:27,610 --> 00:47:28,790
And so you need to:

819
00:47:29,000 --> 00:47:30,000
from logistic regression,

820
00:47:30,180 --> 00:47:31,300
ten times per model,

821
00:47:31,510 --> 00:47:32,400
rather than just once.

822
00:47:32,540 --> 00:47:34,120
And so this is computationally more expensive.

823
00:47:34,430 --> 00:47:35,770
But k equals ten works great.

824
00:47:37,550 --> 00:47:44,400
And then, finally, in there's actually a

825
00:47:45,330 --> 00:47:47,550
version of this that you can take even further,

826
00:47:47,900 --> 00:47:51,050
which is when your set k equals m.

827
00:47:51,810 --> 00:47:53,550
And so that's when you take your training set,

828
00:47:53,920 --> 00:47:56,360
and you split it into as many pieces as

829
00:47:56,570 --> 00:47:58,310
you have training examples.

830
00:47:59,080 --> 00:48:00,370
And this procedure is called

831
00:48:00,610 --> 00:48:01,900
leave one out cross validation.

832
00:48:06,350 --> 00:48:08,340
And what you do is you then

833
00:48:09,140 --> 00:48:10,570
take out the first training example,

834
00:48:10,840 --> 00:48:11,920
train on the rest,

835
00:48:12,120 --> 00:48:13,540
and test on the first example.

836
00:48:13,780 --> 00:48:15,130
Then you take out the second training example,

837
00:48:16,760 --> 00:48:17,420
train on the rest,

838
00:48:17,620 --> 00:48:18,900
and test on the second example.

839
00:48:19,100 --> 00:48:20,260
Then you take out the third example,

840
00:48:20,460 --> 00:48:22,000
train on everything, but your third example.

841
00:48:22,180 --> 00:48:23,650
Test on the third example, and so on.

842
00:48:23,970 --> 00:48:27,090
And so with this many pieces you are now making,

843
00:48:27,300 --> 00:48:30,080
maybe even more effective use of your

844
00:48:30,270 --> 00:48:31,950
data than k-fold cross validation.

845
00:48:32,240 --> 00:48:33,610
But you could leave leave one out

846
00:48:33,780 --> 00:48:36,210
cross validation is computationally very expensive

847
00:48:36,540 --> 00:48:38,440
because now you need to repeatedly

848
00:48:38,680 --> 00:48:40,030
leave one example out,

849
00:48:40,250 --> 00:48:41,290
and then run your learning

850
00:48:41,470 --> 00:48:44,780
algorithm on m minus one training examples.

851
00:48:44,940 --> 00:48:46,600
You need to do this a lot of times,

852
00:48:46,760 --> 00:48:48,830
and so this is computationally very expensive.

853
00:48:49,010 --> 00:48:50,130
And typically,

854
00:48:50,300 --> 00:48:52,720
this is done only when you're extremely data scarce.

855
00:48:53,160 --> 00:48:55,880
So if you have a learning problem where you have,

856
00:48:56,080 --> 00:48:58,070
say, 15 training examples or something,

857
00:48:58,370 --> 00:49:00,070
then if you have very few training examples,

858
00:49:00,360 --> 00:49:06,400
leave one out cross validation is maybe preferred.

859
00:49:07,130 --> 00:49:08,370
Yeah?

860
00:49:08,700 --> 00:49:11,630
Student:You know, that time you proved that

861
00:49:11,830 --> 00:49:15,160
the difference between the generalized by number of

862
00:49:15,330 --> 00:49:17,980
examples in your training set and VC dimension.

863
00:49:18,420 --> 00:49:28,080
So maybe examples into different groups, we can use that

864
00:49:28,320 --> 00:49:30,200
Instructor (Andrew Ng):Yeah, I mean

865
00:49:30,360 --> 00:49:32,350
Student:- compute the training error,

866
00:49:32,520 --> 00:49:34,560
and use that for computing for a generalized error.

867
00:49:34,740 --> 00:49:36,210
Instructor (Andrew Ng):Yeah, that's done, but

868
00:49:36,710 --> 00:49:39,530
yeah, in practice, I personally tend not to do that.

869
00:49:39,800 --> 00:49:43,220
It tends not to be the VC dimension

870
00:49:43,410 --> 00:49:45,050
bounds are somewhat loose bounds.

871
00:49:45,260 --> 00:49:48,440
And so there are people in structure risk

872
00:49:48,640 --> 00:49:50,230
minimization that propose what you do,

873
00:49:50,420 --> 00:49:52,910
but I personally tend not to do that, though.

874
00:50:09,690 --> 00:50:18,210
Questions for cross validation? Yeah.

875
00:50:40,500 --> 00:50:43,300
Instructor (Andrew Ng):Right.

876
00:50:45,120 --> 00:50:47,250
Instructor (Andrew Ng):Yeah.

877
00:50:48,030 --> 00:50:50,490
Instructor (Andrew Ng):No okay.

878
00:50:50,660 --> 00:50:51,820
So it turns out that when you're

879
00:50:52,010 --> 00:50:52,940
proving learning theory bounds,

880
00:50:53,160 --> 00:50:54,930
very often the bounds will be extremely loose

881
00:50:55,090 --> 00:50:57,290
because you're sort of proving the worse case upper

882
00:50:57,450 --> 00:51:00,210
bound that holds true even for very bad

883
00:51:00,450 --> 00:51:06,920
what is it so the bounds

884
00:51:07,130 --> 00:51:08,390
that I proved just now; right?

885
00:51:08,600 --> 00:51:10,010
That holds true for absolutely any

886
00:51:10,200 --> 00:51:13,600
probability distribution over training examples; right?

887
00:51:13,800 --> 00:51:15,080
So just assume the training

888
00:51:15,310 --> 00:51:16,140
examples we've drawn,

889
00:51:16,350 --> 00:51:18,320
iid from some distribution script d,

890
00:51:18,860 --> 00:51:20,600
and the bounds I proved hold true

891
00:51:20,810 --> 00:51:25,480
for absolutely any probability distribution over script d.

892
00:51:26,010 --> 00:51:29,400
And chances are whatever real life

893
00:51:29,700 --> 00:51:32,180
distribution you get over, you know,

894
00:51:32,380 --> 00:51:34,060
houses and their prices or whatever,

895
00:51:34,420 --> 00:51:36,830
is probably not as bad as the very worse

896
00:51:37,010 --> 00:51:39,190
one you could've gotten; okay?

897
00:51:39,350 --> 00:51:42,380
And so it turns out that if you actually

898
00:51:42,570 --> 00:51:44,650
plug in the constants of learning theory bounds,

899
00:51:44,900 --> 00:51:47,190
you often get extremely large numbers.

900
00:51:47,650 --> 00:51:50,060
Take logistic regression

901
00:51:50,310 --> 00:51:52,400
logistic regression you have ten parameters

902
00:51:52,620 --> 00:51:55,580
and 0.01 error, and with 95

903
00:51:55,750 --> 00:51:56,710
percent probability.

904
00:51:56,910 --> 00:51:58,340
How many training examples do I need?

905
00:51:58,530 --> 00:51:59,890
If you actually plug in actual constants

906
00:52:00,110 --> 00:52:01,670
into the text for learning theory bounds,

907
00:52:01,930 --> 00:52:04,680
you often get extremely pessimistic estimates

908
00:52:04,870 --> 00:52:06,120
with the number of examples you need.

909
00:52:06,380 --> 00:52:08,920
You end up with some ridiculously large numbers.

910
00:52:09,140 --> 00:52:10,610
You would need 10,000 training

911
00:52:10,790 --> 00:52:12,350
examples to fit ten parameters.

912
00:52:12,580 --> 00:52:19,270
So a good way to think of these learning theory

913
00:52:19,470 --> 00:52:21,060
bounds is and this is why, also,

914
00:52:21,300 --> 00:52:24,410
when I write papers on learning theory bounds,

915
00:52:24,620 --> 00:52:27,890
I quite often use big-O notation to just

916
00:52:28,090 --> 00:52:30,150
absolutely just ignore the constant factors

917
00:52:30,340 --> 00:52:31,780
because the bounds seem to be very loose.

918
00:52:32,150 --> 00:52:34,900
There are some attempts to use these

919
00:52:35,110 --> 00:52:40,220
bounds to give guidelines as to what model to choose,

920
00:52:40,510 --> 00:52:43,540
and so on. But I personally tend to use the bounds

921
00:52:43,810 --> 00:52:47,440
again, intuition about

922
00:52:47,680 --> 00:52:52,470
for example, what are the number of training examples you

923
00:52:52,660 --> 00:52:55,170
need gross linearly in the number of parameters or what

924
00:52:55,380 --> 00:52:57,520
are your gross x dimension in number of parameters;

925
00:52:57,740 --> 00:52:59,700
whether it goes quadratic parameters?

926
00:52:59,880 --> 00:53:01,390
So it's quite often the shape of the bounds.

927
00:53:01,630 --> 00:53:03,480
The fact that the number of training examples

928
00:53:03,750 --> 00:53:04,830
the fact that some complexity

929
00:53:05,020 --> 00:53:06,390
is linear in the VC dimension,

930
00:53:06,610 --> 00:53:08,100
that's sort of a useful intuition you

931
00:53:08,330 --> 00:53:10,110
can get from these theories.

932
00:53:10,350 --> 00:53:12,590
But the actual magnitude of the bound

933
00:53:12,840 --> 00:53:14,190
will tend to be much looser than

934
00:53:14,490 --> 00:53:17,580
will hold true for a particular problem you are working on.

935
00:53:18,150 --> 00:53:20,060
So did that answer your question?

936
00:53:20,390 --> 00:53:22,120
Student:Uh-huh.

937
00:53:26,080 --> 00:53:27,670
Instructor (Andrew Ng):Yeah. And it turns out, by the way,

938
00:53:27,890 --> 00:53:30,580
for myself, a rule of thumb that I often use

939
00:53:30,820 --> 00:53:32,640
is if you're trying to fit a logistic

940
00:53:32,840 --> 00:53:34,410
regression model,

941
00:53:34,900 --> 00:53:38,060
if you have n parameters or n plus one parameters;

942
00:53:38,360 --> 00:53:40,550
if the number of training examples is

943
00:53:40,750 --> 00:53:42,630
ten times your number of parameters,

944
00:53:42,870 --> 00:53:44,420
then you're probably in good shape.

945
00:53:44,680 --> 00:53:46,110
And if your number of training examples is

946
00:53:46,310 --> 00:53:47,870
like tiny times the number of parameters,

947
00:53:48,170 --> 00:53:51,570
then you're probably perfectly fine fitting that model.

948
00:53:52,630 --> 00:53:54,160
So those are the sorts of intuitions that

949
00:53:54,380 --> 00:53:56,470
you can get from these bounds.

950
00:53:58,460 --> 00:54:00,080
Student:In cross validation do

951
00:54:00,260 --> 00:54:01,670
we assume these examples randomly?

952
00:54:01,840 --> 00:54:04,580
Instructor (Andrew Ng):Yes. So by convention

953
00:54:04,780 --> 00:54:08,010
we usually split the train testers randomly.

954
00:54:23,110 --> 00:54:25,510
One more thing I want to talk about for model selection

955
00:54:25,740 --> 00:54:27,830
is there's actually a special case of model selections,

956
00:54:28,090 --> 00:54:29,640
called the feature selection problem.

957
00:54:39,150 --> 00:54:41,030
And so here's the intuition:

958
00:54:41,270 --> 00:54:43,160
for many machine-learning problems

959
00:54:43,400 --> 00:54:46,080
you may have a very high dimensional feature space

960
00:54:51,710 --> 00:54:53,430
So for example, for text classification

961
00:54:53,930 --> 00:54:55,240
and I wanna talk about this text classification

962
00:54:55,240 --> 00:54:56,240
with very high dimensional you have x's –feature x's.

963
00:54:55,480 --> 00:54:57,060
example that spam versus non-spam.

964
00:54:57,460 --> 00:54:59,820
You may easily have on the order

965
00:55:00,010 --> 00:55:02,160
of 30,000 or 50,000 features.

966
00:55:02,460 --> 00:55:05,710
I think I used 50,000 in my early examples.

967
00:55:06,990 --> 00:55:08,640
So if you have so many features

968
00:55:08,870 --> 00:55:10,140
you have 50,000 features,

969
00:55:10,850 --> 00:55:12,510
depending on what learning algorithm you use,

970
00:55:12,900 --> 00:55:14,780
there may be a real risk of over fitting.

971
00:55:15,300 --> 00:55:18,400
And so if you can reduce the number of features,

972
00:55:18,660 --> 00:55:20,730
maybe you can reduce the

973
00:55:20,940 --> 00:55:22,520
variance of your learning algorithm,

974
00:55:22,710 --> 00:55:23,520
and reduce the

975
00:55:23,700 --> 00:55:25,240
risk of over fitting.

976
00:55:25,470 --> 00:55:27,290
And for the specific case of text classification,

977
00:55:28,200 --> 00:55:29,120
if you imagine that maybe

978
00:55:29,330 --> 00:55:31,460
there's a small number of "relevant features,"

979
00:55:31,810 --> 00:55:32,860
so there are all these English words.

980
00:55:33,200 --> 00:55:34,850
And many of these English words probably

981
00:55:35,090 --> 00:55:36,520
don't tell you anything at all about

982
00:55:36,750 --> 00:55:38,580
whether the email is spam or non-spam.

983
00:55:39,200 --> 00:55:41,880
If it were, you know, English function words like,

984
00:55:42,070 --> 00:55:44,500
the, of, a, and; these are probably words

985
00:55:44,720 --> 00:55:45,970
that don't tell you anything about whether

986
00:55:46,180 --> 00:55:47,550
the email is spam or non-spam.

987
00:55:47,750 --> 00:55:49,640
So words in contrast will be a much smaller number of

988
00:55:49,870 --> 00:55:53,360
features that are truly "relevant" to the learning problem.

989
00:55:53,840 --> 00:55:55,120
So for example, you see the

990
00:55:55,360 --> 00:55:56,760
word buy or Viagra,

991
00:55:57,000 --> 00:55:59,250
those are words that are very useful.

992
00:55:59,420 --> 00:56:00,880
So you words, some you spam and non-spam.

993
00:56:01,420 --> 00:56:02,740
You see the word Stanford or

994
00:56:02,930 --> 00:56:04,770
machine-learning or your own personal name.

995
00:56:05,000 --> 00:56:06,500
These are other words that are useful

996
00:56:06,700 --> 00:56:09,020
for telling you whether something is spam or non-spam.

997
00:56:09,370 --> 00:56:11,440
So in feature selection,

998
00:56:11,950 --> 00:56:14,290
we would like to select a subset of the

999
00:56:14,470 --> 00:56:17,430
features that may be or hopefully the most

1000
00:56:17,600 --> 00:56:18,880
relevant ones for a specific

1001
00:56:19,050 --> 00:56:20,480
learning problem,

1002
00:56:20,670 --> 00:56:23,040
so as to give ourselves a simpler learning

1003
00:56:23,210 --> 00:56:25,310
a simpler hypothesis class to choose from.

1004
00:56:25,980 --> 00:56:28,000
And then therefore, reduce the risk of over fitting.

1005
00:56:28,300 --> 00:56:33,130
Even when we may have had 50,000 features originally.

1006
00:56:33,340 --> 00:56:37,520
So how do you do this?

1007
00:56:37,690 --> 00:56:42,170
Well, if you have n features,

1008
00:56:44,140 --> 00:56:52,610
then there are two to the n possible subsets; right?

1009
00:56:54,750 --> 00:56:56,680
Because, you know, each of your n features

1010
00:56:56,860 --> 00:56:58,570
can either be included or excluded.

1011
00:56:58,760 --> 00:57:00,160
So there are two to the n possibilities.

1012
00:57:00,440 --> 00:57:02,300
And this is a huge space.

1013
00:57:02,980 --> 00:57:04,990
So in feature selection,

1014
00:57:05,230 --> 00:57:07,870
what we most commonly do is use various

1015
00:57:08,040 --> 00:57:10,340
searcheristics sort of simple search algorithms

1016
00:57:10,560 --> 00:57:12,290
to try to search through this space of

1017
00:57:12,500 --> 00:57:14,630
two to the n possible subsets of features;

1018
00:57:14,970 --> 00:57:17,220
to try to find a good subset of features.

1019
00:57:17,800 --> 00:57:20,240
This is too large a number to enumerate

1020
00:57:20,410 --> 00:57:21,900
all possible feature subsets.

1021
00:57:22,120 --> 00:57:24,620
And as a complete example,

1022
00:57:25,640 --> 00:57:28,490
this is the forward search algorithm;

1023
00:57:28,760 --> 00:57:30,740
it's also called the forward selection algorithm.

1024
00:57:31,010 --> 00:57:33,810
It's actually pretty simple,

1025
00:57:34,130 --> 00:57:35,590
but I'll just write it out.

1026
00:57:35,800 --> 00:57:37,520
My writing it out will make it look more

1027
00:57:37,690 --> 00:57:38,930
complicated than it really is,

1028
00:57:40,050 --> 00:57:42,410
but it starts with

1029
00:57:45,730 --> 00:57:49,870
initialize the sets script f to be the empty set,

1030
00:57:52,120 --> 00:57:59,720
and then repeat for i equals one to n;

1031
00:58:04,950 --> 00:58:13,030
try adding feature i to the set scripts f,

1032
00:58:14,180 --> 00:58:20,840
and evaluate the model using cross validation.

1033
00:58:25,750 --> 00:58:28,940
And by cross validation, I mean any of the three flavors,

1034
00:58:29,200 --> 00:58:30,790
be it simple hold out cross validation

1035
00:58:31,010 --> 00:58:32,200
or k-fold cross validation

1036
00:58:32,440 --> 00:58:34,160
or leave one out cross validation.

1037
00:58:34,650 --> 00:58:42,840
And then, you know, set f to be equal to f union, I guess.

1038
00:58:43,290 --> 00:58:53,120
And then the best feature found is f 1, I guess; okay?

1039
00:58:57,560 --> 00:59:01,260
And finally, you would okay?

1040
00:59:16,480 --> 00:59:18,420
So forward selections, procedure is:

1041
00:59:18,620 --> 00:59:20,230
follow through the empty set of features.

1042
00:59:20,520 --> 00:59:22,150
And then on each generation,

1043
00:59:22,450 --> 00:59:27,530
take each of your features that isn't already in your set

1044
00:59:27,720 --> 00:59:29,460
script f and you try adding that feature to your set.

1045
00:59:29,770 --> 00:59:31,840
Then you train them all, though,

1046
00:59:32,050 --> 00:59:34,060
and evaluate them all, though, using cross validation.

1047
00:59:34,830 --> 00:59:36,860
And basically, figure out what is the best single

1048
00:59:37,090 --> 00:59:39,030
feature to add to your set script f.

1049
00:59:39,580 --> 00:59:41,980
In step two here,

1050
00:59:42,220 --> 00:59:45,180
you go ahead and add that feature to your set script f,

1051
00:59:45,490 --> 00:59:47,320
and you get it right. And when I say

1052
00:59:47,510 --> 00:59:49,710
best feature or best model here by best,

1053
00:59:49,900 --> 00:59:51,050
I really mean the best model

1054
00:59:51,250 --> 00:59:52,910
according to hold out cross validation.

1055
00:59:53,430 --> 00:59:57,030
By best, I really mean the single feature addition

1056
00:59:57,260 --> 01:00:00,760
that results in the lowest hold out cross validation error

1057
01:00:01,610 --> 01:00:03,360
or the lowest cross validation error.

1058
01:00:03,560 --> 01:00:05,400
So you do this adding one feature at a time.

1059
01:00:05,660 --> 01:00:11,000
When you terminate this a little bit,

1060
01:00:11,390 --> 01:00:13,370
as if you've added all the features to f,

1061
01:00:13,580 --> 01:00:16,160
so f is now the entire set of features;

1062
01:00:16,390 --> 01:00:17,530
you can terminate this.

1063
01:00:17,750 --> 01:00:20,220
Or if by some rule of thumb,

1064
01:00:20,470 --> 01:00:22,650
you know that you probably don't ever

1065
01:00:22,830 --> 01:00:24,440
want more than k features,

1066
01:00:24,670 --> 01:00:25,840
you can also terminate this

1067
01:00:26,140 --> 01:00:28,460
if f is already exceeded some

1068
01:00:28,660 --> 01:00:30,400
threshold number of features.

1069
01:00:30,570 --> 01:00:32,100
So maybe if you have 100 training examples,

1070
01:00:32,320 --> 01:00:33,620
and you're fitting logistic regression,

1071
01:00:33,910 --> 01:00:35,320
you probably know you won't

1072
01:00:35,520 --> 01:00:36,980
want more than 100 features.

1073
01:00:37,210 --> 01:00:40,110
And so you stop after

1074
01:00:40,300 --> 01:00:41,800
you have 100 features

1075
01:00:41,990 --> 01:00:43,670
added to set f; okay?

1076
01:00:45,820 --> 01:00:46,960
And then finally, having done this,

1077
01:00:47,680 --> 01:00:49,350
output of best hypothesis found; again,

1078
01:00:49,670 --> 01:00:51,070
by best, I mean,

1079
01:00:51,410 --> 01:00:52,750
when learning this algorithm,

1080
01:00:53,030 --> 01:00:54,490
you'd be seeing lots of hypothesis.

1081
01:00:54,730 --> 01:00:55,960
You'd be training lots of hypothesis,

1082
01:00:56,160 --> 01:00:57,630
and testing them using cross validation.

1083
01:00:57,960 --> 01:00:59,690
So when I say output best hypothesis found,

1084
01:00:59,920 --> 01:01:02,050
I mean of all of the

1085
01:01:02,260 --> 01:01:03,190
hypothesis you've seen

1086
01:01:03,400 --> 01:01:04,790
during this entire procedure,

1087
01:01:05,040 --> 01:01:05,950
pick the one with the

1088
01:01:06,150 --> 01:01:07,720
lowest cross validation error

1089
01:01:07,960 --> 01:01:10,530
that you saw; okay?

1090
01:01:10,710 --> 01:01:11,850
So that's forward selection.

1091
01:01:35,290 --> 01:01:37,630
So let's see, just to give this a name,

1092
01:01:37,840 --> 01:01:39,010
this is an incidence of what's

1093
01:01:39,210 --> 01:01:43,940
called wrapper feature selection.

1094
01:01:47,860 --> 01:01:51,350
And the term wrapper comes from the fact that

1095
01:01:51,600 --> 01:01:53,830
this feature selection algorithm that I just described

1096
01:01:54,070 --> 01:01:55,770
is a forward selection or forward search.

1097
01:01:56,020 --> 01:01:59,040
It's a piece of software that you write that wraps

1098
01:01:59,250 --> 01:02:00,780
around your learning algorithm.

1099
01:02:01,030 --> 01:02:03,130
In the sense that to perform forward selection,

1100
01:02:03,350 --> 01:02:05,660
you need to repeatedly make cause

1101
01:02:05,960 --> 01:02:10,230
to your learning algorithm to train your model,

1102
01:02:10,540 --> 01:02:13,740
using different subsets of features;

1103
01:02:14,270 --> 01:02:16,520
okay? So this is called wrapper model feature selection.

1104
01:02:16,960 --> 01:02:19,820
And it tends to be somewhat computationally expensive

1105
01:02:20,210 --> 01:02:21,850
because as you're performing the search process,

1106
01:02:22,100 --> 01:02:24,050
you're repeatedly training your learning

1107
01:02:24,240 --> 01:02:26,180
algorithm over and over and over on all of these

1108
01:02:26,380 --> 01:02:28,180
different subsets of features.

1109
01:02:30,530 --> 01:02:31,790
Let's just mention also,

1110
01:02:32,070 --> 01:02:34,010
there is a variation of this called

1111
01:02:34,210 --> 01:02:39,630
backward search or backward selection,

1112
01:02:40,050 --> 01:02:43,930
which is where you start with f

1113
01:02:44,140 --> 01:02:48,080
equals the entire set of features,

1114
01:02:49,460 --> 01:02:59,830
and you delete features one at a time; okay?

1115
01:03:00,210 --> 01:03:05,800
So that's backward search or backward selection.

1116
01:03:06,340 --> 01:03:09,300
And this is another feature

1117
01:03:09,490 --> 01:03:10,870
selection algorithm that you might use.

1118
01:03:12,620 --> 01:03:15,430
Part of whether this makes sense is really

1119
01:03:15,730 --> 01:03:17,550
there will be problems where it

1120
01:03:17,760 --> 01:03:18,980
really doesn't even make sense to

1121
01:03:19,180 --> 01:03:21,100
initialize f to be the set of all features.

1122
01:03:21,440 --> 01:03:24,950
So if you have 100 training examples and 10,000 features,

1123
01:03:25,680 --> 01:03:27,200
which may well happen

1124
01:03:27,550 --> 01:03:32,460
100 emails and 10,000 training 10,000 features in email,

1125
01:03:32,680 --> 01:03:33,890
then 100 training examples

1126
01:03:34,150 --> 01:03:35,540
then depending on the

1127
01:03:35,730 --> 01:03:36,760
learning algorithm you're using,

1128
01:03:36,940 --> 01:03:37,880
it may or may not make sense to

1129
01:03:38,060 --> 01:03:40,350
initialize the set f to be all features,

1130
01:03:40,610 --> 01:03:42,500
and train them all by using all features.

1131
01:03:42,780 --> 01:03:43,640
And if it doesn't make sense,

1132
01:03:43,840 --> 01:03:45,250
then you can train them all by using all features;

1133
01:03:45,430 --> 01:03:47,300
then forward selection would be more common.

1134
01:03:49,600 --> 01:03:54,040
So let's see.

1135
01:03:54,530 --> 01:03:55,870
Wrapper model feature selection algorithms

1136
01:03:56,070 --> 01:03:57,330
tend to work well.

1137
01:03:57,650 --> 01:04:00,430
And in particular, they actually often work better

1138
01:04:00,640 --> 01:04:02,310
than a different class of algorithms

1139
01:04:02,510 --> 01:04:03,600
I'm gonna talk about now.

1140
01:04:03,800 --> 01:04:04,600
But their main disadvantage is that

1141
01:04:04,760 --> 01:04:06,210
they're computationally very expensive.

1142
01:04:08,750 --> 01:04:10,680
Do you have any questions about this before

1143
01:04:12,990 --> 01:04:16,400
I talk about the other? Yeah?

1144
01:04:16,600 --> 01:04:18,710
Instructor (Andrew Ng):Yeah yes, you're actually right.

1145
01:04:19,060 --> 01:04:21,060
So forward search and backward search,

1146
01:04:21,330 --> 01:04:22,660
both of these are searcheristics,

1147
01:04:22,830 --> 01:04:26,550
and you cannot but for either of these you cannot

1148
01:04:26,740 --> 01:04:28,470
guarantee they'll find the best subset of features.

1149
01:04:28,890 --> 01:04:32,530
It actually turns out that under many formulizations

1150
01:04:32,800 --> 01:04:33,990
of the feature selection problems

1151
01:04:34,200 --> 01:04:35,680
it actually turns out to be an empty heart problem,

1152
01:04:35,880 --> 01:04:37,440
to find the best subset of features.

1153
01:04:40,200 --> 01:04:41,530
But in practice,

1154
01:04:41,760 --> 01:04:42,920
forward selection backward

1155
01:04:43,090 --> 01:04:44,360
selection work fine,

1156
01:04:44,560 --> 01:04:45,690
and you can also envision other search

1157
01:04:45,870 --> 01:04:47,660
algorithms where you sort of have other

1158
01:04:47,850 --> 01:04:49,150
methods to search through the space up

1159
01:04:49,320 --> 01:04:51,360
to the end possible feature subsets.

1160
01:04:51,910 --> 01:04:58,710
So let's see.

1161
01:05:06,220 --> 01:05:08,240
Wrapper feature selection tends to work well

1162
01:05:08,470 --> 01:05:10,450
when you can afford to do it computationally.

1163
01:05:11,480 --> 01:05:15,140
But for problems such as text classification

1164
01:05:15,480 --> 01:05:17,550
it turns out for text classification specifically

1165
01:05:17,960 --> 01:05:19,520
because you have so many features,

1166
01:05:19,770 --> 01:05:21,560
and easily have 50,000 features.

1167
01:05:21,910 --> 01:05:24,510
Forward selection would be very, very expensive.

1168
01:05:24,760 --> 01:05:27,570
So there's a different class of algorithms

1169
01:05:27,790 --> 01:05:32,150
that will give you that tends not to do

1170
01:05:32,380 --> 01:05:34,310
as well in the sense of generalization error.

1171
01:05:34,630 --> 01:05:36,740
So you tend to learn the hypothesis that works less well,

1172
01:05:37,210 --> 01:05:39,830
but is computationally much less expensive.

1173
01:05:40,490 --> 01:05:44,540
And these are called the filter

1174
01:05:47,270 --> 01:05:49,300
feature selection methods.

1175
01:05:49,930 --> 01:05:53,270
And the basic idea is that

1176
01:05:53,800 --> 01:06:00,350
for each feature i will compute

1177
01:06:04,320 --> 01:06:25,590
some measure of how informative xi is about y; okay?

1178
01:06:25,900 --> 01:06:26,610
And to do this,

1179
01:06:26,820 --> 01:06:28,120
we'll use some simple heuristics;

1180
01:06:28,540 --> 01:06:29,960
for every feature

1181
01:06:30,190 --> 01:06:33,670
we'll just try to compute some rough estimate or compute

1182
01:06:33,750 --> 01:06:52,980
some measure of how informative xi is about y.

1183
01:06:54,070 --> 01:06:56,180
So there are many ways you can do this.

1184
01:06:56,410 --> 01:06:58,380
One way you can choose is to just compute

1185
01:06:58,580 --> 01:07:00,490
the correlation between xi and y.

1186
01:07:00,690 --> 01:07:02,430
And just for each of your features just see how

1187
01:07:02,650 --> 01:07:05,910
correlated this is with your class label y.

1188
01:07:06,400 --> 01:07:10,190
And then you just pick the top k most correlated features.

1189
01:07:12,790 --> 01:07:15,740
Another way to do this

1190
01:07:44,910 --> 01:07:53,310
for the case of text classification,

1191
01:07:53,540 --> 01:07:54,760
there's one other method,

1192
01:07:54,970 --> 01:07:56,330
which especially for this k features I guess

1193
01:07:56,570 --> 01:08:02,010
there's one other informative measure that's used

1194
01:08:02,230 --> 01:08:05,320
very commonly, which is called major information.

1195
01:08:11,170 --> 01:08:15,050
I'm going to tell you some of these ideas in problem sets,

1196
01:08:15,530 --> 01:08:17,130
but I'll just say this very briefly.

1197
01:08:17,520 --> 01:08:20,170
So the major information between feature xi and y

1198
01:08:22,460 --> 01:08:24,380
I'll just write out the definition, I guess.

1199
01:08:27,540 --> 01:08:29,530
Let's say this is text classification,

1200
01:08:29,760 --> 01:08:31,730
so x can take on two values, 0, 1;

1201
01:08:32,240 --> 01:08:34,980
the major information between xi and y is

1202
01:08:35,180 --> 01:08:37,080
to find out some overall possible values of x;

1203
01:08:37,480 --> 01:08:39,330
some overall possible values of y

1204
01:08:40,120 --> 01:08:52,270
times the distribution times that.

1205
01:08:53,110 --> 01:09:00,850
Where all of these distributions

1206
01:09:01,120 --> 01:09:03,610
where so the joint distribution over xi and y,

1207
01:09:04,120 --> 01:09:06,140
you would estimate from your training data

1208
01:09:12,750 --> 01:09:14,840
all of these things you would use, as well.

1209
01:09:15,160 --> 01:09:17,230
You would estimate from the training data what is

1210
01:09:17,430 --> 01:09:18,690
the probability that x is 0,

1211
01:09:18,910 --> 01:09:20,080
what's the probability that x is one,

1212
01:09:20,260 --> 01:09:22,030
what's the probability that x is 0, y is 0,

1213
01:09:22,230 --> 01:09:24,790
x is one; y is 0, and so on.

1214
01:09:25,950 --> 01:09:33,300
So it turns out there's a standard information theoretic

1215
01:09:33,580 --> 01:09:36,130
measure of how different probability distributions are.

1216
01:09:36,600 --> 01:09:38,590
And I'm not gonna prove this here.

1217
01:09:38,810 --> 01:09:45,560
But it turns out that this major information is actually

1218
01:09:51,720 --> 01:09:56,260
so the standard measure of how different distributions are;

1219
01:09:56,480 --> 01:09:57,830
called the K-L divergence.

1220
01:09:58,110 --> 01:09:59,940
When you take a class in information theory,

1221
01:10:00,220 --> 01:10:02,080
you have seen concepts of mutual information

1222
01:10:02,310 --> 01:10:03,360
in the K-L divergence,

1223
01:10:03,590 --> 01:10:04,630
but if you haven't, don't worry about it.

1224
01:10:04,830 --> 01:10:06,340
Just the intuition is there's something

1225
01:10:06,540 --> 01:10:08,530
called K-L divergence that's a formal measure of

1226
01:10:08,770 --> 01:10:10,360
how different two

1227
01:10:10,570 --> 01:10:11,910
probability distributions are.

1228
01:10:12,260 --> 01:10:13,790
And mutual information is a measure

1229
01:10:14,030 --> 01:10:20,470
for how different the joint distribution is of x and y;

1230
01:10:21,170 --> 01:10:23,810
from the distribution you would get

1231
01:10:24,080 --> 01:10:24,960
if you were to assume they

1232
01:10:25,170 --> 01:10:27,380
were independent; okay?

1233
01:10:27,560 --> 01:10:28,870
So if x and y were independent,

1234
01:10:29,440 --> 01:10:32,950
then p of x, y would be equal to p of x times p of y.

1235
01:10:33,660 --> 01:10:35,540
And so you know, this distribution

1236
01:10:35,800 --> 01:10:37,220
and this distribution would be identical,

1237
01:10:37,540 --> 01:10:38,950
and the K-L divergence would be 0.

1238
01:10:39,270 --> 01:10:42,860
In contrast, if x and y were very non-independent

1239
01:10:43,150 --> 01:10:44,400
in other words, if x and y are

1240
01:10:44,630 --> 01:10:46,020
very informative about each other,

1241
01:10:46,350 --> 01:10:48,680
then this K-L divergence will be large.

1242
01:10:49,090 --> 01:10:51,350
And so mutual information is a formal measure

1243
01:10:51,600 --> 01:10:54,670
of how non-independent x and y are.

1244
01:10:55,120 --> 01:10:56,300
And if x and y are

1245
01:10:56,600 --> 01:10:57,650
highly non-independent

1246
01:10:57,950 --> 01:11:00,240
then that means that x will presumably

1247
01:11:00,500 --> 01:11:01,570
tell you something about y,

1248
01:11:01,840 --> 01:11:03,730
and so they'll have large mutual information.

1249
01:11:04,030 --> 01:11:07,270
And this measure of information will tell you

1250
01:11:07,540 --> 01:11:08,870
x might be a good feature.

1251
01:11:09,620 --> 01:11:10,980
And you get to play with some of these

1252
01:11:11,170 --> 01:11:12,600
ideas more in the problem sets.

1253
01:11:12,790 --> 01:11:13,940
So I won't say much more about it.

1254
01:11:14,200 --> 01:11:17,710
And what you do then is

1255
01:11:17,920 --> 01:11:19,800
having chosen some measure like

1256
01:11:20,020 --> 01:11:22,180
correlation or major information or something else,

1257
01:11:22,480 --> 01:11:29,540
you then pick the top k features;

1258
01:11:30,140 --> 01:11:33,140
meaning that you compute correlation between xi and y

1259
01:11:33,350 --> 01:11:34,900
for all the features of mutual information

1260
01:11:35,090 --> 01:11:36,450
xi and y for all the features.

1261
01:11:36,730 --> 01:11:38,960
And then you include in your learning algorithm

1262
01:11:39,230 --> 01:11:42,400
the k features of the largest correlation with the label

1263
01:11:42,670 --> 01:11:44,930
or the largest mutual information label, whatever.

1264
01:11:45,340 --> 01:11:47,330
And to choose k, you can actually

1265
01:11:55,200 --> 01:11:58,090
use cross validation, as well; okay?

1266
01:11:58,300 --> 01:12:00,080
So you would take all your features,

1267
01:12:00,390 --> 01:12:03,040
and sort them in decreasing order of mutual information.

1268
01:12:03,250 --> 01:12:05,880
And then you'd try using just the top one feature,

1269
01:12:06,160 --> 01:12:08,710
the top two features, the top three features, and so on.

1270
01:12:08,960 --> 01:12:11,690
And you decide how many features includes

1271
01:12:11,970 --> 01:12:17,350
using cross validation; okay?

1272
01:12:17,550 --> 01:12:18,540
Or you can sometimes you can

1273
01:12:18,720 --> 01:12:20,420
just choose this by hand, as well.

1274
01:12:22,440 --> 01:12:35,210
Okay. Questions about this? Okay. Cool. Great.

1275
01:12:35,430 --> 01:12:37,620
So next lecture I'll continue

1276
01:12:37,900 --> 01:12:40,100
I'll wrap up the Bayesian model selection,

1277
01:12:40,190 --> 01:12:41,130
but less close to the end

