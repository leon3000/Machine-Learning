1
00:00:16,050 --> 00:00:21,320
机器学习--第17讲

2
00:00:21,420 --> 00:00:22,610
好  早上好 欢迎回来

3
00:00:22,710 --> 00:00:25,520
所以我希望大家过了一个

4
00:00:25,600 --> 00:00:26,390
很愉快的感恩节假期

5
00:00:26,480 --> 00:00:28,420
习题集后

6
00:00:28,490 --> 00:00:29,980
我怀疑我们许多人需要一个

7
00:00:30,060 --> 00:00:34,390
前几天通过电子邮件

8
00:00:34,460 --> 00:00:37,950
宣布的一个快速公告

9
00:00:38,040 --> 00:00:40,590
今天下午我们将在讲座之前要做一个录音

10
00:00:40,670 --> 00:00:42,600
所以我周三不会在这里

11
00:00:42,680 --> 00:00:44,080
我们将提前本星期三的演讲录音的时间

12
00:00:44,160 --> 00:00:45,360
如果你今天下午有空

13
00:00:45,450 --> 00:00:47,820
请在这个时间过来

14
00:00:47,910 --> 00:00:51,660
它会在下午3:45

15
00:00:51,740 --> 00:00:56,680
在Skilling礼堂

16
00:00:56,770 --> 00:00:58,630
Skilling193在3:45

17
00:00:58,720 --> 00:01:01,730
但当然  你也可以在往常一样

18
00:01:01,830 --> 00:01:03,170
在通常时间来上课  或像往常一样在网上看

19
00:01:05,710 --> 00:01:08,680
好的  欢迎回来

20
00:01:08,780 --> 00:01:10,430
我今天想要做的是

21
00:01:10,520 --> 00:01:12,370
继续我们的讨论MDP中的强化学习

22
00:01:12,470 --> 00:01:14,090
今天我要复习这个长期的话题

23
00:01:14,180 --> 00:01:16,920
所以今天的讲座

24
00:01:17,010 --> 00:01:19,590
大部分时间将继续讲MDP

25
00:01:19,700 --> 00:01:24,400
尤其是  解决状态MDP的算法

26
00:01:24,490 --> 00:01:27,380
所以我会

27
00:01:27,460 --> 00:01:28,730
简单地谈谈离散化

28
00:01:28,830 --> 00:01:31,480
我会花很多时间谈论

29
00:01:31,580 --> 00:01:35,090
"模型" MDP 的同化型

30
00:01:35,210 --> 00:01:38,320
然后谈谈拟合值迭代算法

31
00:01:38,410 --> 00:01:42,210
和建立在上面的两个函数

32
00:01:42,290 --> 00:01:46,140
然后希望

33
00:01:46,240 --> 00:01:47,530
我将有时间讲第二个算法

34
00:01:47,620 --> 00:01:49,840
近似政策迭代

35
00:01:49,950 --> 00:01:54,310
先回顾一下  好的  在以前的讲座中

36
00:01:54,420 --> 00:01:57,670
我定义了强化学习的问题

37
00:01:57,770 --> 00:02:01,080
我定义了MDP

38
00:02:01,170 --> 00:02:06,470
所以让我回顾一下那个符号

39
00:02:06,580 --> 00:02:10,660
我说  一个MDP或马氏决策过程  是一个五项集合

40
00:02:10,760 --> 00:02:16,220
元组  包括那些东西

41
00:02:16,320 --> 00:02:20,790
和上一次的运行示例是这一个

42
00:02:20,890 --> 00:02:25,860
好的  改编自Russell

43
00:02:25,930 --> 00:02:28,340
和Norvig的(AI)人工智能教科书

44
00:02:28,440 --> 00:02:34,270
所以  在这个例子中  我使用的MDP

45
00:02:34,370 --> 00:02:38,040
它有11个状态  因此

46
00:02:38,130 --> 00:02:41,920
那是S的位置 行动的罗盘方向为:

47
00:02:42,020 --> 00:02:43,950
北部  南部  东部和西部

48
00:02:44,040 --> 00:02:48,620
状态转移概率是捕捉

49
00:02:48,750 --> 00:02:51,990
每一个转移状态的机会

50
00:02:52,100 --> 00:02:54,120
当你在任何给定的状态下

51
00:02:54,230 --> 00:02:57,030
采取任何行动时

52
00:02:57,150 --> 00:03:01,360
因此在我们的例子中

53
00:03:01,470 --> 00:03:03,520
我们的机器人在这个特定范围内游散

54
00:03:03,620 --> 00:03:05,820
随机动力  我们说  如果你采取行动

55
00:03:05,930 --> 00:03:07,350
向北走和向南走

56
00:03:07,440 --> 00:03:10,100
你有一个实际的0.8机会北上

57
00:03:10,220 --> 00:03:11,710
0.1的机会向左转变方向

58
00:03:11,800 --> 00:03:14,540
0.1的机会向右转变方向

59
00:03:14,670 --> 00:03:18,010
所以说  机器人的嘈杂的动态模型[无声]

60
00:03:18,120 --> 00:03:23,450
并且奖励函数是+ / -1在吸收状态

61
00:03:23,570 --> 00:03:37,920
-0.02在其他地方

62
00:03:38,030 --> 00:03:42,070
这是一个MDP的一个例子

63
00:03:42,170 --> 00:03:43,880
这五样东西是什么 哦  我用

64
00:03:43,970 --> 00:03:49,890
一个折扣因子G通常是略小于1

65
00:03:50,000 --> 00:03:54,880
所以这是0.99

66
00:03:54,980 --> 00:03:59,580
而且使我们的目标是找到的政策

67
00:03:59,700 --> 00:04:03,740
调控政策是在?那是一个函数映射

68
00:04:03,840 --> 00:04:07,370
告诉我们在每一个状态采取什么行动

69
00:04:07,720 --> 00:04:10,660
并且我们的目标是找到一个策略

70
00:04:10,740 --> 00:04:14,020
来最大化我们的总收益的预期值

71
00:04:14,110 --> 00:04:17,060
因此  我们要找到一个政策 那么

72
00:04:17,140 --> 00:04:20,820
让我们来看看

73
00:04:20,910 --> 00:04:36,300
我们定义的价值函数Vp(s)等于这个

74
00:04:36,390 --> 00:04:39,720
我们说  政策的价值π 状态S


75
00:04:39,820 --> 00:04:43,620
是折扣奖励的总和的预期值所给定的

76
00:04:43,700 --> 00:04:45,630
在执行政策的条件下?

77
00:04:45,740 --> 00:04:51,570
你在状态S下启动了机器人

78
00:04:51,650 --> 00:04:56,380
我们找到政策的战略是由两个步骤组成

79
00:04:56,460 --> 00:05:00,360
因此我们的目标是找到一个很好的政策

80
00:05:00,450 --> 00:05:12,490
最大化预期价值的贴现奖励的总和

81
00:05:12,570 --> 00:05:14,870
所以目标就是要找到一个

82
00:05:14,960 --> 00:05:18,090
可以将计算回报的预期值最大化的政策

83
00:05:18,180 --> 00:05:20,600
战略政策

84
00:05:20,690 --> 00:05:23,150
是先计算最优值函数

85
00:05:23,240 --> 00:05:25,530
我记为V *(s)

86
00:05:25,610 --> 00:05:28,910
它是那样定义的

87
00:05:29,000 --> 00:05:31,410
它是任何政策可以得到的最大价值

88
00:05:31,520 --> 00:05:48,680
例如  该MDP的最优值函数

89
00:05:48,770 --> 00:06:02,030
看起来像这样 所以  换句话说

90
00:06:02,120 --> 00:06:04,910
从这些任何状态开始

91
00:06:05,000 --> 00:06:07,880
你的折扣奖励的总和的预期值

92
00:06:07,970 --> 00:06:14,140
因此这是V *  我们也说过

93
00:06:14,240 --> 00:06:17,980
一旦你找到了V

94
00:06:18,070 --> 00:06:21,560
你可以用它来计算出最佳的政策

95
00:06:36,280 --> 00:06:38,210
所以一旦你找到V

96
00:06:38,320 --> 00:06:41,960
我们可以使用这个等式

97
00:06:42,060 --> 00:06:45,110
找到最佳的价值π*该算法的

98
00:06:46,190 --> 00:06:50,170
最后一块是贝尔曼方程

99
00:06:50,240 --> 00:06:53,430
我们知道  V *  你可以在状态S

100
00:06:53,520 --> 00:06:56,140
得到的最优的折扣奖励总和

101
00:06:56,220 --> 00:06:57,070
是等于你在状态+ G开始时

102
00:06:57,170 --> 00:07:00,270
获得的立即回报总和

103
00:07:00,350 --> 00:07:04,740
(你可以采取最优的行动)

104
00:07:04,820 --> 00:07:14,400
(你的未来折扣奖励的总和)

105
00:07:14,480 --> 00:07:18,170
(从状态S(p)开始的未来收益

106
00:07:18,250 --> 00:07:20,530
这是你可能过渡到1(S)后

107
00:07:20,620 --> 00:07:24,970
因此这给了我们一个值迭代算法

108
00:07:25,040 --> 00:07:30,840
这实质上第VI

109
00:07:30,940 --> 00:07:33,140
我把值迭代简写为VI

110
00:07:33,230 --> 00:07:35,660
所以在值迭代算法

111
00:07:35,760 --> 00:07:38,030
在VI中  你只采用贝尔曼方程

112
00:07:38,090 --> 00:07:39,930
并反复做这个

113
00:07:49,090 --> 00:07:52,760
因此  初始化一些猜测的价值函数

114
00:07:52,860 --> 00:07:55,320
然后初始化一个零的总和四舍五入的猜测

115
00:07:55,390 --> 00:07:57,520
然后重复执行此更新所有状态

116
00:07:57,590 --> 00:07:59,470
我上一次说过

117
00:07:59,550 --> 00:08:03,000
如果你这样反复做

118
00:08:03,080 --> 00:08:05,230
那么V(S)将收敛到最优值函数

119
00:08:05,320 --> 00:08:08,610
发现V *(S)

120
00:08:08,710 --> 00:08:10,710
你可以计算出最佳的政策?

121
00:08:10,800 --> 00:08:16,900
最后一个我想要回顾的是

122
00:08:17,010 --> 00:08:32,910
是政策的迭代算法

123
00:08:33,010 --> 00:08:35,060
我们重复以下两个步骤

124
00:08:39,440 --> 00:08:41,770
让我们看看  给定一个随机的初始政策

125
00:08:41,860 --> 00:08:44,280
我们将解出Vp

126
00:08:44,370 --> 00:08:46,480
我们会解决的具体政策的价值函数

127
00:08:46,560 --> 00:08:49,980
所以这意味着为每一个状态

128
00:08:50,080 --> 00:08:51,690
计算预期的折扣回报的总和

129
00:08:51,800 --> 00:08:54,890
如果你执行那个政策?从状态

130
00:08:55,010 --> 00:08:59,130
然后另外一个

131
00:08:59,220 --> 00:09:32,360
政策迭代的步骤

132
00:09:32,440 --> 00:09:35,490
是找到政策的价值函数

133
00:09:35,580 --> 00:09:37,670
你再更新那个政策

134
00:09:37,760 --> 00:09:39,660
假装你已经找到了

135
00:09:39,720 --> 00:09:42,680
最优值函数  V

136
00:09:42,780 --> 00:09:44,480
然后你重复执行这两个步骤

137
00:09:44,560 --> 00:09:46,030
根据你的现行政策解出价值函数

138
00:09:46,130 --> 00:09:48,720
然后假装这是最优值函数

139
00:09:48,800 --> 00:09:51,430
并解决给定值函数的政策

140
00:09:51,520 --> 00:09:53,110
你反复更新的

141
00:09:53,200 --> 00:09:57,060
价值函数

142
00:09:57,150 --> 00:10:01,430
或根据该值函数来解出政策

143
00:10:01,490 --> 00:10:05,190
我上一次说  这也将导致

144
00:10:05,270 --> 00:10:08,270
估计价值函数V收敛至V

145
00:10:08,340 --> 00:10:11,220
这将导致p收敛至?*  最优的政策

146
00:10:11,340 --> 00:10:16,210
因此  这些都是基于

147
00:10:16,290 --> 00:10:17,310
我们上次的演讲从MDP开始

148
00:10:17,390 --> 00:10:20,860
并推出了很多新的符号标志

149
00:10:20,940 --> 00:10:24,330
只是再次总结了这些东西

150
00:10:24,450 --> 00:10:26,210
我现在要做的  我今天接下来的讲座

151
00:10:26,300 --> 00:10:29,560
实际上是基于这两种算法的

152
00:10:29,660 --> 00:10:34,450
所以我认为  如果关于这一块你有任何问题

153
00:10:34,550 --> 00:10:37,130
现在问  因为我得继续讲下去了

154
00:10:37,210 --> 00:10:37,770
请说

155
00:10:37,860 --> 00:10:38,750
学生:我不明白这两种算法

156
00:10:38,810 --> 00:10:40,930
有很大的不同?

157
00:10:43,930 --> 00:10:47,090
我明白  对的  所以呀

158
00:10:47,170 --> 00:10:49,280
你看到它们是不同的?OK

159
00:10:49,370 --> 00:10:52,840
它是如何的不同 让我们来看看

160
00:10:52,930 --> 00:10:56,170
因此  这里有一个区别

161
00:10:56,250 --> 00:10:58,810
我并没有说这个  因为今天不再使用它

162
00:10:58,900 --> 00:11:01,860
因此  值迭代和迭代政策是不同的算法

163
00:11:01,940 --> 00:11:06,290
在政策迭代的这一步

164
00:11:06,370 --> 00:11:09,210
你给定一个固定的政策

165
00:11:09,290 --> 00:11:12,890
你要解出该政策的价值函数

166
00:11:12,980 --> 00:11:18,450
所以你给定一些固定的政策?

167
00:11:18,540 --> 00:11:22,330
这意味着从该状态的行动一些函数映射

168
00:11:22,400 --> 00:11:25,410
所以给你的一些政策之类的

169
00:11:31,260 --> 00:11:36,320
这只是一些政策  它不是一个伟大的政策

170
00:11:36,420 --> 00:11:41,950
而在我包围的这一步

171
00:11:42,050 --> 00:12:02,010
我们已经找到S的??

172
00:12:02,110 --> 00:12:04,260
这意味着每一个状态

173
00:12:04,360 --> 00:12:06,860
你需要计算预期贴现回报的总和

174
00:12:06,970 --> 00:12:09,530
或者如果执行这个具体的政策

175
00:12:09,640 --> 00:12:13,790
并在该状态的MDP开始

176
00:12:13,890 --> 00:12:17,810
所以  我上次展示了这个

177
00:12:17,890 --> 00:12:20,640
我今天不会详细说明了

178
00:12:20,730 --> 00:12:23,470
所以我上次说过

179
00:12:23,570 --> 00:12:26,300
你实际上可以通过求解线性方程组系统

180
00:12:26,380 --> 00:12:29,770
解出Vp 这里有Vp的贝尔曼方程的

181
00:12:29,870 --> 00:12:32,480
一种形式  结果是  如果你写了这一点

182
00:12:32,550 --> 00:12:34,890
你最终得到一个11个未知数的

183
00:12:34,980 --> 00:12:37,430
11个方程的线性系统

184
00:12:37,520 --> 00:12:41,460
并且你实际上能够解出

185
00:12:41,520 --> 00:12:43,360
一项固定政策的价值函数

186
00:12:43,430 --> 00:12:49,010
通过解11个变量和11个约束的

187
00:12:49,090 --> 00:12:52,820
线性方程系统  所以这就是策略迭代;

188
00:12:52,900 --> 00:12:57,470
然而在值迭代中  回到黑板上

189
00:12:57,570 --> 00:13:00,610
在值迭代中  你稍微反复执行这个更新

190
00:13:00,710 --> 00:13:02,090
在这里你更新一个状态的值

191
00:13:02,180 --> 00:13:05,550
因此  我希望你们能够明白

192
00:13:05,640 --> 00:13:07,020
这些算法是不同的

193
00:13:10,880 --> 00:13:12,320
学生:如果是在这种情况 在原子包

194
00:13:12,420 --> 00:13:13,670
假设我们永远

195
00:13:13,730 --> 00:13:15,560
无法得到这些状态呢?

196
00:13:15,640 --> 00:13:20,000
是的 这里有为这个

197
00:13:20,080 --> 00:13:21,560
[无声]要解决的事情

198
00:13:21,640 --> 00:13:22,830
例如  让数字看起来漂亮点

199
00:13:22,900 --> 00:13:24,440
但我不想要在上面花太多时间

200
00:13:24,520 --> 00:13:26,300
但是  那么这个假设是

201
00:13:26,390 --> 00:13:28,290
一旦你进入了吸收的状态

202
00:13:28,400 --> 00:13:30,530
那么整个就结束了  或者  没有更多的回报

203
00:13:30,610 --> 00:13:33,120
在你能想到的另一种方式

204
00:13:33,200 --> 00:13:35,420
来思考的吸收状态之后

205
00:13:35,500 --> 00:13:37,700
吸收状态在数学上是等价的

206
00:13:37,800 --> 00:13:39,690
你可以把吸收状态看作为从1

207
00:13:39,780 --> 00:13:44,680
到总共12个状态的过渡概率

208
00:13:44,770 --> 00:13:47,900
那么  一旦你处于第12个状态

209
00:13:47,980 --> 00:13:50,630
你始终保持在这12状态

210
00:13:50,710 --> 00:13:52,740
并正在从那里有没有进一步的奖励

211
00:13:52,850 --> 00:13:55,120
如果你愿意  你可以认为这实际上

212
00:13:55,210 --> 00:13:58,590
一个有12个状态

213
00:13:58,680 --> 00:14:01,920
而不是11个状态的MDP  而第12个状态

214
00:14:02,000 --> 00:14:03,220
是你永远停留的零成本的吸收状态

215
00:14:03,320 --> 00:14:05,680
有其他问题么?

216
00:14:05,760 --> 00:14:09,500
嗯  请说

217
00:14:09,580 --> 00:14:11,250
学生: Bellman方程在哪里

218
00:14:11,350 --> 00:14:16,320
[无声]的最优值[无声]?

219
00:14:16,430 --> 00:14:22,560
小子  是的 好吧  这个贝尔曼方程

220
00:14:22,650 --> 00:14:27,640
我指着的这个方程

221
00:14:27,750 --> 00:14:32,440
我想给它做最后一次的阐述

222
00:14:35,070 --> 00:14:39,720
我会用一句话概括它

223
00:14:39,820 --> 00:14:42,870
那就是  我得到预期的总收益

224
00:14:42,970 --> 00:14:44,800
我希望从状态a得到的东西

225
00:14:44,900 --> 00:14:48,330
等于我的立即回报

226
00:14:48,430 --> 00:14:52,020
即我从一个状态开始获得的奖励

227
00:14:52,110 --> 00:14:54,430
让我们来看看 如果我总结状态

228
00:14:54,510 --> 00:14:56,780
我要去得到第一笔报酬

229
00:14:56,860 --> 00:14:58,210
然后我可以过渡到其他一些状态

230
00:14:58,320 --> 00:15:01,400
然后从其他状态  我会得到一些额外的奖励

231
00:15:01,500 --> 00:15:03,710
因此  贝尔曼方程把那个总和

232
00:15:03,800 --> 00:15:06,360
分解成两个部分 它说  一个状态的价值是

233
00:15:06,450 --> 00:15:17,600
等于你获得的即时奖励  嗯 ?V*(s)其实是

234
00:15:31,190 --> 00:15:34,570
等于+ G的  所以这是V*(s)

235
00:15:34,680 --> 00:15:38,030
所以贝尔曼的方程把V*(s)中断成两个项

236
00:15:38,110 --> 00:15:40,990
并说  还有的这第一个项

237
00:15:41,070 --> 00:15:45,120
是立即奖励  然后+ G

238
00:15:45,200 --> 00:15:47,640
(你在未来得到的奖励)

239
00:15:47,750 --> 00:15:49,640
结果它和第二排是相等的

240
00:15:49,760 --> 00:15:53,510
我以前的讲座中

241
00:15:53,600 --> 00:15:56,200
花了更多的时间证明它

242
00:15:56,290 --> 00:15:58,720
但是  希望  这次讲座的目的

243
00:15:58,790 --> 00:16:00,160
如果你不确定这个东西

244
00:16:00,240 --> 00:16:01,250
如果你不记得它的证明

245
00:16:01,340 --> 00:16:03,030
那么请你记住我的话

246
00:16:03,110 --> 00:16:06,620
这个等式是成立的  因为我等下

247
00:16:06,690 --> 00:16:09,870
也会稍微用到它

248
00:16:09,990 --> 00:16:13,250
然后讲义也进一步

249
00:16:13,340 --> 00:16:14,850
介绍了为什么这个等式成立的理由

250
00:16:14,930 --> 00:16:18,650
但现在  是啊

251
00:16:18,740 --> 00:16:20,320
现在记住我的话

252
00:16:20,410 --> 00:16:21,250
它是成立的

253
00:16:21,340 --> 00:16:23,430
因为我们今天晚些时候也会使用到它

254
00:16:25,140 --> 00:16:35,170
学生:[听不清]

255
00:16:35,260 --> 00:16:40,440
它会被转成[听不清]

256
00:16:40,550 --> 00:16:42,600
其实真正的问题是 是否在政策迭代中

257
00:16:42,690 --> 00:16:44,340
我们是否表现?暗中地  使用V(S)

258
00:16:44,420 --> 00:16:50,000
将成为相当于估值

259
00:16:50,100 --> 00:16:52,250
得到的答复是没有排序

260
00:16:52,350 --> 00:16:55,690
让我们来看看 策略迭代

261
00:16:55,800 --> 00:17:00,030
和值迭代算法密切相关的算法

262
00:17:00,150 --> 00:17:01,980
这是真正的  它们之间实际上

263
00:17:02,080 --> 00:17:03,770
是一个统一体

264
00:17:03,870 --> 00:17:08,560
但是  事实证明  哦  不

265
00:17:08,650 --> 00:17:25,430
该算法是不等价的

266
00:17:26,000 --> 00:17:27,230
只有在政策迭代中

267
00:17:27,310 --> 00:17:30,160
才有一个步骤:

268
00:17:30,260 --> 00:17:32,420
你解决政策工具的价值函数是V  解出VP

269
00:17:32,510 --> 00:17:36,140
通常  你可以做到这一点

270
00:17:36,230 --> 00:17:40,530
例如  通过求解线性方程组系统

271
00:17:40,620 --> 00:17:42,800
在值迭代中  它是一个不同的算法

272
00:17:42,880 --> 00:17:45,160
是的 我希望你们理解了

273
00:17:45,230 --> 00:17:47,160
至少它看起来是不同的

274
00:17:47,270 --> 00:17:52,030
学生:[听不清] [听不清]你表示的?

275
00:17:52,110 --> 00:17:53,080
潜在的  那么你没有解决

276
00:17:53,150 --> 00:17:55,220
[无声]方程

277
00:17:57,850 --> 00:18:03,540
是啊  问题是--让我们来看看

278
00:18:03,640 --> 00:18:07,240
为了解出Vp  当你有一个固定的政策时

279
00:18:07,330 --> 00:18:09,590
这个才起作用  所以一旦你改变值函数

280
00:18:09,670 --> 00:18:12,810
如果?以及变化了  那么就难以解出它

281
00:18:12,900 --> 00:18:17,130
呀  所以以后我们将谈论一些例子

282
00:18:17,520 --> 00:18:19,650
当?是隐式的表现  但至少现在

283
00:18:19,770 --> 00:18:22,680
我觉得这里有--呀

284
00:18:22,770 --> 00:18:27,900
也许有一种重新定义东西的方法

285
00:18:27,980 --> 00:18:29,880
看到一个值迭代的映射

286
00:18:29,960 --> 00:18:31,210
但通常不这样做的

287
00:18:31,320 --> 00:18:33,640
这些被视为不同的算法

288
00:18:37,090 --> 00:18:40,230
OK  酷  都是好问题 让我继续前进

289
00:18:40,320 --> 00:18:44,690
谈谈如何概括这些连续状态的想法

290
00:18:44,790 --> 00:18:59,320
到目前为止  我们为离散状态

291
00:18:59,410 --> 00:19:04,490
或有限状态的MDP所做的一切

292
00:19:04,590 --> 00:19:06,930
例如  我们在这里有一个11个状态的

293
00:19:07,020 --> 00:19:09,550
有限集合的MDP  那么值函数

294
00:19:09,640 --> 00:19:15,810
即V(S)或我们的价值函数的估计

295
00:19:15,890 --> 00:19:17,820
V(S)  可以使用11个数字的数组表示

296
00:19:17,900 --> 00:19:20,480
因为如果你有11个状态

297
00:19:20,560 --> 00:19:22,590
价值函数需要给11个状态中的

298
00:19:22,680 --> 00:19:26,680
每一个分配一个实数

299
00:19:26,770 --> 00:19:28,710
所以使用一个11个

300
00:19:28,800 --> 00:19:33,440
数字的数组表示V(S)

301
00:19:33,500 --> 00:19:36,640
今天我们要【听不清】谈谈连续状态

302
00:19:36,720 --> 00:19:43,290
因此  举例来说  如果你想控制

303
00:19:43,370 --> 00:19:47,290
任何真正的[听不清]数字

304
00:19:47,410 --> 00:19:50,410
因此  举例来说  如果你要控制一辆车

305
00:19:50,480 --> 00:19:56,240
一辆车被定位成XYT

306
00:19:56,320 --> 00:20:01,070
作为位置和方向

307
00:20:01,150 --> 00:20:03,770
如果你想马尔可夫速度

308
00:20:03,870 --> 00:20:06,970
然后Xdot  Ydot  Tdot

309
00:20:07,050 --> 00:20:08,130
所以这些都是使取决于

310
00:20:08,220 --> 00:20:10,370
是否要对运动和位置建模

311
00:20:10,450 --> 00:20:12,120
或是否要建立动力模型

312
00:20:12,190 --> 00:20:13,960
也表示为是速度

313
00:20:14,060 --> 00:20:20,050
刚才我向你展示了一个直升机飞行视频

314
00:20:20,140 --> 00:20:21,580
使用热带雨林

315
00:20:21,670 --> 00:20:24,450
我们的学习算法

316
00:20:24,540 --> 00:20:26,450
所以直升机可以在三维空间中飞行

317
00:20:26,540 --> 00:20:29,550
而不是仅仅在2-D平面上

318
00:20:29,630 --> 00:20:35,380
状态将给予XYZ位置  FT?

319
00:20:35,480 --> 00:20:47,210
这是[无声] ?那个FT?是一个

320
00:20:47,300 --> 00:20:50,540
用于标记直升机的P [听不清]

321
00:20:50,630 --> 00:21:00,080
只是方向  如果你想

322
00:21:00,170 --> 00:21:02,350
控制直升机

323
00:21:02,440 --> 00:21:04,330
很可能要建立速度模型

324
00:21:04,470 --> 00:21:07,390
这意味着线性速度以及角速度

325
00:21:07,480 --> 00:21:09,200
所以这将是是一个12维的状态

326
00:21:09,300 --> 00:21:15,560
如果你想要一个例子  是一种乐趣

327
00:21:15,670 --> 00:21:23,830
但不寻常的是  我只是把这个作为例子

328
00:21:23,930 --> 00:21:25,840
实际上在今天的讲座中使用这个小例子

329
00:21:25,930 --> 00:21:29,240
是一个反向的钟摆为题

330
00:21:29,330 --> 00:21:31,940
这是强化学习中一个长期运行的经典

331
00:21:32,030 --> 00:21:35,040
想象你在铁路上有一辆小马车

332
00:21:35,130 --> 00:21:42,260
铁路在某点结束

333
00:21:42,340 --> 00:21:44,840
想象你把一个杆子贴在马车上

334
00:21:44,930 --> 00:21:48,570
这是一个自由的枢纽

335
00:21:48,680 --> 00:21:51,060
所以这里的杆子可以自由旋转

336
00:21:51,140 --> 00:21:55,100
你的目标是控制马车

337
00:21:55,270 --> 00:21:58,090
在这条铁路上来回移动

338
00:21:58,200 --> 00:21:59,920
以保持杆子平衡

339
00:22:00,040 --> 00:22:03,880
是啊  在这里教室里没有这样一个杆子

340
00:22:03,960 --> 00:22:06,700
但你明白我的意思

341
00:22:06,770 --> 00:22:09,390
所以你可以想象 哦  这里有一个长杆?

342
00:22:09,490 --> 00:22:10,740
学生:在角落里

343
00:22:11,030 --> 00:22:17,020
哦  谢谢 酷 所以  我没有练习它

344
00:22:17,220 --> 00:22:18,360
但你可以用一个长杆

345
00:22:18,440 --> 00:22:20,150
并且使其保持平衡

346
00:22:20,230 --> 00:22:22,350
想像你可以比我可以做的更好

347
00:22:22,410 --> 00:22:24,650
想象一下  这些都是[听不清]

348
00:22:24,700 --> 00:22:26,090
来回移动要尽量保持竿的平衡

349
00:22:26,170 --> 00:22:28,810
所以实际上你可以

350
00:22:28,870 --> 00:22:30,090
使用强化学习算法来处理

351
00:22:30,160 --> 00:22:35,870
人们【听不清】实施和发挥

352
00:22:35,950 --> 00:22:37,170
使用强化学习算法

353
00:22:37,250 --> 00:22:41,250
并且为此

354
00:22:41,330 --> 00:22:45,570
状态将是X和T

355
00:22:45,650 --> 00:22:51,930
因此X将车的位置

356
00:22:52,010 --> 00:22:59,420
并且T将是杆子的方向 极线速度和角速度

357
00:22:59,480 --> 00:23:02,190
所以实际上

358
00:23:02,390 --> 00:23:03,730
我将会使用这个例子几次

359
00:23:15,570 --> 00:23:19,160
因此  为了读取连续状态空间

360
00:23:19,250 --> 00:23:21,230
你怎么样实施一个

361
00:23:21,320 --> 00:23:23,610
比如值迭代和策略迭代的算法

362
00:23:23,710 --> 00:23:26,080
来解决MDP  并控制如汽车

363
00:23:26,160 --> 00:23:30,010
或直升机或像倒立摆的问题呢?

364
00:23:30,100 --> 00:23:32,250
因此  你可以做的一件事情是

365
00:23:32,350 --> 00:23:35,980
这也许是最简单的事情

366
00:23:36,060 --> 00:23:39,270
如果你有说一个二维的连续状态空间

367
00:23:39,330 --> 00:23:42,360
S-1和S-2是我的状态变量

368
00:23:42,440 --> 00:23:44,260
并在所有的例子

369
00:23:44,350 --> 00:23:45,910
我猜这里有4维到12维

370
00:23:46,010 --> 00:23:47,360
我在这里就画2-D

371
00:23:47,450 --> 00:23:49,830
做的最简单的事情是

372
00:23:49,910 --> 00:23:51,260
采取连续状态空间

373
00:23:51,360 --> 00:23:57,110
把它离散成若干分离的单元

374
00:24:07,570 --> 00:24:10,620
并且我使用的S-bar  来表示他们

375
00:24:10,730 --> 00:24:12,130
是离散的或他们的离散状态

376
00:24:12,180 --> 00:24:13,790
这样你就可以【听不清】

377
00:24:13,870 --> 00:24:15,490
这种有限的连续状态问题

378
00:24:15,570 --> 00:24:17,960
或状态离散集问题

379
00:24:18,050 --> 00:24:21,490
然后你可以使用政策迭代或值迭代

380
00:24:21,570 --> 00:24:32,730
来解出V *(S)-bar和?*(S)-bar

381
00:24:32,810 --> 00:24:40,440
而如果你是机器人  然后处于一定的状态

382
00:24:40,530 --> 00:24:43,360
然后你会找出它处于什么离散状态中

383
00:24:43,440 --> 00:24:45,610
在这种情况下

384
00:24:45,730 --> 00:24:49,820
这个离散dygrid单元

385
00:24:49,910 --> 00:24:53,870
这就是所谓的S -bar  然后执行

386
00:24:53,950 --> 00:24:56,480
你选择这个政策 你可以选择

387
00:24:56,570 --> 00:24:59,900
应用于离散状态给出的行动

388
00:24:59,970 --> 00:25:02,150
所以离散化也许是最直截了当的方式

389
00:25:02,250 --> 00:25:04,130
使离散状态的问题

390
00:25:04,240 --> 00:25:05,890
变成一个连续的状态问题

391
00:25:05,990 --> 00:25:08,200
有时你可以八九不离十地让它工作

392
00:25:08,290 --> 00:25:11,080
但是为什么这个不能很好地工作

393
00:25:11,170 --> 00:25:14,440
有几个原因 原因之一如下

394
00:25:14,530 --> 00:25:19,420
对于这张照片

395
00:25:19,520 --> 00:25:21,480
让我们暂时搁置强化学习

396
00:25:21,570 --> 00:25:25,140
现在只是想想回归分析

397
00:25:25,240 --> 00:25:29,810
因此  假设你有一些常量X

398
00:25:29,900 --> 00:25:37,170
并假设我有一些数据

399
00:25:37,270 --> 00:25:39,090
我想填充一个函数 Y是X的函数

400
00:25:39,200 --> 00:25:43,110
所以离散化是说

401
00:25:43,210 --> 00:25:47,550
我要去使用我的横轴Xs

402
00:25:47,610 --> 00:25:50,630
并分成若干段

403
00:25:50,720 --> 00:25:54,170
有时候  我也可以叫这些"段"为"桶"

404
00:25:54,260 --> 00:25:56,010
然后我们有时使用

405
00:25:56,090 --> 00:25:59,810
这些"桶"中的分段常量

406
00:25:59,890 --> 00:26:03,900
来粗略估计这个函数

407
00:26:03,970 --> 00:26:06,120
然后看看这个

408
00:26:06,200 --> 00:26:07,970
这显然 不是一个很好的表现形式

409
00:26:08,050 --> 00:26:09,810
对  以及当我们谈论回归的时候

410
00:26:09,910 --> 00:26:14,820
你只要选择X的一些特性

411
00:26:14,900 --> 00:26:16,320
和运行线性回归等东西

412
00:26:16,410 --> 00:26:18,520
你更好地适应这个函数

413
00:26:18,620 --> 00:26:21,420
并且感觉到  离散

414
00:26:21,520 --> 00:26:24,930
不是一个很好的源分段常数函数

415
00:26:25,020 --> 00:26:26,620
它不是一个能很好的

416
00:26:26,700 --> 00:26:29,300
表示很多东西的函数

417
00:26:29,390 --> 00:26:32,760
也有感觉到

418
00:26:32,840 --> 00:26:35,140
在不同的桶之间不是平滑的

419
00:26:35,230 --> 00:26:37,550
也没有泛化 而事实上  早在回归中

420
00:26:37,640 --> 00:26:40,910
我绝不会选择

421
00:26:40,990 --> 00:26:43,140
使用这种可视化来做回归

422
00:26:43,230 --> 00:26:44,640
这真的没有任何意义

423
00:26:44,720 --> 00:26:51,640
因此  在同样的方式  不用X  V(S)

424
00:26:51,750 --> 00:26:55,140
不用X和X的一些假设函数

425
00:26:55,240 --> 00:26:56,930
如果你有那个状态

426
00:26:57,010 --> 00:26:58,380
你想近似估计价值函数

427
00:26:58,470 --> 00:27:00,800
那么你可以用离散来解决许多问题

428
00:27:00,900 --> 00:27:02,560
但也许这不是最好的表现形式

429
00:27:02,670 --> 00:27:04,620
来表示价值函数

430
00:27:04,750 --> 00:27:11,070
并且离散的其他问题

431
00:27:11,160 --> 00:27:17,460
也许是更严肃的问题是

432
00:27:17,560 --> 00:27:19,620
往往富于奇异地称为维数的祸根

433
00:27:19,720 --> 00:27:28,180
并且观察

434
00:27:28,280 --> 00:27:34,850
如果状态空间是在RN

435
00:27:36,030 --> 00:27:40,590
如果你把每个变量离散成K个桶

436
00:27:40,680 --> 00:27:46,030
所以如果每个变量离散成K个离散值

437
00:27:46,130 --> 00:27:51,580
那么你得到的K的N次方的离散状态

438
00:27:51,680 --> 00:27:56,200
换句话说

439
00:27:56,310 --> 00:27:58,550
你最终的离散状态的数量

440
00:27:58,630 --> 00:28:03,170
呈指数增长的维问题

441
00:28:03,250 --> 00:28:06,830
因此  对于一个

442
00:28:06,930 --> 00:28:09,610
12维状态空间的直升机

443
00:28:09,670 --> 00:28:12,720
这将可能大概为100的12次方

444
00:28:12,810 --> 00:28:15,630
很大的  并且它是不可行的

445
00:28:15,720 --> 00:28:18,160
因此离散化在两个高维的状态的空间中

446
00:28:18,230 --> 00:28:21,500
不能权衡地很好

447
00:28:23,490 --> 00:28:27,750
而这个观测法实际上比机器

448
00:28:27,830 --> 00:28:30,680
和连续状态问题应用地更普遍

449
00:28:30,770 --> 00:28:34,060
例如  强化学习中的另一种

450
00:28:34,140 --> 00:28:38,210
相当知名的应用

451
00:28:38,280 --> 00:28:42,200
是工厂自动化

452
00:28:42,310 --> 00:28:45,330
如果你能想象你工厂中

453
00:28:45,440 --> 00:28:48,040
有20台机器

454
00:28:48,130 --> 00:28:49,420
机器放置在装配生产线上

455
00:28:49,510 --> 00:28:50,970
并且他们都做一些

456
00:28:51,040 --> 00:28:52,760
流水线上的一部分工作

457
00:28:52,850 --> 00:28:54,240
然后把那部分转交到不同的机器

458
00:28:54,320 --> 00:28:55,640
你要使用的

459
00:28:55,740 --> 00:28:56,980
强化学习算法

460
00:28:57,080 --> 00:28:58,840
[听不清]顺序处理

461
00:28:58,940 --> 00:29:00,170
不同事情的不同机器

462
00:29:00,270 --> 00:29:01,840
是依据你的装配线的

463
00:29:01,920 --> 00:29:03,250
可能不同的机器

464
00:29:03,340 --> 00:29:04,800
能处理不同的事情

465
00:29:04,900 --> 00:29:07,560
因此  如果你有N台机器

466
00:29:07,650 --> 00:29:10,040
并且每台机器可以有K个状态

467
00:29:10,130 --> 00:29:12,200
然后  如果你用离散化来处理

468
00:29:12,310 --> 00:29:13,700
状态的总数

469
00:29:13,780 --> 00:29:15,010
将会为K到N

470
00:29:15,130 --> 00:29:17,580
如果你有N台机器

471
00:29:17,660 --> 00:29:20,160
如果每台机器可以有K个状态

472
00:29:20,260 --> 00:29:22,620
还是那句话  你可以得到这个状态的数量

473
00:29:22,750 --> 00:29:26,450
很庞大 其他著名的例子是

474
00:29:26,560 --> 00:29:30,020
如果你有一个棋盘游戏  另一个例子是

475
00:29:30,120 --> 00:29:32,400
你想要使用的强化学习来下棋

476
00:29:32,480 --> 00:29:36,590
然后  如果棋盘游戏上有N块

477
00:29:36,680 --> 00:29:39,620
棋盘上有N块

478
00:29:39,750 --> 00:29:41,870
如果每块可位于K个位置

479
00:29:41,950 --> 00:29:44,370
那么这是一个游戏

480
00:29:44,470 --> 00:29:46,750
类似维度祸根的东西

481
00:29:46,820 --> 00:29:48,800
最终在棋盘游戏中

482
00:29:48,900 --> 00:29:50,630
离散状态的数量将会以指数形式增长

483
00:29:50,710 --> 00:29:57,850
因此  维度祸根说明

484
00:29:57,960 --> 00:30:03,490
离散化不能很好地处理高维状态空间

485
00:30:03,590 --> 00:30:05,810
或至少是离散表示法

486
00:30:05,880 --> 00:30:08,220
能很好地处理高维状态空间

487
00:30:08,300 --> 00:30:10,990
在实践中  通常将离散

488
00:30:11,050 --> 00:30:13,640
如果你有一个2维的问题

489
00:30:13,730 --> 00:30:15,120
离散通常会处理地很好

490
00:30:15,190 --> 00:30:18,000
如果你有一个3维的问题

491
00:30:18,110 --> 00:30:20,170
你经常可以让离散不会处理地太坏

492
00:30:20,270 --> 00:30:22,840
没有很多麻烦

493
00:30:22,910 --> 00:30:25,990
有了一个4维的问题

494
00:30:26,070 --> 00:30:28,870
他们可能是具有挑战性

495
00:30:28,960 --> 00:30:34,310
当你处于较高

496
00:30:34,400 --> 00:30:39,390
和高维的状态空间中时

497
00:30:39,480 --> 00:30:41,550
【听不清】你需要找到离散化

498
00:30:41,640 --> 00:30:44,080
并且处理非均匀的网格

499
00:30:44,190 --> 00:30:50,250
所以例如

500
00:30:50,340 --> 00:30:51,610
我为你绘制的是一个

501
00:30:51,700 --> 00:30:54,010
非均匀离散化

502
00:30:54,110 --> 00:30:55,960
我离散的S-2比S-1多得多

503
00:30:56,040 --> 00:30:57,430
如果你到

504
00:30:57,510 --> 00:31:01,020
更高维的状态空间中

505
00:31:01,100 --> 00:31:03,570
你可能

506
00:31:03,660 --> 00:31:05,060
需要手动

507
00:31:05,140 --> 00:31:07,630
处理这些

508
00:31:07,720 --> 00:31:09,450
没有统一离散的选择

509
00:31:09,550 --> 00:31:11,860
但人民的智慧似乎是

510
00:31:11,950 --> 00:31:14,290
如果你有2或3维的问题

511
00:31:14,370 --> 00:31:16,130
它处理地很好 4维的问题

512
00:31:16,240 --> 00:31:17,960
你也许可以让它工作

513
00:31:18,050 --> 00:31:21,700
但它稍微具有挑战性

514
00:31:21,810 --> 00:31:23,930
有时可以闲逛和聪明点

515
00:31:24,020 --> 00:31:26,280
你经常可以推动

516
00:31:26,380 --> 00:31:27,790
离散约6维的问题

517
00:31:27,880 --> 00:31:31,880
但有一定的难度

518
00:31:31,950 --> 00:31:34,870
高于6维的问题使用离散化

519
00:31:34,960 --> 00:31:38,450
将会非常难以解决 所以这只是

520
00:31:38,560 --> 00:31:41,790
粗略的大众智慧的管理问题

521
00:31:41,880 --> 00:31:43,560
你想想使用离散

522
00:31:50,380 --> 00:31:53,630
但今天的大部分时间我想谈论的是

523
00:31:53,720 --> 00:31:57,060
[无声]的方法

524
00:31:57,150 --> 00:32:00,700
往往大大优于离散

525
00:32:00,800 --> 00:32:05,240
我们将直接估计V

526
00:32:05,330 --> 00:32:09,420
而不用离散的结果 在我跳转到

527
00:32:09,510 --> 00:32:11,140
特殊的表示法之前  让我花几分钟

528
00:32:11,220 --> 00:32:13,270
谈谈问题的设置 对于今天的讲座

529
00:32:13,370 --> 00:32:17,250
我打算把重点放在连续状态的问题

530
00:32:17,330 --> 00:32:20,750
为了让事情

531
00:32:20,830 --> 00:32:29,220
在这堂课上变得简单

532
00:32:29,300 --> 00:32:31,330
我想看看连续行动

533
00:32:31,430 --> 00:32:36,990
所以我要去看到离散行动A

534
00:32:37,070 --> 00:32:40,860
原来实际上这是很多问题的

535
00:32:40,950 --> 00:32:43,770
一个关键的事实  原来的状态空间

536
00:32:43,870 --> 00:32:48,710
是远远比行动的状态大得多

537
00:32:48,810 --> 00:32:50,670
似乎已经摸索出处理很多问题的方式

538
00:32:50,760 --> 00:32:51,790
例如

539
00:32:51,910 --> 00:32:55,030
驾驶汽车的状态空间是

540
00:32:55,130 --> 00:32:59,630
6维  XY T  Xdot  Ydot  Tdot

541
00:32:59,710 --> 00:33:04,280
然而  你的行动有

542
00:33:04,360 --> 00:33:05,630
你仍然有两个动作

543
00:33:05,710 --> 00:33:08,550
你向前向后的运动  并操纵这辆车

544
00:33:08,640 --> 00:33:10,720
所以你有6维的状态和2-D的行为

545
00:33:10,800 --> 00:33:12,690
并让离散行动比离散状态更容易

546
00:33:12,760 --> 00:33:15,410
下面的唯一例子是关于直升机

547
00:33:15,510 --> 00:33:17,350
你在一个4维的行为中

548
00:33:17,460 --> 00:33:19,260
有12- D的状态

549
00:33:19,360 --> 00:33:21,810
原来  往往比离散连续行动

550
00:33:21,890 --> 00:33:24,360
成一个连续的动作总和

551
00:33:24,460 --> 00:33:28,240
要容易得多

552
00:33:28,350 --> 00:33:30,180
对于倒立摆  你有一个4-D的状态

553
00:33:30,260 --> 00:33:32,770
和一个1-D的行为

554
00:33:32,870 --> 00:33:36,740
无论你让购物车向左边还是右边加速

555
00:33:36,820 --> 00:33:40,590
它都是1-D的行为  所以对于今天剩余的时间

556
00:33:40,700 --> 00:33:42,790
我要去假设一个连续状态

557
00:33:42,870 --> 00:33:44,530
但我假定  也许你已经离散了你的行为

558
00:33:44,620 --> 00:33:47,150
只是因为它在实践中证明

559
00:33:47,210 --> 00:33:49,040
不是所有问题都有用

560
00:33:49,120 --> 00:33:54,070
对于多数问题  大量的行为

561
00:33:54,140 --> 00:34:00,910
比大量的状态空间的困难更少

562
00:34:01,000 --> 00:34:15,580
所以我要假设  我们有一个MDP的模型

563
00:34:15,670 --> 00:34:18,900
或模拟器  这是一个关于

564
00:34:18,980 --> 00:34:21,390
如何表示状态转移概率的假设

565
00:34:21,470 --> 00:34:25,080
我要假设  我将使用

566
00:34:25,140 --> 00:34:27,370
术语‘模型’

567
00:34:27,450 --> 00:34:28,950
和‘模拟器’  几乎是同义词

568
00:34:29,040 --> 00:34:33,070
那么具体的  我要假设的是

569
00:34:33,160 --> 00:34:34,770
我们有一个黑盒子和一块代码

570
00:34:34,850 --> 00:34:42,820
使我可以输入任何状态  输入一个动作

571
00:34:42,900 --> 00:34:46,970
它会输出的S`(S prime)(S`)

572
00:34:47,050 --> 00:34:52,580
从状态过渡分布的样本

573
00:34:52,650 --> 00:34:55,370
这其实是  表示我的状态

574
00:34:55,430 --> 00:34:59,770
转移概率的假设  所以我假设

575
00:34:59,860 --> 00:35:02,960
我有一个盒子  读取状态行动

576
00:35:03,010 --> 00:35:06,210
并输出混合状态

577
00:35:06,290 --> 00:35:10,210
如此  因为他们是得到

578
00:35:17,590 --> 00:35:19,560
不同的MDP的相当常见的方式

579
00:35:19,640 --> 00:35:21,830
你可能会从物理模拟器得到一个模型

580
00:35:21,940 --> 00:35:26,370
因此  举例来说

581
00:35:26,470 --> 00:35:33,650
如果你对控制

582
00:35:33,720 --> 00:35:37,450
倒立摆感兴趣

583
00:35:37,530 --> 00:35:42,340
你的行动是A

584
00:35:42,440 --> 00:35:45,120
那是施加的车向左或向右的一个力量

585
00:35:45,230 --> 00:35:51,000
你的状态是Xdot  T Tdot

586
00:35:51,090 --> 00:36:01,640
我要把它按照那个顺序写下来

587
00:36:01,720 --> 00:36:03,070
为了保持完整  我要写下一堆等式

588
00:36:03,150 --> 00:36:05,120
但一切我要在下面写下的

589
00:36:05,200 --> 00:36:06,990
大多数是无端的

590
00:36:07,060 --> 00:36:10,700
但这样一来  也许我会翻开

591
00:36:10,790 --> 00:36:12,490
一本物理教科书  力学的教科书

592
00:36:12,580 --> 00:36:14,020
可以制定出这样的物理设备的运动的方程

593
00:36:14,110 --> 00:36:17,330
等你发现那个S dot

594
00:36:17,440 --> 00:36:23,730
圆点表示求导

595
00:36:23,800 --> 00:36:26,600
这样的状态对时间进行求导

596
00:36:26,690 --> 00:36:34,970
是Xdot给予的  ?-L(B)

597
00:36:35,060 --> 00:36:56,190
花费B在M Tdot B 并且A是

598
00:36:56,270 --> 00:36:58,440
施加在车上的力量

599
00:36:58,540 --> 00:37:01,520
L是杆的长度 M是系统的总质量等

600
00:37:01,590 --> 00:37:04,560
因此  所有这些方程能有效利用

601
00:37:04,650 --> 00:37:06,010
为了完整性把它们写下来

602
00:37:06,080 --> 00:37:10,500
但通过翻页  打开一本物理教科书

603
00:37:10,580 --> 00:37:12,250
你可以算出出这些方程和概念

604
00:37:12,320 --> 00:37:14,640
然后给出一个模型

605
00:37:14,700 --> 00:37:19,200
它可以说  S - 2 +?1

606
00:37:19,270 --> 00:37:22,280
你还是一个时间步长后

607
00:37:22,340 --> 00:37:29,160
将以前的状态等于加[无声]

608
00:37:29,230 --> 00:37:33,620
所以在你的模拟器或在我的模型

609
00:37:33,690 --> 00:37:36,790
每10份之1秒  所以??T将在一秒钟内

610
00:37:36,840 --> 00:37:44,480
那么加上??T乘以它

611
00:37:44,550 --> 00:38:04,510
因此  将是提出MDP模型的一种方式

612
00:38:04,620 --> 00:38:08,530
在这个具体的例子中

613
00:38:08,610 --> 00:38:11,130
我实际上写下了确定性模型

614
00:38:11,210 --> 00:38:13,210
因为和通过确定性

615
00:38:13,280 --> 00:38:15,850
我的意思是  在一个状态上给一个行为

616
00:38:15,930 --> 00:38:20,400
下一个状态不是随机的

617
00:38:20,480 --> 00:38:23,950
所以是一个确定性模型的一个例子

618
00:38:24,020 --> 00:38:26,630
在那里我可以精确地计算下一个状态

619
00:38:26,700 --> 00:38:28,660
作为前一个状态和行为的函数

620
00:38:28,730 --> 00:38:31,920
这是一个确定性模型

621
00:38:31,980 --> 00:38:34,230
因为所有的概率集合

622
00:38:34,320 --> 00:38:37,530
是在单一的状态和特定的行为下

623
00:38:37,610 --> 00:38:59,710
还可以使用随机模型

624
00:38:59,780 --> 00:39:01,960
第二种方法  通常用于

625
00:39:02,030 --> 00:39:10,650
实现模型的是学习一种 再次强调

626
00:39:10,740 --> 00:39:14,350
你具体要做的就是

627
00:39:14,440 --> 00:39:17,140
你要想象你有一个物理的倒立摆系统

628
00:39:17,240 --> 00:39:19,730
因为你物理上拥有一个倒立摆机器

629
00:39:19,820 --> 00:39:24,140
你会做的是  然后你要初始化

630
00:39:24,230 --> 00:39:25,820
你的倒立摆机器为某种状态

631
00:39:25,910 --> 00:39:29,230
然后执行一些政策

632
00:39:29,310 --> 00:39:31,110
可能会有一些随机的政策

633
00:39:31,190 --> 00:39:32,990
或一些你认为是相当不错的政策

634
00:39:33,070 --> 00:39:35,120
或者你甚至可以尝试自己控制操纵杆等

635
00:39:35,200 --> 00:39:38,600
但是  你在设置系统的状态为零

636
00:39:38,650 --> 00:39:41,820
然后  你采取一些行动 这里是零

637
00:39:41,890 --> 00:39:45,260
并且那个游戏可以通过

638
00:39:45,360 --> 00:39:47,260
某种政策来选择或通过

639
00:39:47,330 --> 00:39:49,230
使用操纵杆tryina控制倒立摆来选择

640
00:39:49,300 --> 00:39:52,190
系统将过渡到某种新的状态  S-1

641
00:39:52,290 --> 00:39:59,010
那么你采取某种新的动作  A-1等

642
00:39:59,100 --> 00:40:01,040
比方说  你做这个两个时间步长

643
00:40:01,130 --> 00:40:06,220
有时我把这个叫做轨迹

644
00:40:06,300 --> 00:40:10,440
并且你重复这个M次

645
00:40:10,490 --> 00:40:15,660
所以这是第一个轨迹的第一次实验

646
00:40:15,740 --> 00:40:19,690
然后你再次这样处理

647
00:40:19,770 --> 00:40:37,960
初始化为某种状态等等

648
00:40:38,040 --> 00:40:41,280
所以  你这样处理很多次

649
00:40:41,370 --> 00:41:02,540
然后你可以运行的学习算法估计ST+1

650
00:41:02,620 --> 00:41:06,250
作为ST和AT的函数

651
00:41:06,340 --> 00:41:08,800
为完整起见  你应该把它当做倒立摆问题

652
00:41:08,880 --> 00:41:12,630
因此ST +1是一个4维向量

653
00:41:12,700 --> 00:41:14,930
ST  AT将是一个4维向量

654
00:41:15,030 --> 00:41:17,060
那将是一个实数

655
00:41:17,140 --> 00:41:19,950
所以你可能运行线性回归的4次

656
00:41:20,030 --> 00:41:21,920
预测每一个状态变量

657
00:41:22,020 --> 00:41:27,240
为这5个实数的函数

658
00:41:29,590 --> 00:41:34,140
例如  如果你说  如果你想要

659
00:41:34,230 --> 00:41:36,570
估计下一个状态ST+1

660
00:41:36,660 --> 00:41:42,530
根据你之前状态的线性函数和你的行为

661
00:41:42,630 --> 00:41:49,810
所以在这里将会是一个4*4的矩阵

662
00:41:49,920 --> 00:41:54,510
而B将是一个4维向量

663
00:41:54,600 --> 00:42:02,330
那么你会选择A和B的值  使它最小化

664
00:42:02,410 --> 00:42:34,710
所以如果你想建立模型为ST+1

665
00:42:34,810 --> 00:42:37,110
为一些先前的状态行为的

666
00:42:37,210 --> 00:42:40,360
线性函数

667
00:42:40,440 --> 00:42:42,820
那么你可能建立这种优化目标

668
00:42:42,900 --> 00:42:45,400
并选择A和B为ST +1的预测值

669
00:42:45,490 --> 00:42:48,100
以尽量减少误差平方和ST和AT的线性函数

670
00:42:48,180 --> 00:42:58,580
我应该说  这是一个具体的例子

671
00:42:58,670 --> 00:43:01,580
使用了前面说的行为的线性函数

672
00:43:01,660 --> 00:43:04,750
来预测未来的状态

673
00:43:04,820 --> 00:43:06,140
当然  你也可以

674
00:43:06,200 --> 00:43:07,780
使用其他的算法

675
00:43:07,860 --> 00:43:09,740
像"低【听不清】重线性回归"

676
00:43:09,850 --> 00:43:11,940
或者"非线性特征的线性回归"

677
00:43:12,010 --> 00:43:14,970
或"核心线性回归"

678
00:43:15,060 --> 00:43:17,310
或者其他根据现有状态

679
00:43:17,380 --> 00:43:20,220
用于预测下一个状态的非线性函数

680
00:43:24,510 --> 00:43:27,270
所以这只是【听不清】线性问题

681
00:43:27,330 --> 00:43:30,070
结果"低【听不清】重线性回归"

682
00:43:30,140 --> 00:43:31,950
可用于很多机器  也是一种比较有效的

683
00:43:32,060 --> 00:43:48,760
解决学习问题的方法

684
00:43:48,830 --> 00:43:52,230
所以学者建立模型  学到参数A和B

685
00:43:52,310 --> 00:43:55,060
然后你有一个模型

686
00:43:55,150 --> 00:44:00,930
你说  ST+1加BAT

687
00:44:01,000 --> 00:44:09,060
所以这将是一个确定性模型的一个例子

688
00:44:09,170 --> 00:44:11,600
或学到参数A和B  你可能会说

689
00:44:11,700 --> 00:44:28,630
ST +1是等于AST+ BAT +?T

690
00:44:28,740 --> 00:44:31,580
所以这些将是非常合理的方式

691
00:44:31,660 --> 00:44:34,650
来提出一个倒立摆MDP的

692
00:44:34,740 --> 00:44:38,500
确定性模型或随机模型

693
00:44:41,170 --> 00:44:45,030
所以概括一下  我们现在有一个模型

694
00:44:45,110 --> 00:44:48,690
这意味着一段代码  在那里你可以输入一个

695
00:44:48,780 --> 00:44:54,340
状态  一个行为  获得了一个ST +1

696
00:44:54,420 --> 00:44:57,130
因此  如果你有一个随机模型

697
00:44:57,220 --> 00:44:59,780
然后改变这个模型

698
00:44:59,860 --> 00:45:02,220
你将样品?T[听不清]分布

699
00:45:02,310 --> 00:45:04,600
用来生成ST +1 ?

700
00:45:09,440 --> 00:45:18,700
因此  它实际上在预览在事先

701
00:45:18,810 --> 00:45:21,260
我想  它实际上处于

702
00:45:21,360 --> 00:45:23,460
非线性动力系统的具体情况

703
00:45:23,550 --> 00:45:25,480
在这个特定情况下

704
00:45:25,550 --> 00:45:27,620
下一个状态是当前状态行为的线性函数

705
00:45:27,700 --> 00:45:29,810
结果它是你们可以使用的

706
00:45:29,890 --> 00:45:32,110
非常强大的算法?

707
00:45:32,180 --> 00:45:33,810
所以我今天不会去谈它了

708
00:45:33,890 --> 00:45:35,980
我将在下一个演讲谈它  而不是现在

709
00:45:36,070 --> 00:45:40,120
但事实证明  对于倒立摆的许多问题

710
00:45:40,210 --> 00:45:42,320
如果你使用低

711
00:45:42,410 --> 00:45:44,060
[无声]重量和线性归

712
00:45:44,140 --> 00:45:46,540
和长线性算法

713
00:45:46,620 --> 00:45:48,100
因为许多系统不是线性的

714
00:45:48,190 --> 00:45:50,170
你可以建立一个非线性?模型

715
00:45:53,680 --> 00:45:57,020
所以我现在想要做的是

716
00:45:57,110 --> 00:45:59,810
谈谈关于一个给定模型

717
00:45:59,900 --> 00:46:03,650
给定一个MDP的模拟器

718
00:46:03,730 --> 00:46:05,900
如何来用算法来估计alpha值函数

719
00:46:05,980 --> 00:46:09,400
在我继续之前  让我检查是否存在问题

720
00:46:09,490 --> 00:46:20,720
好吧  酷 所以这里是那个想法

721
00:46:20,820 --> 00:46:44,490
当我们谈到线性回归时

722
00:46:44,600 --> 00:46:47,760
我们说过  鉴于一些监督学习中的输入X

723
00:46:47,860 --> 00:46:50,380
输入特征是X

724
00:46:50,470 --> 00:46:53,580
我们可以选择X的一些特征

725
00:46:53,690 --> 00:46:58,370
然后估计变量的特征为

726
00:46:58,460 --> 00:47:01,060
X变量特征的一个线性函数

727
00:47:01,160 --> 00:47:04,340
所以做完全同样的事情

728
00:47:04,510 --> 00:47:08,890
来估计最优值函数

729
00:47:08,970 --> 00:47:12,230
尤其是  我们将选择一个状态S的

730
00:47:12,340 --> 00:47:17,670
一些特征5-S.

731
00:47:17,770 --> 00:47:26,910
所以你其实可以选择5-S等于S

732
00:47:27,010 --> 00:47:28,470
这将是一个合理的选择

733
00:47:28,580 --> 00:47:30,400
如果你想近似值函数

734
00:47:30,490 --> 00:47:34,170
为状态的一个线性函数

735
00:47:34,260 --> 00:47:37,420
但你也可以选择其他的东西

736
00:47:37,540 --> 00:47:39,180
因此  例如倒立摆的例子

737
00:47:39,300 --> 00:47:43,060
你可以选择5-S等于特征向量

738
00:47:43,140 --> 00:47:46,390
那可能[听不清] 1  或者你可能

739
00:47:46,500 --> 00:47:54,580
有Xdot2  Xdot  也许有些交叉项

740
00:47:54,680 --> 00:48:00,150
也许*X  也许dot2等

741
00:48:00,270 --> 00:48:05,120
所以  你选择一些特征向量

742
00:48:07,020 --> 00:48:19,140
然后近似值函数为状态的值

743
00:48:19,230 --> 00:48:24,630
是等于数据传输乘以特征

744
00:48:24,740 --> 00:48:26,610
我应该提前道歉

745
00:48:26,700 --> 00:48:28,590
我重用了符号

746
00:48:28,720 --> 00:48:32,030
这很不幸 我使用数据

747
00:48:32,110 --> 00:48:35,340
均表示了杆子

748
00:48:35,490 --> 00:48:39,610
倒立摆的马车的角度

749
00:48:39,700 --> 00:48:43,230
因此  这是已知的角度T

750
00:48:43,350 --> 00:48:45,080
也用T来表示我的[听不清]算法的参数向量

751
00:48:45,190 --> 00:48:46,750
因此  对重用的符号表示遗憾

752
00:48:46,830 --> 00:48:54,490
就像我们在线性回归所做的

753
00:48:54,580 --> 00:48:56,350
我的目标是提出特征的一个线性组合

754
00:48:56,440 --> 00:48:57,830
它给了我一个很好的值函数的近似

755
00:48:57,920 --> 00:49:00,120
这是完全类似的

756
00:49:00,260 --> 00:49:02,610
当我们说

757
00:49:02,720 --> 00:49:06,570
在我们估计的线性回归中

758
00:49:06,690 --> 00:49:14,670
我的回应在那里

759
00:49:15,030 --> 00:49:17,390
但Y作为一个线性函数的一个特征

760
00:49:17,480 --> 00:49:19,620
是一个输入 这就是我们

761
00:49:19,700 --> 00:49:51,490
在线性回归所拥有的

762
00:49:51,570 --> 00:49:54,060
让我写下值迭代  然后我将写下

763
00:49:54,160 --> 00:49:57,930
一个近似的值迭代  对于离散状态

764
00:49:58,030 --> 00:50:02,050
这是价值迭代背后的想法

765
00:50:02,130 --> 00:50:05,200
我们说  V(S)将更新

766
00:50:05,280 --> 00:50:17,550
为R(S)+?G [听不清]

767
00:50:17,620 --> 00:50:20,330
这是值迭代

768
00:50:20,440 --> 00:50:22,110
并在连续状态的情况下

769
00:50:22,160 --> 00:50:25,790
这将会被替换为[听不清]  [无声]

770
00:50:25,880 --> 00:50:33,200
在状态之上  而不是通过状态的总和

771
00:50:33,320 --> 00:50:41,270
而通过状态所取代 让我写这个R(S)+ G

772
00:50:41,360 --> 00:50:43,590
然后  T prime的总和

773
00:50:43,700 --> 00:50:47,130
这是一个真正的随机状态的期望

774
00:50:47,220 --> 00:50:49,690
作为prime  从状态转移概率块的

775
00:50:49,770 --> 00:50:57,570
SA的V(S)prime 所以这是一个

776
00:50:57,670 --> 00:50:59,440
所有状态S`(S prime)

777
00:50:59,480 --> 00:51:01,810
到达S`(S prime)(值)概率的总和

778
00:51:01,910 --> 00:51:04,330
所以这其实是一个的随机状态S`(S prime)

779
00:51:04,410 --> 00:51:09,720
从PSA产生的期望

780
00:51:09,820 --> 00:51:12,670
所以我现在要做的是

781
00:51:12,760 --> 00:51:28,220
写下来一个称为拟合值迭代的算法

782
00:51:28,320 --> 00:51:31,530
那是一个近似值  但特别是

783
00:51:31,630 --> 00:51:34,880
用于连续的状态的 我只是写下了

784
00:51:34,960 --> 00:51:36,840
前两个步骤  然后我将继续

785
00:51:36,920 --> 00:51:40,250
在下一块黑板  所以该算法的第一步是

786
00:51:40,350 --> 00:51:44,850
我们将样本 随机选择的一些状态集

787
00:51:44,960 --> 00:51:59,080
所以比如S-M的随机样品S-1  S-2

788
00:51:59,210 --> 00:52:01,370
所以选择一个随机状态

789
00:52:01,450 --> 00:52:10,190
并且初始化我的参数向量等于0

790
00:52:10,300 --> 00:52:13,840
这里与值迭代相类似

791
00:52:13,960 --> 00:52:17,530
我可能初始化值函数是全0的函数

792
00:52:17,640 --> 00:52:22,080
那么这是算法最终样子

793
00:52:22,160 --> 00:52:44,710
实际上有很多需要写

794
00:52:44,760 --> 00:54:17,460
让我们来看看 这就是那个算法

795
00:56:12,270 --> 00:56:18,780
让我调整下书写 给我一点时间?

796
00:56:18,830 --> 00:56:20,360
给我一分钟来完成

797
00:56:20,430 --> 00:56:21,780
然后我将逐步调试它

798
00:56:26,780 --> 00:56:29,160
其实  如果我的一些代码是合法的

799
00:56:29,240 --> 00:56:58,900
让我知道 因此  让我逐步调试

800
00:56:59,010 --> 00:57:02,790
那么简单解释一下它的原理

801
00:57:02,870 --> 00:57:10,080
所以听到的算法是--让我们来看看

802
00:57:10,160 --> 00:57:11,950
在原来的值迭代算法中

803
00:57:12,020 --> 00:57:15,260
我们将对每个状态采用这个值  V(s)I

804
00:57:15,340 --> 00:57:18,830
我们将用这个表达式覆盖它

805
00:57:18,910 --> 00:57:21,750
在原型中  这个离散值迭代算法是V(S)I

806
00:57:21,830 --> 00:57:26,420
并且我们将设置V(S)I

807
00:57:26,490 --> 00:57:31,030
等于它  我想 现在我们已经

808
00:57:31,110 --> 00:57:32,590
在连续状态的情况下

809
00:57:32,640 --> 00:57:33,980
我们有一个状态的无限连续设置

810
00:57:34,040 --> 00:57:36,710
所以你不能离散地设置这些值

811
00:57:36,790 --> 00:57:39,630
所以我们要做的是

812
00:57:39,690 --> 00:57:44,900
选择参数T

813
00:57:45,000 --> 00:57:48,510
使V(S)I和右侧的这个东西

814
00:57:48,590 --> 00:57:53,590
尽可能接近 这就是YI最后结果

815
00:57:53,680 --> 00:57:57,870
彻底地  我将要做的是

816
00:57:57,960 --> 00:58:01,560
我要构建这个项的估计值

817
00:58:01,640 --> 00:58:03,100
然后我会选择我的函数逼近的参数

818
00:58:03,180 --> 00:58:04,600
我要去选择我的参数为T

819
00:58:04,700 --> 00:58:08,700
使V(S)尽可能接近这些

820
00:58:08,760 --> 00:58:10,980
这就是YI所表示的东西

821
00:58:11,070 --> 00:58:13,630
具体地说  我要做的是

822
00:58:13,730 --> 00:58:16,550
我会选择参数的数据

823
00:58:16,610 --> 00:58:19,230
以尽量减少T [无声]加5S的平方差

824
00:58:19,300 --> 00:58:23,140
这件东西在这里只是V(S)I

825
00:58:23,310 --> 00:58:25,980
因为我逼近V(S)I

826
00:58:26,070 --> 00:58:29,100
是一个5SI的线性函数

827
00:58:29,180 --> 00:58:32,240
所以选择参数的数据

828
00:58:32,570 --> 00:58:36,170
以最大限度地减少平方差的总和

829
00:58:36,250 --> 00:58:40,130
因此  这是最后一步是

830
00:58:40,210 --> 00:58:42,780
基本值迭代的近似版本

831
00:58:42,850 --> 00:58:46,900
上述一切正在做的是刚刚

832
00:58:46,990 --> 00:58:51,400
与这个词的近似  这个叫做YI的东西

833
00:58:51,480 --> 00:58:53,850
所以融合的  为每一个状态SI

834
00:58:53,930 --> 00:58:56,100
我们要估计右侧的东西是什么

835
00:58:56,180 --> 00:58:59,610
但这里有一个期望

836
00:58:59,690 --> 00:59:01,710
是一个连续状态集的期望

837
00:59:01,790 --> 00:59:03,850
可能是一个非常高维的状态

838
00:59:03,960 --> 00:59:06,030
所以我不能准确计算这种期望

839
00:59:06,120 --> 00:59:09,290
我会做的是

840
00:59:09,370 --> 00:59:12,270
我将用我的模拟器

841
00:59:12,360 --> 00:59:15,490
从这个P substrip分布中对状态集取样

842
00:59:15,570 --> 00:59:18,530
SIA  从我得到的状态过渡分配开始

843
00:59:18,600 --> 00:59:20,320
如果我在状态I  采取行动A

844
00:59:20,410 --> 00:59:24,440
然后通过状态样本来计算这个期望

845
00:59:24,520 --> 00:59:28,040
通过逐步调试这个算法

846
00:59:28,130 --> 00:59:31,850
只是说  对于每个状态和每个动作

847
00:59:31,940 --> 00:59:34,170
我要从状态集中取样

848
00:59:34,250 --> 00:59:37,510
这个S`(S prime) 1到达S`(S prime) K

849
00:59:37,590 --> 00:59:39,430
通过状态过渡分布  仍然使用这个模型

850
00:59:39,510 --> 00:59:42,010
然后我会设置Q(a)等于那个平均值

851
00:59:42,080 --> 00:59:45,620
所以这是我的估计

852
00:59:45,720 --> 00:59:50,790
对于R(S)I + G(这个预期值

853
00:59:50,870 --> 00:59:55,160
具体的行动) 然后  我将使用

854
00:59:55,280 --> 00:59:58,310
行动A的最大值  这返回给我YI

855
00:59:58,390 --> 01:00:02,060
所以YI是为S的 最后  我会真正

856
01:00:02,150 --> 01:00:05,740
运行线性回归  这是最后的设置

857
01:00:05,840 --> 01:00:09,670
[听不清]得到V(S)  使之接近YI

858
01:00:09,780 --> 01:00:13,590
因此  该算法被称为拟合值迭代

859
01:00:13,690 --> 01:00:17,350
对于连续的问题  它实际上往往相当不错

860
01:00:17,450 --> 01:00:20,320
对于6 - 10 – 20-维的状态空间

861
01:00:20,450 --> 01:00:25,120
如果你可以选择相应的特征

862
01:00:25,220 --> 01:00:27,360
如果明白了这个算法

863
01:00:27,440 --> 01:00:35,150
请举手?

864
01:00:35,250 --> 01:00:40,770
你们当中有些人没有举手

865
01:00:40,850 --> 01:00:43,070
是否有对这些有问题

866
01:00:43,150 --> 01:00:44,020
请说?

867
01:00:44,100 --> 01:00:45,490
学生:在此设置中

868
01:00:45,570 --> 01:00:48,010
有没有一个凹[无声]函数?

869
01:00:48,100 --> 01:00:56,480
噢  是的 一个MDP包括SA

870
01:00:56,580 --> 01:01:03,730
状态过渡?概率G和R

871
01:01:03,850 --> 01:01:06,290
碎玉连续状态空间

872
01:01:06,390 --> 01:01:08,860
S将像R4的倒立摆的东西

873
01:01:08,990 --> 01:01:12,030
离散的状态转换概率的行为

874
01:01:12,120 --> 01:01:13,200
包含模型或模拟器指定

875
01:01:13,300 --> 01:01:18,160
G只是像0.99的实数

876
01:01:18,250 --> 01:01:21,720
并且是通常是

877
01:01:21,820 --> 01:01:23,790
给你的真正的函数

878
01:01:23,880 --> 01:01:28,420
奖励函数  是某种4维状态的函数

879
01:01:28,510 --> 01:01:32,420
并且  例如  你可能会选择

880
01:01:32,510 --> 01:01:35,240
一个奖励函数  等于负的--我不知道

881
01:01:35,350 --> 01:01:41,280
作为奖励函数的一个简单例子

882
01:01:41,360 --> 01:01:44,800
如果我们想要一个-1

883
01:01:44,870 --> 01:01:49,740
如果杆子掉了  这取决于

884
01:01:49,830 --> 01:01:51,560
你选择的奖励函数  为-1

885
01:01:51,640 --> 01:01:53,560
如果倒立摆落在地

886
01:01:53,640 --> 01:01:57,860
并发现它的角度大于30?或0°等 


887
01:01:57,940 --> 01:02:02,800
所以这将是一个

888
01:02:02,890 --> 01:02:05,930
奖励函数的一个例子

889
01:02:06,030 --> 01:02:07,140
你可以选择的倒立摆的一个例子

890
01:02:07,220 --> 01:02:08,780
但肯定的  假设奖励函数给你了

891
01:02:08,870 --> 01:02:11,230
对任何状态  使你可以计算出R(S)I

892
01:02:11,310 --> 01:02:16,680
是否还有其他问题吗?

893
01:03:23,020 --> 01:03:25,030
其实  让我尝试问一个问题

894
01:03:25,150 --> 01:03:27,950
所以我在这里所做的

895
01:03:28,060 --> 01:03:32,780
假设我们有一个随机模拟器

896
01:03:32,890 --> 01:03:35,310
因此  事实证明  我可以简化算法

897
01:03:35,400 --> 01:03:37,910
如果我有一个确定的模拟器

898
01:03:37,990 --> 01:03:40,390
而确定性模拟器给定一个既定的行为

899
01:03:40,460 --> 01:03:43,360
我的下一个状态始终是完全确定的

900
01:03:43,450 --> 01:03:46,050
因此  让我问你  如果我有一个

901
01:03:46,140 --> 01:03:48,050
确定性的模拟器  我将如何改变这种算法?

902
01:03:48,140 --> 01:03:50,020
我将如何简化这个算法??

903
01:03:50,130 --> 01:03:54,690
学生:降低你的样品

904
01:03:54,790 --> 01:03:56,380
你画[听不清] ?

905
01:03:56,450 --> 01:03:59,510
对  所以Justin是对的

906
01:03:59,610 --> 01:04:00,830
如果我有一个确定性模拟器

907
01:04:00,930 --> 01:04:02,940
我从这些样本将完全相同

908
01:04:03,020 --> 01:04:04,520
并因此  如果我有一个确定的模拟器

909
01:04:04,610 --> 01:04:07,090
我可以集K等于1

910
01:04:07,210 --> 01:04:09,930
所以我并不需要绘制K不同的样本

911
01:04:10,020 --> 01:04:12,770
我真的只需要一个样本

912
01:04:12,870 --> 01:04:14,990
如果我有一个确定的模拟器

913
01:04:15,070 --> 01:04:21,020
这样可以简化设置K = 1时

914
01:04:21,120 --> 01:04:23,610
如果你有一个确定的模拟器 请说?

915
01:04:27,370 --> 01:04:28,280
学生:我想我真的对它很困惑

916
01:04:28,380 --> 01:04:30,750
是啊  我们大概把这个东西变成

917
01:04:30,860 --> 01:04:33,150
看起来像线性状态回归

918
01:04:33,250 --> 01:04:35,480
或一些你知道的数据转置乘以什么的东西

919
01:04:35,570 --> 01:04:40,060
但是我猜想我是一个小的

920
01:04:40,170 --> 01:04:41,520
我其实不知道  自己要问的问题

921
01:04:41,610 --> 01:04:45,250
但像我们这样做之前

922
01:04:45,370 --> 01:04:46,860
我们有离散状态  和其他一切

923
01:04:46,950 --> 01:04:50,340
我们决心找到这个最优的政策

924
01:04:50,440 --> 01:04:55,620
我想它看起来并不像

925
01:04:55,740 --> 01:04:58,040
我们没有说  发布政策

926
01:04:58,160 --> 01:04:59,920
有点困难的

927
01:05:00,040 --> 01:05:04,570
好了  是啊

928
01:05:04,660 --> 01:05:05,910
所以[无声]回到政策

929
01:05:05,990 --> 01:05:08,350
但也许我应该只是说几句话

930
01:05:08,430 --> 01:05:09,900
让我试图得到

931
01:05:09,990 --> 01:05:11,180
一些你所说的

932
01:05:11,270 --> 01:05:13,180
寻找最优的政策的策略

933
01:05:13,270 --> 01:05:16,180
已经找到某种方式找到V

934
01:05:16,270 --> 01:05:18,570
找到一些方法来找到最优值函数

935
01:05:18,650 --> 01:05:21,960
然后用它来计算

936
01:05:22,050 --> 01:05:24,170
?*和?*.的近似值

937
01:05:24,260 --> 01:05:26,970
到目前为止

938
01:05:27,020 --> 01:05:28,980
我所做的一切已经集中在  如何找到V

939
01:05:29,080 --> 01:05:34,640
我只想说一句话

940
01:05:34,730 --> 01:05:37,260
事 实证明  对于线性回归

941
01:05:37,360 --> 01:05:39,270
往往很容易的

942
01:05:39,360 --> 01:05:40,690
选择一些特征的资源

943
01:05:40,780 --> 01:05:42,040
这通常并不难

944
01:05:42,120 --> 01:05:45,150
为估计值函数而选择特征

945
01:05:45,230 --> 01:05:47,190
往往有些困难

946
01:05:47,280 --> 01:05:51,530
因为一个状态的价值是多么好

947
01:05:51,630 --> 01:05:54,130
是开始于这种状态

948
01:05:54,210 --> 01:05:58,710
我预期的贴现回报总和是什么?

949
01:05:58,810 --> 01:06:01,300
如果我在一定的状态开始  怎么办?

950
01:06:01,400 --> 01:06:04,460
所以需要衡量状态的特征真的有多好

951
01:06:04,560 --> 01:06:08,800
是开始在一定状态?而且对于倒立摆

952
01:06:08,870 --> 01:06:12,450
你其实有那种状态

953
01:06:12,530 --> 01:06:15,010
杆子是垂直的

954
01:06:15,090 --> 01:06:16,690
并且几种在轨道上

955
01:06:16,780 --> 01:06:18,580
也许更好  并且你可以提出特征

956
01:06:18,660 --> 01:06:20,370
来测量杆子的方向

957
01:06:20,450 --> 01:06:22,290
和你与轨道的中心有多接近等

958
01:06:22,370 --> 01:06:24,220
并且这是使用近似V *的合理特征

959
01:06:24,320 --> 01:06:26,700
虽然在一般情况下

960
01:06:26,800 --> 01:06:30,530
选择特征

961
01:06:30,620 --> 01:06:32,250
价值函数逼近法

962
01:06:32,330 --> 01:06:35,210
往往是稍微比为线性回归

963
01:06:35,290 --> 01:06:36,710
选择好的特征更精妙一些

964
01:06:36,820 --> 01:06:40,370
好  然后Justin的问题

965
01:06:40,480 --> 01:06:44,130
给定V *  你如何回去找到一个政策呢?

966
01:06:44,230 --> 01:06:50,530
在离散的情况下  所以我们有?*(S)

967
01:06:50,630 --> 01:06:59,000
等于所有[听不清]基于那个A

968
01:06:59,090 --> 01:07:07,010
因此  这再次  我惯于把这个写作为

969
01:07:07,100 --> 01:07:09,850
一个状态[听不清]的总和

970
01:07:09,930 --> 01:07:13,540
我把它写成一种期望

971
01:07:13,640 --> 01:07:16,960
因此  一旦你找到最优值函数V

972
01:07:17,060 --> 01:07:20,790
然后你可以通过计算[听不清]

973
01:07:20,890 --> 01:07:23,940
来找到最佳的政策?

974
01:07:24,050 --> 01:07:27,810
所以  如果你是在一个连续的状态MDP中

975
01:07:27,910 --> 01:07:30,190
那么你实际上不能在每一个状态前

976
01:07:30,270 --> 01:07:32,340
这样处理  因为有一个无限数量的状态

977
01:07:32,440 --> 01:07:34,070
所以你不能实际执行它

978
01:07:34,180 --> 01:07:35,440
来预先计算?每一个单一的状态 ?

979
01:07:35,540 --> 01:07:40,060
你反而要做的是  每当你的机器人

980
01:07:40,170 --> 01:07:43,260
在某些特定的状态S

981
01:07:43,370 --> 01:07:46,020
只有当你的系统在一些特定的状态S

982
01:07:46,120 --> 01:07:48,000
就像你的车是在一些位置方向

983
01:07:48,100 --> 01:07:51,040
或者你的倒立摆在一些特定的位置

984
01:07:51,140 --> 01:07:56,820
在一些特定的角度T

985
01:07:56,900 --> 01:08:01,610
只有当你的系统  为一个因素

986
01:08:01,700 --> 01:08:04,470
或一个期盼游戏或一个机器人

987
01:08:04,570 --> 01:08:07,740
在一些特定的状态S中

988
01:08:07,850 --> 01:08:11,650
然后  你会提前计算这个augmax

989
01:08:11,700 --> 01:08:14,410
所以只有当你在某些状态S

990
01:08:22,040 --> 01:08:24,100
然后计算这augmax

991
01:08:24,210 --> 01:08:26,930
然后执行该行动A

992
01:08:27,010 --> 01:08:30,290
然后作为你的行动的结果

993
01:08:30,350 --> 01:08:32,210
你的机器人将过渡到了一些新的状态

994
01:08:32,290 --> 01:08:34,590
然后它会给予具体的新的状态

995
01:08:34,670 --> 01:08:37,150
而你计算augmax是使用你所在的特定状态S

996
01:08:43,200 --> 01:08:44,380
这是几种方法可以做到这一点

997
01:08:44,470 --> 01:08:47,340
在内循环的拟合值迭代算法中

998
01:08:47,420 --> 01:08:49,400
做到这一点的一种方法实际上是相同的

999
01:08:49,510 --> 01:08:52,770
因为大量状态的一个期望

1000
01:08:52,850 --> 01:08:56,090
你需要取样模拟器的一些状态

1001
01:08:56,190 --> 01:08:58,550
然后近似估计这种期望

1002
01:08:58,640 --> 01:09:00,790
使用你的样品平均

1003
01:09:00,880 --> 01:09:03,910
所以它实际上是作为内循环值迭代算法

1004
01:09:04,030 --> 01:09:07,170
所以  你可以做到这一点

1005
01:09:07,270 --> 01:09:08,730
有时可以这样做

1006
01:09:08,830 --> 01:09:11,500
有时也可以是一个痛苦

1007
01:09:11,580 --> 01:09:14,400
拥有一组状态近似的期望的样品

1008
01:09:14,470 --> 01:09:16,340
每次你想在你的MDP中采取行动 ?

1009
01:09:16,420 --> 01:09:20,230
几个特殊情况下可以做到这一点

1010
01:09:20,310 --> 01:09:21,820
一个特殊的情况下

1011
01:09:21,920 --> 01:09:23,660
如果你有一个确定性的模拟器

1012
01:09:30,640 --> 01:09:34,050
如果它是一个确定性的模拟器

1013
01:09:34,150 --> 01:09:35,850
所以换句话说  如果你的类似物

1014
01:09:35,940 --> 01:09:41,420
仅仅是一些函数  可线性或非线性函数

1015
01:09:41,500 --> 01:09:43,580
如果它是一个确定性的模拟器

1016
01:09:43,680 --> 01:09:46,200
那么下一个状态  ST+1

1017
01:09:46,280 --> 01:09:50,450
仅仅是一些你以前既定行动的功函数

1018
01:09:50,540 --> 01:09:53,380
如果是这样的话  那么这种期望

1019
01:09:53,460 --> 01:09:56,240
嗯  那么这可以简化为一个

1020
01:09:56,330 --> 01:10:04,700
我猜S的F的V * 的A的一个augmax

1021
01:10:04,780 --> 01:10:09,260
因为这是真正的意思

1022
01:10:09,350 --> 01:10:16,670
是S`(S prime)= F(S)  A

1023
01:10:16,770 --> 01:10:18,350
我在符号之间来回切换

1024
01:10:18,460 --> 01:10:19,890
我希望这是可以的

1025
01:10:19,990 --> 01:10:21,880
S表示当前的状态  S`(S prime)

1026
01:10:21,970 --> 01:10:23,520
确定性状态对应ST和ST+1

1027
01:10:23,620 --> 01:10:25,880
通过当前的状态

1028
01:10:25,970 --> 01:10:28,930
两者都大致表示符号法

1029
01:10:29,050 --> 01:10:31,050
不要介意我在它们之间来回切换

1030
01:10:31,140 --> 01:10:33,040
但如果它是一个确定性的模拟器

1031
01:10:33,140 --> 01:10:35,150
然后你可以为每一个动作

1032
01:10:35,270 --> 01:10:37,150
计算下一个状态S`(S prime)

1033
01:10:37,250 --> 01:10:40,030
基于目前的状态  然后采取行动A的augmax

1034
01:10:40,110 --> 01:10:43,340
基本上选择这个动作

1035
01:10:43,430 --> 01:10:45,050
让你得到最高值状态

1036
01:11:01,410 --> 01:11:06,680
所以这是一个案例  在那里

1037
01:11:06,770 --> 01:11:08,500
你可以计算augmax  我们可以计算

1038
01:11:08,600 --> 01:11:10,410
那个表达式  而不用取样

1039
01:11:10,500 --> 01:11:13,730
一些样品的平均 另一种

1040
01:11:13,820 --> 01:11:16,070
非常常见的情况  实际上是

1041
01:11:16,150 --> 01:11:25,120
如果你有一个随机模拟器

1042
01:11:25,200 --> 01:11:28,510
但如果你类似的情况  采取一个非常具体的

1043
01:11:28,600 --> 01:11:35,140
形式ST+1=F(s)T  AT+?T

1044
01:11:35,260 --> 01:11:38,930
其中这个是高斯噪音

1045
01:11:39,020 --> 01:11:46,320
[听不清]是一个非常普遍的方式

1046
01:11:46,390 --> 01:11:48,430
来构建模拟器  在那里你对

1047
01:11:48,530 --> 01:11:50,540
下一个状态建模  作为当前状态

1048
01:11:50,620 --> 01:11:53,100
和行动的功能  再加上一些噪音的函数

1049
01:11:53,190 --> 01:11:55,520
所以一旦具体的例子有点像微型动力系统

1050
01:11:55,610 --> 01:12:00,080
是我们谈到目前的状态

1051
01:12:00,170 --> 01:12:02,480
和行动加高斯噪声的线性函数

1052
01:12:02,550 --> 01:12:08,640
在这种情况下  可以通过A进行估计

1053
01:12:08,700 --> 01:12:10,500
很好

1054
01:12:19,850 --> 01:12:27,380
在这种情况下  你采取

1055
01:12:27,480 --> 01:12:33,870
你试着估计的期望

1056
01:12:33,950 --> 01:12:36,740
V * S`(S prime)的预期值

1057
01:12:36,820 --> 01:12:45,490
我们可以估计为  V *的S`(S prime)的

1058
01:12:45,540 --> 01:12:47,030
预期值  这是近似法

1059
01:12:47,120 --> 01:12:51,460
通常  一个函数的预期值

1060
01:12:51,540 --> 01:12:54,330
是不等于价值的期望

1061
01:12:54,410 --> 01:13:02,460
但它往往是一个合理的近似

1062
01:13:02,560 --> 01:13:05,610
所以这将是估计期望的另一种方法

1063
01:13:05,710 --> 01:13:11,420
所以你根据看我们做的同样的公式

1064
01:13:11,500 --> 01:13:15,850
正如我刚才写的  来选择行动

1065
01:13:15,920 --> 01:13:24,390
因此这将是估计这个augmax一种方法

1066
01:13:24,500 --> 01:13:31,180
基本上忽视了模拟器的噪音

1067
01:13:31,290 --> 01:13:35,110
这往往处理得很好

1068
01:13:35,170 --> 01:13:36,940
因为许多仿真器

1069
01:13:37,030 --> 01:13:39,380
结果是一些线性形式或一些非线性函数

1070
01:13:39,470 --> 01:13:42,170
加零均值高斯噪音

1071
01:13:42,260 --> 01:13:45,150
所以只是忽略

1072
01:13:45,230 --> 01:13:46,980
零均值高斯噪音

1073
01:13:47,090 --> 01:13:49,320
使你可以快速计算它

1074
01:13:49,400 --> 01:13:54,860
为了完成这一点  那是什么

1075
01:13:54,950 --> 01:13:59,940
对  V * F的SA  你下面的

1076
01:14:00,020 --> 01:14:07,160
被认为是数据传输Fi的S`(S prime)

1077
01:14:07,250 --> 01:14:10,740
S`(S prime)= F的SA 很好  所以这个V

1078
01:14:10,840 --> 01:14:13,770
你会使用参数的数据来计算它

1079
01:14:13,870 --> 01:14:16,140
使用你刚刚学会使用的拟合值迭代算法

1080
01:14:16,220 --> 01:14:23,920
关于这个有问题吗??

1081
01:14:29,760 --> 01:14:34,610
学生:[听不清]情况

1082
01:14:34,740 --> 01:14:37,690
对应实时应用程序  可以使用[无声]

1083
01:14:37,820 --> 01:14:41,870
例如[听不清]

1084
01:14:41,940 --> 01:14:43,660
是的  是在实时应用中

1085
01:14:43,750 --> 01:14:45,790
可能使用[无声]的期望

1086
01:14:51,440 --> 01:14:53,300
来取样情况阶段吗

1087
01:14:53,380 --> 01:14:55,890
电脑今天其实是惊人的快 实际上

1088
01:14:55,970 --> 01:14:59,420
我常常惊讶  在实时中  你可以处理多少

1089
01:14:59,520 --> 01:15:02,980
所以我飞行直升机使用和这个不同的算法?

1090
01:15:03,060 --> 01:15:04,560
我不能说

1091
01:15:04,640 --> 01:15:08,090
但我的直觉是

1092
01:15:08,160 --> 01:15:11,300
你实际上用直升机这样处理

1093
01:15:11,380 --> 01:15:13,340
直升机将控制在10HZ和50HZ之间的某处

1094
01:15:13,440 --> 01:15:15,130
你需要每秒钟处理10到50次

1095
01:15:15,220 --> 01:15:17,440
这实际上充足的时间

1096
01:15:17,530 --> 01:15:20,260
来取样1000个状态

1097
01:15:20,360 --> 01:15:21,700
和计算这个期望 ?

1098
01:15:21,800 --> 01:15:24,340
他们真的很难  直升机

1099
01:15:24,450 --> 01:15:27,320
因为直升机是关键任务

1100
01:15:27,420 --> 01:15:30,230
你做一些很快的事情

1101
01:15:30,310 --> 01:15:32,970
你可能做的严重破坏

1102
01:15:33,060 --> 01:15:36,010
也许是基于不是很好的理由

1103
01:15:36,110 --> 01:15:38,630
实际上我们倾向于避免扔硬币

1104
01:15:38,720 --> 01:15:41,180
当我们在空中的时候

1105
01:15:41,290 --> 01:15:43,900
这样让我们的行动是

1106
01:15:44,000 --> 01:15:47,210
一些随机过程的观念是有一些吓人的

1107
01:15:47,300 --> 01:15:49,160
而我们往往不这样做

1108
01:15:49,260 --> 01:15:52,500
我应该说的可能不是一个很好的原因

1109
01:15:52,610 --> 01:15:54,420
因为计算大量东西的平均

1110
01:15:54,490 --> 01:15:57,680
是很好的  但可能过于保守设计选择

1111
01:15:57,780 --> 01:16:00,810
我们其实不这样  倾向于在保守的东西中

1112
01:16:00,890 --> 01:16:02,700
不找任何随机的东西 我们做这个选择

1113
01:16:02,770 --> 01:16:05,210
是因为其他的东西都稍微安全一些

1114
01:16:05,310 --> 01:16:07,200
我认为你可以经常做到这一点

1115
01:16:07,300 --> 01:16:10,490
只要我看到一个模型

1116
01:16:10,580 --> 01:16:14,270
可以快速评估计算  在这里你可以取样到

1117
01:16:14,380 --> 01:16:16,820
100个状态转换或1000的状态转换

1118
01:16:16,900 --> 01:16:18,940
然后在10HZ那样处理 他们没有那样说

1119
01:16:19,000 --> 01:16:21,090
这往往是取得这个  为什么我们经常

1120
01:16:21,170 --> 01:16:23,340
会使用其他的不需要绘图大样本的近似值

1121
01:16:23,420 --> 01:16:30,340
还有别的吗?不  OK  酷

1122
01:16:30,430 --> 01:16:32,300
所以  现在你知道一个算法

1123
01:16:32,400 --> 01:16:34,100
[无声]对连续状态空间的强化学习

1124
01:16:34,210 --> 01:16:36,540
然后

1125
01:16:36,640 --> 01:16:39,140
我们将学习更多的一些想法

1126
01:16:39,220 --> 01:16:41,420
关于一些更强大的算法

1127
01:16:41,530 --> 01:16:42,890
解决连续状态空间的MDP

1128
01:16:42,980 --> 01:16:44,850
感谢 让我们今天结束

