1
00:00:15,790 --> 00:00:25,300
欢迎回来

2
00:00:25,370 --> 00:00:27,050
今天我要

3
00:00:27,120 --> 00:00:30,270
继续讲

4
00:00:30,350 --> 00:00:31,910
EM算法

5
00:00:32,010 --> 00:00:33,400
具体地

6
00:00:33,450 --> 00:00:36,300
我会结合上节课推出的

7
00:00:36,370 --> 00:00:38,150
的EM算法的一般形式

8
00:00:38,190 --> 00:00:40,070
讲一下混合

9
00:00:40,130 --> 00:00:40,890
高斯模型

10
00:00:40,970 --> 00:00:42,650
之后再将其应用到

11
00:00:42,730 --> 00:00:44,010
混合朴素贝叶斯模型

12
00:00:44,100 --> 00:00:45,820
之后我们

13
00:00:45,900 --> 00:00:47,960
结合EM算法

14
00:00:48,030 --> 00:00:49,120
介绍

15
00:00:49,170 --> 00:00:50,780
因子分析算法

16
00:00:50,810 --> 00:00:52,680
最后我们会

17
00:00:52,780 --> 00:00:54,070
额外地介绍一些

18
00:00:54,110 --> 00:00:56,220
高斯分布的

19
00:00:56,320 --> 00:00:57,500
有用的性质

20
00:00:57,650 --> 00:00:59,010
回顾一下之前讲的内容

21
00:00:59,120 --> 00:01:04,570
在上一讲

22
00:01:04,680 --> 00:01:06,400
我们开始讲

23
00:01:06,510 --> 00:01:07,740
无监督学习

24
00:01:07,870 --> 00:01:10,810
这是一类机器学习问题

25
00:01:10,930 --> 00:01:11,670
你有一个

26
00:01:11,790 --> 00:01:13,840
包含了

27
00:01:13,950 --> 00:01:17,410
m个无标记样本的

28
00:01:17,490 --> 00:01:19,570
训练集合

29
00:01:19,660 --> 00:01:20,700
这些样本没有标记

30
00:01:20,830 --> 00:01:21,820
所以我们称之为无监督的

31
00:01:21,980 --> 00:01:23,650
上次我讲的

32
00:01:23,780 --> 00:01:26,070
问题是

33
00:01:26,260 --> 00:01:27,600
如果给你一个看起来

34
00:01:27,700 --> 00:01:31,580
像这样的数据集合

35
00:01:31,630 --> 00:01:32,880
你希望对这些数据的

36
00:01:32,990 --> 00:01:37,730
概率密度P(x)进行建模

37
00:01:37,840 --> 00:01:39,420
数据集合可能是这样的

38
00:01:39,490 --> 00:01:43,580
所以你可以认为

39
00:01:43,640 --> 00:01:44,410
这些数据

40
00:01:44,500 --> 00:01:46,530
是由两个高斯分布生成的

41
00:01:46,640 --> 00:01:49,540
所以我们介绍了一个算法

42
00:01:49,640 --> 00:01:52,310
可以拟合出混合高斯模型

43
00:01:52,430 --> 00:01:53,410
对吗?

44
00:01:53,500 --> 00:01:55,090
我们讲到

45
00:01:55,160 --> 00:01:56,660
我们希望将

46
00:01:56,760 --> 00:01:58,560
x的概率密度P(x)建模为

47
00:01:58,680 --> 00:02:02,900
∑_z?〖P(x│z)P(z)〗

48
00:02:03,000 --> 00:02:07,190
∑_z?〖P(x│z)P(z)〗

49
00:02:07,280 --> 00:02:09,600
这个隐含

50
00:02:09,700 --> 00:02:10,790
的随机变量z

51
00:02:10,880 --> 00:02:13,600
代表你的

52
00:02:13,740 --> 00:02:14,880
数据来自于

53
00:02:14,950 --> 00:02:15,870
哪两个高斯分布

54
00:02:15,970 --> 00:02:19,490
所以

55
00:02:19,560 --> 00:02:24,720
z服从参数为

56
00:02:24,850 --> 00:02:29,520
Φ的多项式分布

57
00:02:29,600 --> 00:02:37,380
x|z=j服从均值为μ_j

58
00:02:37,500 --> 00:02:41,410
方差为Σ_j的高斯分布

59
00:02:41,500 --> 00:02:42,930
对吗?

60
00:02:43,000 --> 00:02:45,230
在上节课的

61
00:02:45,300 --> 00:02:45,900
一开始

62
00:02:45,950 --> 00:02:46,580
我们介绍了

63
00:02:46,710 --> 00:02:47,870
一个凭空想出来的

64
00:02:47,960 --> 00:02:49,720
非常具体的算法

65
00:02:49,810 --> 00:02:52,020
用于拟合出这个问题的参数:

66
00:02:52,130 --> 00:02:54,720
Φ  μ和Σ

67
00:02:54,820 --> 00:02:58,480
在上一节课的后半节课

68
00:02:58,580 --> 00:02:59,380
我介绍了

69
00:02:59,470 --> 00:03:00,360
EM算法

70
00:03:00,470 --> 00:03:05,090
它的目标是

71
00:03:05,170 --> 00:03:06,640
选取参数

72
00:03:06,770 --> 00:03:08,020
使得对数似然性

73
00:03:08,150 --> 00:03:08,730
最大化

74
00:03:08,830 --> 00:03:10,820
所以

75
00:03:10,940 --> 00:03:14,820
我们希望相对于θ

76
00:03:14,930 --> 00:03:23,000
使右边的这个对数似然函数最大化

77
00:03:23,100 --> 00:03:25,050
因为我们引入了

78
00:03:25,190 --> 00:03:26,660
隐含的随机变量z

79
00:03:26,780 --> 00:03:28,460
所以它应该等于这个式子

80
00:03:37,520 --> 00:03:40,410
对吗?

81
00:03:40,520 --> 00:03:48,880
使用Jensen不等式

82
00:03:48,980 --> 00:03:51,790
在E-step

83
00:03:51,920 --> 00:03:55,000
我们将

84
00:03:55,090 --> 00:03:57,800
概率分布Q_i定义

85
00:03:57,950 --> 00:04:05,090
为一个后验概率分布:

86
00:04:05,180 --> 00:04:06,200
P(z_i |x_i;θ)

87
00:04:06,320 --> 00:04:10,430
在M-step

88
00:04:10,490 --> 00:04:17,510
我们将θ的值

89
00:04:17,600 --> 00:04:22,230
更新为使这个式子最大化的值

90
00:04:22,340 --> 00:04:36,510
对吗?

91
00:04:36,600 --> 00:04:38,470
这些是我们上节课

92
00:04:38,580 --> 00:04:39,890
得到的结果

93
00:04:39,960 --> 00:04:43,460
我们将它画成一张图

94
00:04:43,560 --> 00:04:45,050
这是对数似然函数

95
00:04:45,180 --> 00:04:46,910
l(θ)

96
00:04:47,040 --> 00:04:48,150
通常很难直接将其最大化

97
00:04:48,260 --> 00:04:50,580
E-step做的是

98
00:04:50,660 --> 00:04:52,860
确定

99
00:04:52,960 --> 00:04:54,080
概率分布Q_i

100
00:04:54,180 --> 00:04:55,190
在图中

101
00:04:55,260 --> 00:04:57,060
它表示对数似然函数的下界

102
00:04:57,130 --> 00:04:59,260
对吗?

103
00:04:59,370 --> 00:05:01,880
水平轴是θ

104
00:05:01,980 --> 00:05:06,270
在M-step

105
00:05:06,330 --> 00:05:07,690
你希望最大化

106
00:05:07,770 --> 00:05:08,630
这个下界

107
00:05:08,690 --> 00:05:09,390
对吗?

108
00:05:09,460 --> 00:05:10,660
也许你之前在这里

109
00:05:10,790 --> 00:05:12,880
但是现在你跳到了这里

110
00:05:12,960 --> 00:05:16,410
Ok

111
00:05:16,500 --> 00:05:19,310
ok

112
00:05:19,400 --> 00:05:21,040
这个下界函数

113
00:05:21,130 --> 00:05:27,090
实际上就是

114
00:05:27,240 --> 00:05:28,560
argmax的右半部分

115
00:05:28,690 --> 00:05:29,410
ok

116
00:05:29,510 --> 00:05:32,440
如果你将argmax右边的

117
00:05:32,580 --> 00:05:33,560
整个式子看成

118
00:05:33,670 --> 00:05:34,980
是θ的函数

119
00:05:35,110 --> 00:05:38,440
那么这个θ的函数就是

120
00:05:38,520 --> 00:05:40,370
对数似然函数

121
00:05:40,460 --> 00:05:42,320
的下界  所以

122
00:05:42,390 --> 00:05:43,640
我们在M-step中所做的工作

123
00:05:43,750 --> 00:05:45,910
对应于跳到这里

124
00:05:46,020 --> 00:05:49,910
的下界函数的最大值

125
00:05:49,990 --> 00:05:56,210
事实证明--

126
00:05:56,240 --> 00:05:58,810
为什么我们要使用

127
00:05:58,900 --> 00:05:59,690
EM算法呢?

128
00:05:59,760 --> 00:06:00,640
事实证明

129
00:06:00,720 --> 00:06:02,770
通常情况下

130
00:06:02,890 --> 00:06:04,600
我们今天看到的例子全是这样

131
00:06:04,730 --> 00:06:06,130
事实证明  通常情况下

132
00:06:06,210 --> 00:06:11,510
EM算法的M-step中

133
00:06:11,590 --> 00:06:13,420
进行的最大化操作

134
00:06:13,530 --> 00:06:15,480
通常情况下

135
00:06:15,600 --> 00:06:16,570
是可以用解析形式

136
00:06:16,650 --> 00:06:18,680
计算出来的

137
00:06:18,780 --> 00:06:23,780
如果你尝试直接求

138
00:06:23,870 --> 00:06:24,620
这个目标函数的最大值

139
00:06:24,710 --> 00:06:26,750
你需要对右边的

140
00:06:26,850 --> 00:06:28,520
这个最大似然性求导数

141
00:06:28,640 --> 00:06:30,910
令其

142
00:06:31,030 --> 00:06:31,860
导数

143
00:06:31,930 --> 00:06:33,250
为0并求解它

144
00:06:33,350 --> 00:06:34,010
你会发现

145
00:06:34,110 --> 00:06:35,870
你根本无法

146
00:06:35,970 --> 00:06:36,880
得到解的解析形式

147
00:06:36,990 --> 00:06:39,870
举一个具体的例子

148
00:06:39,980 --> 00:06:42,300
你们记得

149
00:06:42,390 --> 00:06:43,070
我们之前对于

150
00:06:43,150 --> 00:06:45,050
指数函数族模型的讨论吗?

151
00:06:45,140 --> 00:06:50,700
如果x和z

152
00:06:50,790 --> 00:06:52,350
是联合的

153
00:06:52,420 --> 00:06:53,140
变量

154
00:06:53,240 --> 00:06:55,960
如果P(x  z|θ)

155
00:06:56,080 --> 00:06:57,110
是一个指数族

156
00:06:57,240 --> 00:06:57,860
分布

157
00:06:57,960 --> 00:06:59,750
混合高斯模型

158
00:06:59,880 --> 00:07:01,120
就是这样的

159
00:07:01,240 --> 00:07:02,540
如果是这样的话

160
00:07:02,620 --> 00:07:04,490
那么M-step就是容易计算的

161
00:07:04,610 --> 00:07:06,780
E-step也是容易计算的

162
00:07:06,870 --> 00:07:07,690
所以你可以

163
00:07:07,780 --> 00:07:08,770
很容易地完成这些步骤

164
00:07:08,860 --> 00:07:11,070
而直接求解

165
00:07:11,180 --> 00:07:13,020
这个原始

166
00:07:13,110 --> 00:07:14,230
的极大似然

167
00:07:14,350 --> 00:07:18,510
估计问题

168
00:07:18,530 --> 00:07:19,690
在计算上是非常困难的

169
00:07:19,770 --> 00:07:20,820
你需要先求导

170
00:07:20,920 --> 00:07:21,930
并令导数为0

171
00:07:22,010 --> 00:07:22,640
之后求解

172
00:07:22,660 --> 00:07:23,520
你会发现你无法得到

173
00:07:23,570 --> 00:07:24,510
这个问题的解析形式的解

174
00:07:24,580 --> 00:07:25,420
明白吗?

175
00:07:25,490 --> 00:07:33,560
我一会儿要做的是

176
00:07:33,660 --> 00:07:34,830
将EM算法的一般形式

177
00:07:34,890 --> 00:07:37,790
应用到

178
00:07:37,820 --> 00:07:39,470
混合高斯模型中

179
00:07:39,540 --> 00:07:41,450
我会针对

180
00:07:41,550 --> 00:07:42,560
混合高斯模型的情形

181
00:07:42,630 --> 00:07:43,700
对E-step和M-step进行求解

182
00:07:43,780 --> 00:07:45,570
但是在那之前

183
00:07:45,680 --> 00:07:46,770
我想再说一些关于

184
00:07:46,870 --> 00:07:48,140
EM一般形式的事情

185
00:07:48,230 --> 00:07:52,300
事实证明  有另外一种

186
00:07:52,380 --> 00:07:54,350
理解EM算法的方式

187
00:07:54,470 --> 00:07:55,860
我可以

188
00:07:55,940 --> 00:08:00,810
定义一个优化目标

189
00:08:00,920 --> 00:08:07,510
J(θ  Q)  将它定义成这种形式

190
00:08:07,630 --> 00:08:12,920
这就是M-step

191
00:08:13,040 --> 00:08:15,660
中argmax中的式子

192
00:08:15,800 --> 00:08:22,980
对吗?

193
00:08:23,120 --> 00:08:27,470
利用Jensen不等式

194
00:08:27,590 --> 00:08:31,750
我们可以证明

195
00:08:31,890 --> 00:08:36,900
l(θ)≥J(θ  Q)

196
00:08:36,980 --> 00:08:39,210
l(θ)≥J(θ  Q)

197
00:08:39,330 --> 00:08:40,400
换句话说

198
00:08:40,480 --> 00:08:41,600
我们证明了

199
00:08:41,670 --> 00:08:43,410
对于任意θ和Q

200
00:08:43,510 --> 00:08:45,040
对数似然性是

201
00:08:45,130 --> 00:08:45,880
J(θ  Q)的上界

202
00:08:45,980 --> 00:08:49,550
我们可以

203
00:08:49,680 --> 00:08:50,910
联系一下之前

204
00:08:50,980 --> 00:08:51,720
学过的知识

205
00:08:51,770 --> 00:08:54,920
你们也可以在某种意义上思考

206
00:08:55,020 --> 00:08:55,620
协变量原因，额？

207
00:08:55,730 --> 00:09:00,420
但是，我们的讨论一会

208
00:09:00,520 --> 00:09:01,820
关于并列上升最优化

209
00:09:01,900 --> 00:09:04,740
所以我们可以展示

210
00:09:04,880 --> 00:09:06,240
我实际上不会展示这个现象

211
00:09:06,320 --> 00:09:07,490
所以只要记住我的话

212
00:09:07,550 --> 00:09:08,760
你可以回去自己查找它

213
00:09:08,840 --> 00:09:14,120
EM算法实际上是

214
00:09:14,220 --> 00:09:17,940
相对于函数J的坐标上升算法

215
00:09:18,030 --> 00:09:19,310
在E-step

216
00:09:19,360 --> 00:09:20,490
你在相对于 Q进行最大化

217
00:09:20,570 --> 00:09:24,810
而在M-step

218
00:09:24,900 --> 00:09:32,410
你在相对于θ进行最大化

219
00:09:32,510 --> 00:09:34,090
明白吗?

220
00:09:34,130 --> 00:09:36,480
这是EM算法的

221
00:09:36,610 --> 00:09:37,440
另外一种理解方式

222
00:09:37,520 --> 00:09:40,210
这可以帮助你们理解为什么EM算法是收敛的

223
00:09:40,370 --> 00:09:44,040
因为每一次

224
00:09:44,180 --> 00:09:46,180
迭代之后

225
00:09:46,310 --> 00:09:48,580
J(θ  Q)都会

226
00:09:48,650 --> 00:09:49,470
单调上升

227
00:09:49,550 --> 00:09:50,870
明白吗?

228
00:09:50,930 --> 00:09:59,790
接下来我要

229
00:09:59,860 --> 00:10:00,710
将这个

230
00:10:00,800 --> 00:10:02,980
一般化的EM算法流程

231
00:10:03,060 --> 00:10:04,520
应用到

232
00:10:04,580 --> 00:10:08,580
混合高斯模型的情形

233
00:10:08,690 --> 00:10:11,640
在这之前

234
00:10:11,740 --> 00:10:25,020
让我看看

235
00:10:25,150 --> 00:10:26,580
你们关于EM算法

236
00:10:26,680 --> 00:10:28,610
有什么问题?

237
00:10:28,710 --> 00:10:30,930
很好

238
00:10:31,120 --> 00:10:33,710
让我们继续来讲

239
00:10:33,830 --> 00:10:40,790
混合高斯模型的EM算法

240
00:10:40,890 --> 00:10:41,870
我用MoG作为

241
00:10:41,980 --> 00:10:42,670
混合高斯模型的简称

242
00:10:42,740 --> 00:10:43,660
在E-step

243
00:10:43,760 --> 00:10:44,830
我们会求出这些概率分布Q

244
00:10:44,990 --> 00:10:45,940
对吗?

245
00:10:46,030 --> 00:10:46,910
具体地

246
00:10:46,960 --> 00:10:48,080
我想要求出--

247
00:10:48,150 --> 00:10:50,210
Q是隐含随机变量

248
00:10:50,330 --> 00:10:52,370
z上的概率分布

249
00:10:52,480 --> 00:10:54,890
所以在E-step

250
00:10:54,970 --> 00:10:56,050
我要去计算

251
00:10:56,110 --> 00:10:58,140
Q_i (z^((i) )=j)

252
00:10:58,220 --> 00:10:59,350
你可以认为

253
00:10:59,410 --> 00:11:02,070
它表示P(z^((i) )=j)

254
00:11:02,200 --> 00:11:04,310
概率分布Q

255
00:11:04,420 --> 00:11:05,140
就是这个意思

256
00:11:05,210 --> 00:11:10,090
所以EM算法告诉我们

257
00:11:10,210 --> 00:11:15,870
概率分布Q

258
00:11:16,000 --> 00:11:17,900
就等于这个后验概率

259
00:11:18,030 --> 00:11:19,490
P(z^((i) )=j|x^((i) ) Φ  μ  Σ)

260
00:11:19,630 --> 00:11:31,520
对吗?

261
00:11:31,620 --> 00:11:32,410
你计算这个式子的方式

262
00:11:32,480 --> 00:11:34,210
是通过贝叶斯公式

263
00:11:34,350 --> 00:11:36,250
它应该等于这个

264
00:11:42,330 --> 00:11:57,840
对吗?

265
00:11:57,930 --> 00:11:59,670
这个结果是由贝叶斯公式直接得出的

266
00:11:59,800 --> 00:12:04,510
你知道这一项

267
00:12:04,570 --> 00:12:10,890
因x^((i) ) |z^((i) )=j服从均值为μ_j

268
00:12:10,990 --> 00:12:15,890
协方差为Σ_j的

269
00:12:15,970 --> 00:12:16,790
高斯分布

270
00:12:16,840 --> 00:12:18,530
所以为了计算第一项

271
00:12:18,590 --> 00:12:19,380
你只需将参数

272
00:12:19,460 --> 00:12:21,260
μ_j 和Σ_j的高斯分布

273
00:12:21,350 --> 00:12:23,520
的密度函数代入进来

274
00:12:23,590 --> 00:12:25,610
这一项你也知道

275
00:12:25,650 --> 00:12:32,160
因为你知道z服从多项式分布

276
00:12:32,270 --> 00:12:37,460
参数由Φ给出

277
00:12:37,590 --> 00:12:39,710
所以这一项就等于

278
00:12:39,810 --> 00:12:40,590
Φ_j

279
00:12:40,680 --> 00:12:45,180
你可以直接

280
00:12:45,270 --> 00:12:45,830
代进来

281
00:12:45,960 --> 00:12:47,000
类似地

282
00:12:47,090 --> 00:12:47,780
对分母进行同样的代入

283
00:12:47,880 --> 00:12:48,870
这样你就求出了Q

284
00:12:48,970 --> 00:12:50,040
明白吗?

285
00:12:50,130 --> 00:12:53,380
在上一讲

286
00:12:53,510 --> 00:12:54,390
我将

287
00:12:54,480 --> 00:12:57,890
Q_i (z^((i) )=j)

288
00:12:57,990 --> 00:13:00,640
表示为w_j^((i) )

289
00:13:00,740 --> 00:13:02,270
这就是E-step

290
00:13:02,330 --> 00:13:11,550
在M-step

291
00:13:11,620 --> 00:13:15,190
我们相对于所有的参数

292
00:13:15,320 --> 00:13:16,170
令这个式子最大化

293
00:13:16,260 --> 00:13:22,350
我猜今天同样的公式

294
00:13:22,460 --> 00:13:23,690
我得写好几遍

295
00:13:23,770 --> 00:13:29,680
我们

296
00:13:29,780 --> 00:13:49,290
应该将要进行的工作

297
00:13:49,420 --> 00:13:50,580
具体化

298
00:13:50,690 --> 00:13:52,420
所以

299
00:13:52,520 --> 00:13:53,390
我们可以得到--

300
00:13:53,470 --> 00:13:57,570
将你已经知道的这些量代入

301
00:13:57,660 --> 00:14:01,990
会得到这个式子

302
00:14:02,110 --> 00:14:38,230
这样

303
00:14:38,370 --> 00:14:40,840
我们就清楚了

304
00:14:40,920 --> 00:14:42,460
M-step具体应该做什么

305
00:14:42,560 --> 00:14:45,010
在M-step

306
00:14:45,110 --> 00:14:46,060
这里是

307
00:14:46,190 --> 00:14:46,940
Q_i (z^((i) )=j)

308
00:14:47,040 --> 00:14:48,170
内部的

309
00:14:48,270 --> 00:14:49,460
这个对j求和的求和式

310
00:14:49,560 --> 00:14:50,910
实际上是对z^((i) )

311
00:14:51,020 --> 00:14:52,950
所有的可能值进行求和

312
00:14:53,050 --> 00:14:54,880
这里是高斯密度函数

313
00:14:55,000 --> 00:14:57,590
对不起

314
00:14:57,670 --> 00:14:59,840
这里的第一项

315
00:14:59,920 --> 00:15:06,910
是P(x^((i) ) |z^((i) ))

316
00:15:07,040 --> 00:15:11,120
这一项是P(z^((i) ))

317
00:15:11,220 --> 00:15:13,030
明白吗?

318
00:15:13,170 --> 00:15:18,620
为了最大化这个

319
00:15:18,700 --> 00:15:20,330
——如果你想要最大化这个

320
00:15:20,390 --> 00:15:21,680
对于你所有的参数

321
00:15:21,790 --> 00:15:23,490
Φ μ和Σ

322
00:15:23,550 --> 00:15:25,820
使函数最大化

323
00:15:25,930 --> 00:15:26,880
比如说相对于μ

324
00:15:26,950 --> 00:15:29,360
你需要相对于

325
00:15:29,440 --> 00:15:30,280
μ对函数求导

326
00:15:30,340 --> 00:15:33,300
并令导数为0

327
00:15:33,440 --> 00:15:36,710
经过计算

328
00:15:36,850 --> 00:15:37,730
你可以得到这个式子

329
00:15:37,820 --> 00:15:48,940
所以你就用这个式子

330
00:15:49,040 --> 00:15:50,030
更新μ

331
00:15:50,130 --> 00:15:51,600
明白吗?

332
00:15:51,680 --> 00:15:53,820
具体的公式

333
00:15:53,870 --> 00:15:55,380
并不重要

334
00:15:55,480 --> 00:15:57,760
所有这些公式

335
00:15:57,880 --> 00:15:58,530
都写在讲义上

336
00:15:58,630 --> 00:15:59,250
我将这些步骤写下来

337
00:15:59,320 --> 00:16:01,470
是想让你们明白M-step做的

338
00:16:01,540 --> 00:16:02,330
具体的事情

339
00:16:02,440 --> 00:16:03,680
讲这个公式写下来

340
00:16:03,790 --> 00:16:04,850
代入所有你知道的密度函数

341
00:16:04,920 --> 00:16:06,360
相对于参数求导  令导数为0

342
00:16:06,440 --> 00:16:07,090
解出μ_j

343
00:16:07,190 --> 00:16:08,860
并用相同的方式

344
00:16:09,020 --> 00:16:10,320
求解

345
00:16:10,440 --> 00:16:12,250
并更新

346
00:16:12,400 --> 00:16:14,200
其它的

347
00:16:14,300 --> 00:16:16,430
参数的值

348
00:16:16,530 --> 00:16:17,670
明白吗?

349
00:16:17,770 --> 00:16:19,540
这里

350
00:16:19,700 --> 00:16:24,540
还需要指出一点

351
00:16:24,640 --> 00:16:25,590
容易忽略的

352
00:16:25,680 --> 00:16:27,650
地方

353
00:16:27,730 --> 00:16:29,110
你们中有些人可能

354
00:16:29,200 --> 00:16:33,710
已经看出来了

355
00:16:33,800 --> 00:16:34,930
但是我还是要讲一下

356
00:16:34,990 --> 00:16:35,770
Φ_i服从

357
00:16:35,850 --> 00:16:36,960
多项式分布

358
00:16:37,060 --> 00:16:38,370
相对于Φ_i

359
00:16:38,460 --> 00:16:41,870
使这个式子最大化的时候

360
00:16:41,950 --> 00:16:43,180
实际上

361
00:16:43,280 --> 00:16:44,500
还需要满足一些条件  对吗?

362
00:16:44,560 --> 00:16:48,340
也就是

363
00:16:48,440 --> 00:16:51,530
所有的Φ之和必须为1

364
00:16:51,620 --> 00:16:52,470
对吗?

365
00:16:52,560 --> 00:16:54,190
在M-step

366
00:16:54,280 --> 00:16:55,030
我希望相对于所有的参数

367
00:16:55,130 --> 00:16:56,010
令这个式子

368
00:16:56,090 --> 00:16:56,820
最大化

369
00:16:56,890 --> 00:16:59,110
对于

370
00:16:59,180 --> 00:17:00,290
参数Φ_j

371
00:17:00,380 --> 00:17:02,280
你需要满足约束:

372
00:17:02,380 --> 00:17:04,490
所有的Φ之和

373
00:17:04,560 --> 00:17:05,170
等于1

374
00:17:05,250 --> 00:17:08,550
你们已经知道

375
00:17:08,640 --> 00:17:09,420
如何处理有约束的优化问题了

376
00:17:09,480 --> 00:17:10,140
对吗?

377
00:17:10,190 --> 00:17:11,020
我们之前在讲SVM的时候

378
00:17:11,070 --> 00:17:11,640
讲过拉格朗日乘数法

379
00:17:11,680 --> 00:17:12,210
和通用拉格朗日

380
00:17:12,270 --> 00:17:14,290
算子

381
00:17:14,340 --> 00:17:16,090
为了相对于

382
00:17:16,180 --> 00:17:17,570
Φ_j进行最大化

383
00:17:17,630 --> 00:17:21,360
你需要构造拉格朗日算子

384
00:17:21,460 --> 00:17:24,570
对吗?

385
00:17:24,650 --> 00:17:25,950
应该是

386
00:17:26,010 --> 00:17:27,560
这个公式

387
00:17:27,680 --> 00:17:29,340
加上β

388
00:17:29,440 --> 00:17:34,970
乘上这个式子

389
00:17:35,050 --> 00:17:36,290
这里是拉格朗日算子

390
00:17:36,380 --> 00:17:44,960
这里是你的优化目标

391
00:17:47,970 --> 00:17:49,160
为了求解

392
00:17:49,250 --> 00:17:51,940
Φ_j

393
00:17:52,100 --> 00:17:53,240
你需要对拉格朗日算子求导

394
00:17:53,330 --> 00:17:58,380
并令导数为0  之后进行求解

395
00:17:58,500 --> 00:17:59,200
明白吗?

396
00:17:59,260 --> 00:18:01,830
经过一些数学推导

397
00:18:01,890 --> 00:18:04,120
你会

398
00:18:04,200 --> 00:18:05,410
得到Φ_j的新值

399
00:18:05,500 --> 00:18:07,990
我这里

400
00:18:08,050 --> 00:18:10,710
就不写了

401
00:18:10,810 --> 00:18:11,730
讲义上都有

402
00:18:11,820 --> 00:18:12,640
我这里不写了

403
00:18:12,750 --> 00:18:16,070
如果

404
00:18:16,160 --> 00:18:20,110
你进行了上面的

405
00:18:20,190 --> 00:18:20,870
这些计算

406
00:18:20,960 --> 00:18:21,740
你就可以验证之前的结论

407
00:18:21,860 --> 00:18:23,660
我写出了

408
00:18:23,770 --> 00:18:25,710
EM算法的一些公式

409
00:18:25,770 --> 00:18:28,380
上节课一开始

410
00:18:28,480 --> 00:18:29,100
我讲到

411
00:18:29,200 --> 00:18:29,910
对于混合高斯模型

412
00:18:29,950 --> 00:18:32,010
使用EM算法

413
00:18:32,090 --> 00:18:33,280
这是计算w_i^((j) )的公式

414
00:18:33,370 --> 00:18:34,310
这是

415
00:18:34,380 --> 00:18:35,470
计算μ的公式

416
00:18:35,560 --> 00:18:36,250
等等

417
00:18:36,310 --> 00:18:37,550
上面的这些推导过程展示了

418
00:18:37,680 --> 00:18:38,940
我们如何得到的这些公式

419
00:18:39,020 --> 00:18:44,090
有问题吗?

420
00:18:44,200 --> 00:18:46,540
什么问题?

421
00:18:46,620 --> 00:18:48,410
S:

422
00:18:48,490 --> 00:18:52,320
I:【听不清】

423
00:18:52,420 --> 00:18:55,420
实际上

424
00:18:55,500 --> 00:18:56,380
应该还有这样的约束:

425
00:18:56,450 --> 00:18:58,430
Φ_j≥0

426
00:18:58,500 --> 00:19:03,110
如果你愿意的话

427
00:19:03,230 --> 00:19:05,870
你可以使用包含了

428
00:19:05,920 --> 00:19:07,560
这些约束的

429
00:19:07,660 --> 00:19:08,750
通用拉格朗日

430
00:19:08,840 --> 00:19:09,510
算子

431
00:19:09,590 --> 00:19:10,910
在考虑这些约束的情况下

432
00:19:10,980 --> 00:19:11,580
进行求解

433
00:19:11,670 --> 00:19:12,990
事实证明

434
00:19:13,040 --> 00:19:14,750
在求偏导数的时候

435
00:19:14,760 --> 00:19:16,140
--我们经常会对

436
00:19:16,210 --> 00:19:17,800
多项式分布的概率

437
00:19:17,890 --> 00:19:18,950
进行极大似然估计

438
00:19:19,020 --> 00:19:20,660
事实证明

439
00:19:20,730 --> 00:19:21,710
这种情况下

440
00:19:21,750 --> 00:19:23,020
如果你忽略这些约束

441
00:19:23,110 --> 00:19:26,820
你会幸运地

442
00:19:26,890 --> 00:19:29,610
得到大于

443
00:19:29,660 --> 00:19:30,350
等于0的解

444
00:19:30,440 --> 00:19:33,040
所以即使忽略这些约束

445
00:19:33,120 --> 00:19:34,770
你也会得到

446
00:19:34,870 --> 00:19:36,070
大于等于0的解

447
00:19:36,170 --> 00:19:37,000
这些解一定是

448
00:19:37,200 --> 00:19:37,900
正确答案

449
00:19:37,990 --> 00:19:39,730
因为增加这些约束

450
00:19:39,850 --> 00:19:40,570
不会改变任何结果

451
00:19:40,650 --> 00:19:44,040
所以这些约束在这种情况下是不需要的

452
00:19:44,120 --> 00:19:45,780
忽略掉它们

453
00:19:45,850 --> 00:19:46,990
按照我写的这些进行求解

454
00:19:47,070 --> 00:19:48,140
也会得到正确的结果

455
00:19:48,210 --> 00:19:56,840
Ok

456
00:19:56,920 --> 00:20:01,900
让我再来快速地介绍

457
00:20:01,970 --> 00:20:03,600
一个混合模型的例子

458
00:20:03,720 --> 00:20:06,640
这个例子

459
00:20:06,690 --> 00:20:07,950
是关于

460
00:20:08,030 --> 00:20:09,220
文本聚类的

461
00:20:09,270 --> 00:20:10,710
有人给你很多文本

462
00:20:10,800 --> 00:20:13,380
你希望将它们

463
00:20:13,470 --> 00:20:15,590
聚类成若干一致的主题

464
00:20:15,700 --> 00:20:18,580
我记得我提到过

465
00:20:18,650 --> 00:20:19,450
news.google.com的例子

466
00:20:19,530 --> 00:20:20,470
这是文本聚类的一个应用

467
00:20:20,560 --> 00:20:21,990
你可以看到

468
00:20:22,090 --> 00:20:24,090
今天发生的

469
00:20:24,220 --> 00:20:25,880
新闻故事

470
00:20:26,010 --> 00:20:28,760
以及每个人

471
00:20:28,850 --> 00:20:29,580
和每个新闻网站

472
00:20:29,640 --> 00:20:30,740
写的新闻故事

473
00:20:30,790 --> 00:20:31,760
以及昨天发生的故事等等

474
00:20:31,820 --> 00:20:32,710
关于同样的事情

475
00:20:32,790 --> 00:20:34,770
会有很多

476
00:20:34,850 --> 00:20:35,670
不同的故事

477
00:20:35,730 --> 00:20:36,320
对吗?

478
00:20:36,400 --> 00:20:38,130
使用文本聚类算法

479
00:20:38,200 --> 00:20:39,450
你可以

480
00:20:39,530 --> 00:20:40,680
将相关的文档分成不同的类

481
00:20:40,730 --> 00:20:41,980
Ok

482
00:20:42,070 --> 00:20:44,690
那么怎样在文本聚类问题中

483
00:20:44,760 --> 00:20:45,450
应用EM算法呢?

484
00:20:45,540 --> 00:20:54,480
我要用一个

485
00:20:54,600 --> 00:20:56,660
例子来说明

486
00:20:56,770 --> 00:20:58,620
我们的输入特征

487
00:20:58,720 --> 00:21:00,450
都是取离散的值

488
00:21:00,570 --> 00:21:02,200
每个

489
00:21:02,320 --> 00:21:03,870
训练样本x^((i) )

490
00:21:03,960 --> 00:21:05,050
都取离散的值

491
00:21:05,130 --> 00:21:07,540
我接下来要讲

492
00:21:07,610 --> 00:21:08,360
的是

493
00:21:08,600 --> 00:21:10,750
混合朴素贝叶斯模型

494
00:21:10,830 --> 00:21:18,570
你们应该记得

495
00:21:18,640 --> 00:21:21,270
我讲过朴素贝叶斯

496
00:21:21,340 --> 00:21:22,040
的两种事件模型

497
00:21:22,100 --> 00:21:22,970
一个是

498
00:21:23,040 --> 00:21:24,130
多值伯努利事件模型

499
00:21:24,190 --> 00:21:26,310
一个是多项式事件模型

500
00:21:26,400 --> 00:21:28,400
今天我要用到的是

501
00:21:28,490 --> 00:21:30,050
多值伯努利事件模型

502
00:21:30,130 --> 00:21:31,460
如果你不记得

503
00:21:31,550 --> 00:21:33,000
这些术语

504
00:21:33,060 --> 00:21:33,770
不用担心

505
00:21:33,830 --> 00:21:35,630
我觉得你们应该能

506
00:21:35,700 --> 00:21:36,290
看懂这些公式

507
00:21:36,390 --> 00:21:38,170
给定一个

508
00:21:38,240 --> 00:21:44,920
包含m个样本的训练集合

509
00:21:45,020 --> 00:21:47,750
所以我们给定了m个文本

510
00:21:47,850 --> 00:21:57,290
每个文本都是一个n维0-1向量

511
00:21:57,380 --> 00:21:59,670
所以每个文本

512
00:21:59,730 --> 00:22:03,330
都是一个n维的位向量

513
00:22:03,440 --> 00:22:05,530
对吗?

514
00:22:05,630 --> 00:22:10,000
x_j^((i) )表示

515
00:22:10,120 --> 00:22:16,600
词语j是否出现在文档i中

516
00:22:16,680 --> 00:22:25,190
比如说

517
00:22:25,280 --> 00:22:29,490
我们希望对z^((i) )建模

518
00:22:29,570 --> 00:22:32,600
它是隐含随机变量

519
00:22:32,710 --> 00:22:33,670
可以

520
00:22:33,750 --> 00:22:34,680
在上取值

521
00:22:34,790 --> 00:22:37,330
这意味着我希望找到

522
00:22:37,420 --> 00:22:38,310
两个类

523
00:22:38,360 --> 00:22:39,850
如果你希望推广的话

524
00:22:39,930 --> 00:22:40,570
也可以取更多的值

525
00:22:40,630 --> 00:22:48,210
对于混合朴素贝叶斯的情形

526
00:22:48,300 --> 00:22:52,890
我们假设z^((i) )

527
00:22:52,970 --> 00:22:58,960
服从参数为Φ的伯努利分布

528
00:22:59,050 --> 00:23:01,650
所以每一个样本

529
00:23:01,690 --> 00:23:04,070
按照某个概率

530
00:23:04,160 --> 00:23:04,940
属于类1或类2

531
00:23:05,050 --> 00:23:06,360
我们对

532
00:23:06,450 --> 00:23:16,310
P(x^((i) ) |z^((i) ))

533
00:23:16,390 --> 00:23:23,170
做出和之前的

534
00:23:23,290 --> 00:23:24,540
朴素贝叶斯相同的假设

535
00:23:24,620 --> 00:23:33,410
对吗?

536
00:23:33,460 --> 00:23:37,720
具体地

537
00:23:37,750 --> 00:24:01,440
--对不起

538
00:24:01,530 --> 00:24:03,670
所以

539
00:24:03,720 --> 00:24:06,980
P(x_j^((i) )=1│z^((i) )=0)=Φ_(j|z=0)

540
00:24:07,070 --> 00:24:10,810
P(x_j^((i) )=1│z^((i) )=0)=Φ_(j|z=0)

541
00:24:10,900 --> 00:24:13,160
P(x_j^((i) )=1│z^((i) )=0)=Φ_(j|z=0)

542
00:24:13,280 --> 00:24:20,400
如果你将

543
00:24:20,520 --> 00:24:22,070
这块黑板上

544
00:24:22,160 --> 00:24:25,450
所有出现的z 替换成y

545
00:24:25,530 --> 00:24:28,920
那么你会得到

546
00:24:29,020 --> 00:24:30,830
我很早以前讲过的

547
00:24:30,930 --> 00:24:32,910
朴素贝叶斯的公式

548
00:24:33,020 --> 00:24:36,330
对吗?

549
00:24:36,390 --> 00:24:42,110
我不打算具体地

550
00:24:42,190 --> 00:24:43,700
推导出EM算法

551
00:24:43,720 --> 00:24:46,270
实际上

552
00:24:46,340 --> 00:24:47,770
如果你用

553
00:24:47,850 --> 00:24:51,220
x和z的

554
00:24:51,320 --> 00:24:52,210
联合概率

555
00:24:52,310 --> 00:24:52,930
按照参数的极大似然

556
00:24:53,010 --> 00:24:54,540
估计推导出EM算法

557
00:24:54,640 --> 00:24:55,850
的公式的话

558
00:24:55,950 --> 00:25:02,270
你会发现  在E-step

559
00:25:02,330 --> 00:25:06,980
你需要计算  这些参数

560
00:25:07,090 --> 00:25:09,330
这些权重w^((i) )应该

561
00:25:09,430 --> 00:25:11,380
等于这个条件概率

562
00:25:11,480 --> 00:25:13,260
以x^((i) )为条件

563
00:25:13,360 --> 00:25:16,650
以Φ为参数

564
00:25:16,710 --> 00:25:20,880
在M-step

565
00:25:20,990 --> 00:25:26,330
你

566
00:25:26,410 --> 00:25:39,350
会得到

567
00:25:39,410 --> 00:26:19,130
这些

568
00:26:19,230 --> 00:26:20,330
公式

569
00:26:20,450 --> 00:26:23,330
这些公式本身

570
00:26:23,390 --> 00:26:24,240
并不是很重要

571
00:26:24,330 --> 00:26:26,590
它们只是为了表达

572
00:26:26,660 --> 00:26:29,100
我会给你们一点时间

573
00:26:29,200 --> 00:26:30,390
写完它

574
00:26:30,450 --> 00:26:32,220
当你写完的时候

575
00:26:32,320 --> 00:26:33,150
看一看这些

576
00:26:33,240 --> 00:26:33,970
公式

577
00:26:34,040 --> 00:26:35,180
看看你们是否能够直观的理解

578
00:26:35,240 --> 00:26:36,330
为什么这三个公式

579
00:26:36,400 --> 00:26:39,180
是

580
00:26:39,260 --> 00:26:42,160
有意义的  什么问题?

581
00:26:42,270 --> 00:26:46,410
S: (听不清)

582
00:26:46,520 --> 00:26:48,250
I:能再说一遍吗?

583
00:26:48,360 --> 00:26:49,730
S: Y

584
00:26:49,820 --> 00:26:58,270
I:是的   谢谢  对不起

585
00:26:58,370 --> 00:27:00,620
这里的y都应该是z

586
00:27:11,670 --> 00:27:14,730
YEAH

587
00:27:14,820 --> 00:27:16,340
S:这是什么?

588
00:27:18,290 --> 00:27:21,050
不 嗯

589
00:27:24,520 --> 00:27:27,850
通常情况下

590
00:27:27,930 --> 00:27:29,350
你可以随机地

591
00:27:29,430 --> 00:27:30,820
初始化Φ

592
00:27:35,250 --> 00:27:36,840
和朴素贝叶斯的情形相同

593
00:27:36,950 --> 00:27:38,750
0概率是一种不好的情况

594
00:27:38,800 --> 00:27:40,720
所以我们应该

595
00:27:40,800 --> 00:27:41,710
避免0概率

596
00:27:41,800 --> 00:27:50,070
让我们看看E-step公式的

597
00:27:50,150 --> 00:27:51,300
直观含义

598
00:27:51,360 --> 00:27:58,010
w^((i) )表示

599
00:27:58,060 --> 00:27:59,430
你对于当前文档来自于哪个类的

600
00:27:59,520 --> 00:28:01,290
最好的猜测

601
00:28:01,400 --> 00:28:03,920
这和我们

602
00:28:04,020 --> 00:28:07,170
之前讨论的EM算法

603
00:28:07,270 --> 00:28:07,980
背后的直观含义

604
00:28:08,090 --> 00:28:08,630
非常类似

605
00:28:08,690 --> 00:28:09,700
在E-step

606
00:28:09,750 --> 00:28:12,080
我们会去计算这些权值

607
00:28:12,160 --> 00:28:12,810
告诉我们

608
00:28:12,880 --> 00:28:13,970
我们目前相信文档

609
00:28:14,050 --> 00:28:15,070
来自于哪个类

610
00:28:15,230 --> 00:28:20,260
在M-step

611
00:28:20,340 --> 00:28:24,100
分子实际是

612
00:28:24,190 --> 00:28:26,240
一些元素

613
00:28:26,330 --> 00:28:27,460
之和--

614
00:28:27,540 --> 00:28:29,870
这只是一种非正式的说法

615
00:28:29,920 --> 00:28:31,430
你可以认为w^((i) )等于1

616
00:28:31,490 --> 00:28:33,690
这里我考虑的是文档

617
00:28:33,760 --> 00:28:37,480
可能来自于类1的情形

618
00:28:37,580 --> 00:28:39,460
所以分子是

619
00:28:39,540 --> 00:28:40,940
我认为来自于

620
00:28:41,030 --> 00:28:44,450
类1且包含词j

621
00:28:44,560 --> 00:28:45,660
的文档个数

622
00:28:45,720 --> 00:28:47,250
这些权值实际上就是概率

623
00:28:47,330 --> 00:28:48,230
我认为它来

624
00:28:48,300 --> 00:28:49,130
自于类1的概率

625
00:28:49,210 --> 00:28:51,620
如果我认为w只能

626
00:28:51,770 --> 00:28:52,990
取0或1的话

627
00:28:53,030 --> 00:28:55,300
需要除以的就是

628
00:28:55,370 --> 00:28:56,810
我认为来自于

629
00:28:56,860 --> 00:28:57,580
类1的文档的总数

630
00:28:57,660 --> 00:28:58,880
所以如果所有的w^((i) )都只能取

631
00:28:58,940 --> 00:29:00,810
0或1的话

632
00:29:00,880 --> 00:29:02,300
那么这个式子就是

633
00:29:02,390 --> 00:29:04,060
类1中包含词j

634
00:29:04,150 --> 00:29:07,130
的文档的

635
00:29:07,220 --> 00:29:08,680
比率

636
00:29:08,740 --> 00:29:09,480
明白吗?

637
00:29:09,530 --> 00:29:10,440
但是在EM算法中

638
00:29:10,530 --> 00:29:11,740
你不能做出

639
00:29:11,810 --> 00:29:13,170
一个如此

640
00:29:13,230 --> 00:29:14,280
绝对

641
00:29:14,360 --> 00:29:15,530
的假设

642
00:29:15,570 --> 00:29:17,890
所以你需要用权值w^((i) )来表达

643
00:29:17,990 --> 00:29:18,910
属于哪个类的

644
00:29:18,990 --> 00:29:19,810
不确定性

645
00:29:19,940 --> 00:29:22,230
明白吗?

646
00:29:22,330 --> 00:29:24,810
事实证明

647
00:29:24,880 --> 00:29:27,420
对于

648
00:29:27,490 --> 00:29:28,220
这个特殊的模型

649
00:29:28,300 --> 00:29:29,150
我们计算

650
00:29:29,260 --> 00:29:30,020
得到的

651
00:29:30,080 --> 00:29:31,250
w^((i) )的值

652
00:29:31,330 --> 00:29:34,310
将会非常接近于0或1

653
00:29:34,380 --> 00:29:35,960
在数值上

654
00:29:36,020 --> 00:29:37,530
它们和0或1

655
00:29:37,620 --> 00:29:39,140
没有什么区别

656
00:29:39,190 --> 00:29:39,820
这是朴素贝叶斯的性质

657
00:29:39,890 --> 00:29:40,760
如果你对于所有这些文档

658
00:29:40,820 --> 00:29:42,740
计算概率

659
00:29:42,810 --> 00:29:45,970
你会发现w^((i) )等于0.0001

660
00:29:46,050 --> 00:29:46,900
或者0.999

661
00:29:46,940 --> 00:29:48,690
它的值和

662
00:29:48,750 --> 00:29:49,530
0或1非常接近

663
00:29:49,610 --> 00:29:50,790
所以在M-step--

664
00:29:50,860 --> 00:29:51,890
实际上就是在猜测

665
00:29:51,970 --> 00:29:53,640
文档来自

666
00:29:53,730 --> 00:29:54,530
类0或类1

667
00:29:54,620 --> 00:29:57,960
用到的公式

668
00:29:58,060 --> 00:29:59,380
和朴素贝叶斯

669
00:29:59,470 --> 00:30:01,580
非常相似

670
00:30:01,680 --> 00:30:06,720
明白吗?很好

671
00:30:06,820 --> 00:30:10,860
如果

672
00:30:10,940 --> 00:30:12,460
这些公式

673
00:30:12,530 --> 00:30:14,270
还是看不懂

674
00:30:14,370 --> 00:30:15,620
回去复习

675
00:30:15,720 --> 00:30:20,350
一下朴素贝叶斯

676
00:30:20,410 --> 00:30:22,510
希望这样

677
00:30:22,590 --> 00:30:23,760
会有

678
00:30:23,840 --> 00:30:25,530
帮助

679
00:30:25,620 --> 00:30:27,330
在我继续之前还有问题吗?

680
00:30:27,430 --> 00:30:31,140
好的

681
00:30:31,220 --> 00:30:34,940
这些公式并不是凭空得到的

682
00:30:35,050 --> 00:30:36,680
而是基于

683
00:30:36,770 --> 00:30:37,760
EM算法框架求出的

684
00:30:37,850 --> 00:30:39,080
推出

685
00:30:39,210 --> 00:30:40,480
这些

686
00:30:40,600 --> 00:30:41,320
结果的方法是:

687
00:30:41,410 --> 00:30:42,710
对于这个模型  写出E-step

688
00:30:42,810 --> 00:30:43,780
和M-step

689
00:30:43,880 --> 00:30:45,930
之后令导数

690
00:30:46,020 --> 00:30:46,990
为0

691
00:30:47,090 --> 00:30:47,860
并进行求解

692
00:30:48,000 --> 00:30:49,130
这样就可以得到

693
00:30:49,220 --> 00:30:50,070
这些公式了

694
00:30:50,160 --> 00:31:23,410
今天我要讲的最后一个知识点

695
00:31:23,510 --> 00:31:25,240
是因子分析模型

696
00:31:25,370 --> 00:31:37,690
之所以要讲它

697
00:31:37,800 --> 00:31:39,610
主要基于两个原因

698
00:31:39,750 --> 00:31:40,570
首先它是一个

699
00:31:40,660 --> 00:31:41,960
非常有用的模型

700
00:31:42,090 --> 00:31:44,660
虽然它的应用

701
00:31:44,750 --> 00:31:45,360
并不如混合高斯模型

702
00:31:45,430 --> 00:31:47,420
或者混合贝叶斯模型那样广泛

703
00:31:47,510 --> 00:31:50,570
但是还是很有用的

704
00:31:50,670 --> 00:31:52,110
另外

705
00:31:52,200 --> 00:31:53,620
一个原因是

706
00:31:53,740 --> 00:31:56,030
这个模型的推导过程中

707
00:31:56,120 --> 00:31:57,250
用到的一些数学步骤是非常有用的

708
00:31:57,310 --> 00:31:58,600
具体地

709
00:31:58,700 --> 00:32:00,010
对于

710
00:32:00,080 --> 00:32:01,040
因子分析

711
00:32:01,150 --> 00:32:03,350
EM算法

712
00:32:03,410 --> 00:32:06,140
中的

713
00:32:06,260 --> 00:32:08,040
隐含随机变量

714
00:32:08,170 --> 00:32:10,110
是连续取值的

715
00:32:10,250 --> 00:32:12,780
所以

716
00:32:12,860 --> 00:32:14,340
因子分析模型的推导过程

717
00:32:14,410 --> 00:32:15,230
和你之前看到的一些推导过程

718
00:32:15,270 --> 00:32:15,850
不太一样

719
00:32:15,960 --> 00:32:17,010
因子分析的

720
00:32:17,040 --> 00:32:19,350
完整的

721
00:32:19,420 --> 00:32:20,470
EM算法推导过程

722
00:32:20,520 --> 00:32:21,760
很长  而且非常复杂

723
00:32:21,810 --> 00:32:22,750
所以今天课上

724
00:32:22,790 --> 00:32:25,340
我不会强求你们看懂

725
00:32:25,420 --> 00:32:28,160
但是相比于

726
00:32:28,210 --> 00:32:29,430
其他部分而言 

727
00:32:29,510 --> 00:32:30,610
这一部分我还是会写出

728
00:32:30,670 --> 00:32:31,670
更多的公式

729
00:32:31,720 --> 00:32:33,360
因为因子分析中只有少数几步

730
00:32:33,450 --> 00:32:34,610
是可以不用公式

731
00:32:34,680 --> 00:32:37,020
仅靠例子就可以说清楚的

732
00:32:37,100 --> 00:32:42,970
为了引出这个模型

733
00:32:43,060 --> 00:32:45,090
我们需要将其

734
00:32:45,190 --> 00:32:45,800
和混合高斯模型进行对比

735
00:32:45,880 --> 00:32:46,700
混合

736
00:32:46,770 --> 00:32:48,010
高斯模型是

737
00:32:48,090 --> 00:32:49,750
我们的第一个模型

738
00:32:49,820 --> 00:32:52,230
在介绍它的时候我们用过

739
00:32:52,270 --> 00:32:56,530
这样的一个数据集合

740
00:32:56,620 --> 00:32:57,900
对吗?

741
00:32:57,950 --> 00:32:59,030
数据集合看起来

742
00:32:59,100 --> 00:32:59,770
是这样的

743
00:32:59,830 --> 00:33:05,580
这个问题中

744
00:33:05,640 --> 00:33:08,240
样本维度n等于2

745
00:33:08,280 --> 00:33:10,640
样本

746
00:33:10,710 --> 00:33:11,610
数目大概等于100

747
00:33:11,670 --> 00:33:12,810
这样

748
00:33:12,850 --> 00:33:16,860
你们就有了

749
00:33:16,930 --> 00:33:18,410
一个无标记的训练集合

750
00:33:18,440 --> 00:33:19,540
你希望用

751
00:33:19,610 --> 00:33:22,140
包含两个分布的混合高斯模型

752
00:33:22,210 --> 00:33:23,990
进行建模

753
00:33:24,080 --> 00:33:25,530
当m非常大的时候  使用混合高斯模型

754
00:33:25,620 --> 00:33:28,150
是可以的

755
00:33:28,270 --> 00:33:33,260
一般情况下

756
00:33:33,310 --> 00:33:34,300
m至少应该

757
00:33:34,410 --> 00:33:36,290
大于样本

758
00:33:36,340 --> 00:33:38,770
的维度n

759
00:33:38,860 --> 00:33:39,780
一般情况下

760
00:33:39,850 --> 00:33:41,830
会远远大于n

761
00:33:41,890 --> 00:33:47,180
这样就可能

762
00:33:47,230 --> 00:33:48,090
存在一个问题

763
00:33:48,150 --> 00:33:50,210
想象一下

764
00:33:50,320 --> 00:33:52,970
如果你的数据维度n

765
00:33:53,050 --> 00:33:54,700
大致等于

766
00:33:54,770 --> 00:33:56,880
或者

767
00:33:56,940 --> 00:34:02,430
远远大于

768
00:34:02,560 --> 00:34:05,270
样本数目m

769
00:34:05,380 --> 00:34:06,930
你们应该怎么做

770
00:34:07,090 --> 00:34:11,360
对于高维的数据

771
00:34:11,410 --> 00:34:12,140
应该如何建模?

772
00:34:12,200 --> 00:34:15,100
这种情况经常会遇到

773
00:34:15,180 --> 00:34:16,950
假设你在经营一个车间

774
00:34:17,020 --> 00:34:17,670
或者工厂

775
00:34:17,740 --> 00:34:20,400
你需要进行

776
00:34:20,500 --> 00:34:21,250
上千项测量

777
00:34:21,380 --> 00:34:22,250
但是你可能只有

778
00:34:22,340 --> 00:34:23,380
20个数据样本

779
00:34:23,460 --> 00:34:26,350
现在数据维度为1000

780
00:34:26,460 --> 00:34:28,220
样本数目为20

781
00:34:28,320 --> 00:34:32,760
假设我们的数据

782
00:34:32,820 --> 00:34:36,070
具有这样的性质

783
00:34:36,200 --> 00:34:38,860
给定一个包含了m个样本的

784
00:34:38,960 --> 00:34:40,050
训练集合

785
00:34:40,120 --> 00:34:41,040
你该怎样对

786
00:34:41,130 --> 00:34:42,410
P(x)进行建模?

787
00:34:42,500 --> 00:34:44,890
你可以

788
00:34:44,990 --> 00:34:46,080
不考虑混合高斯模型

789
00:34:46,220 --> 00:34:47,790
直接用简单的高斯模型进行建模

790
00:34:47,910 --> 00:34:48,700
比

791
00:34:48,790 --> 00:34:49,980
如

792
00:34:50,030 --> 00:34:50,810
说

793
00:34:50,900 --> 00:34:53,780
x服从均值为μ

794
00:34:53,870 --> 00:35:00,730
协方差为Σ的高斯分布

795
00:35:00,840 --> 00:35:02,650
这里Σ为n*n的矩阵

796
00:35:02,760 --> 00:35:06,860
如果你

797
00:35:06,910 --> 00:35:07,740
通过极大似然估计

798
00:35:07,820 --> 00:35:08,630
球这些参数的话

799
00:35:08,700 --> 00:35:10,420
你会发现

800
00:35:10,540 --> 00:35:11,490
μ应该

801
00:35:11,560 --> 00:35:12,220
等于

802
00:35:12,290 --> 00:35:14,920
所有样本的平均值

803
00:35:14,990 --> 00:35:21,570
这个结果是有意义的

804
00:35:21,610 --> 00:35:22,350
协方差矩阵的极大似然

805
00:35:22,410 --> 00:35:24,080
估计等于这个结果

806
00:35:24,130 --> 00:35:39,960
实际上

807
00:35:40,030 --> 00:35:42,530
如果数据的维度

808
00:35:42,600 --> 00:35:43,810
远大于

809
00:35:43,870 --> 00:35:45,990
训练

810
00:35:46,070 --> 00:35:47,780
样本的数目

811
00:35:47,870 --> 00:35:51,660
你通过

812
00:35:51,750 --> 00:35:52,730
极大似然

813
00:35:52,850 --> 00:35:54,130
估计

814
00:35:54,230 --> 00:35:56,400
得到的矩阵是奇异矩阵

815
00:35:56,500 --> 00:36:00,640
矩阵是奇异的

816
00:36:00,730 --> 00:36:01,450
意味着它不满秩

817
00:36:01,520 --> 00:36:02,540
而且特征值为0

818
00:36:02,610 --> 00:36:04,080
希望你们

819
00:36:04,160 --> 00:36:06,080
能听懂这些术语

820
00:36:06,160 --> 00:36:13,660
这就意味着

821
00:36:13,740 --> 00:36:16,080
矩阵Σ是不可逆的

822
00:36:16,130 --> 00:36:23,130
举一个

823
00:36:23,270 --> 00:36:28,180
具体的例子

824
00:36:28,280 --> 00:36:31,060
如果n=m=2

825
00:36:31,170 --> 00:36:32,320
如果数据是2维的

826
00:36:32,390 --> 00:36:34,550
而且只有两个样本

827
00:36:34,610 --> 00:36:36,700
我有两个二维的样本

828
00:36:36,750 --> 00:36:39,720
坐标轴是x_1 和x_2

829
00:36:39,830 --> 00:36:42,820
这是我们的无标记数据

830
00:36:42,900 --> 00:36:44,510
如果你用这组数据

831
00:36:44,600 --> 00:36:45,310
拟合高斯模型

832
00:36:45,350 --> 00:36:46,190
那么你会发现

833
00:36:46,220 --> 00:36:50,010
--我们用一组椭圆

834
00:36:50,050 --> 00:36:51,310
来表示高斯密度函数的轮廓

835
00:36:51,390 --> 00:36:54,040
这些轮廓表示

836
00:36:54,150 --> 00:36:55,440
不同的高斯分布

837
00:36:55,510 --> 00:36:56,620
你会发现

838
00:36:56,710 --> 00:37:00,030
通过极大似然估计

839
00:37:00,150 --> 00:37:00,960
的到的高斯分布

840
00:37:01,020 --> 00:37:04,720
对应的轮廓

841
00:37:04,800 --> 00:37:05,830
是一个无限细而且在

842
00:37:05,920 --> 00:37:06,760
这个方向上无限长的形状

843
00:37:06,860 --> 00:37:09,550
轮廓的宽度

844
00:37:09,620 --> 00:37:13,380
无限细

845
00:37:13,450 --> 00:37:14,460
这个方向上延伸的长度

846
00:37:14,620 --> 00:37:15,400
无限长

847
00:37:15,480 --> 00:37:20,080
你也可以通过另外一种方式发现这个问题

848
00:37:20,150 --> 00:37:24,180
你可以将Σ代入

849
00:37:24,280 --> 00:37:25,010
高斯密度函数的公式中

850
00:37:25,100 --> 00:37:32,840
你并不会

851
00:37:32,900 --> 00:37:38,090
得到一个很好的结果

852
00:37:38,160 --> 00:37:40,380
因为Σ是

853
00:37:40,440 --> 00:37:41,130
不可逆的

854
00:37:41,190 --> 00:37:42,480
所以这里的Σ^(-1)是一个未定义的矩阵

855
00:37:42,540 --> 00:37:44,240
而这里的行列式的值等于0

856
00:37:44,280 --> 00:37:46,840
所以这个

857
00:37:46,950 --> 00:37:49,390
式子的分母等于0

858
00:37:49,450 --> 00:37:53,590
从而这个模型

859
00:37:53,670 --> 00:37:54,590
并不是一个好模型

860
00:37:54,660 --> 00:37:59,650
我们应该可以做的更好

861
00:37:59,750 --> 00:38:01,080
假定给你这样的数据

862
00:38:01,160 --> 00:38:03,120
你该如何对P(x)进行建模?

863
00:38:03,190 --> 00:38:29,300
你可以将

864
00:38:29,400 --> 00:38:32,080
Σ限制为对角矩阵

865
00:38:32,170 --> 00:38:44,240
所以x服从这样的高斯分布

866
00:38:44,310 --> 00:38:47,580
换句话说

867
00:38:47,650 --> 00:38:48,310
你将Σ限制成

868
00:38:48,360 --> 00:38:50,320
这样的一个矩阵

869
00:38:50,390 --> 00:38:51,860
所有不在对角线上的元素都是0

870
00:38:51,910 --> 00:38:58,140
我希望你们能看懂

871
00:38:58,210 --> 00:39:02,110
我写在这里的0

872
00:39:02,200 --> 00:39:04,190
表示除了对角线之外的

873
00:39:04,290 --> 00:39:06,310
所有元素都是0

874
00:39:06,370 --> 00:39:10,600
对这个矩阵的极大似然

875
00:39:10,650 --> 00:39:13,090
估计的结果

876
00:39:13,200 --> 00:39:17,610
你们应该可以猜到

877
00:39:17,670 --> 00:39:23,530
用图来表示

878
00:39:23,590 --> 00:39:26,760
这样的矩阵意味着

879
00:39:26,830 --> 00:39:29,910
高斯分布的轮廓的轴和坐标轴

880
00:39:29,970 --> 00:39:30,960
是平行的

881
00:39:31,000 --> 00:39:33,470
这是协方差矩阵

882
00:39:33,490 --> 00:39:36,630
为对角矩阵的高斯分布的例子

883
00:39:36,690 --> 00:39:39,940
这里是第二个例子

884
00:39:40,020 --> 00:39:43,960
和第三个例子

885
00:39:44,050 --> 00:39:46,370
通常情况下

886
00:39:46,460 --> 00:39:48,850
协方差矩阵

887
00:39:48,960 --> 00:39:50,750
并不是一个对角矩阵

888
00:39:50,820 --> 00:39:54,770
你可以用这种方法对

889
00:39:54,880 --> 00:39:55,630
P(x)进行建模

890
00:39:55,700 --> 00:39:56,390
但是这并不是个好主意

891
00:39:56,470 --> 00:39:57,450
因为这样你就丢失

892
00:39:57,540 --> 00:39:58,580
了不同维度

893
00:39:58,670 --> 00:40:01,050
之间的

894
00:40:01,130 --> 00:40:02,960
相关性

895
00:40:03,060 --> 00:40:05,770
通过这种方法

896
00:40:05,830 --> 00:40:08,140
你无法

897
00:40:08,210 --> 00:40:10,020
捕获到任意

898
00:40:10,130 --> 00:40:12,690
一对纬度之间的关系

899
00:40:12,780 --> 00:40:13,800
什么问题?

900
00:40:13,880 --> 00:40:15,770
S:你能再说一下

901
00:40:15,910 --> 00:40:17,020
对角化矩阵的作用吗?

902
00:40:17,120 --> 00:40:17,840
I:再说一遍

903
00:40:17,930 --> 00:40:18,890
S:协方差矩阵是

904
00:40:18,990 --> 00:40:19,920
对角矩阵   这意味着什么?

905
00:40:20,000 --> 00:40:21,570
我不是很明白 你的例子

906
00:40:21,630 --> 00:40:22,670
I:我

907
00:40:22,740 --> 00:40:25,120
画的这些是

908
00:40:25,250 --> 00:40:26,420
高斯密度函数的

909
00:40:26,470 --> 00:40:29,110
额？所以让我们看看

910
00:40:29,190 --> 00:40:31,420
用斜线引出协方差

911
00:40:31,520 --> 00:40:33,570
然后你可以通过μ和Σ

912
00:40:33,650 --> 00:40:36,060
求出P(x;μ  Σ)

913
00:40:36,190 --> 00:40:39,050
对吗?

914
00:40:39,110 --> 00:40:40,910
如果Σ是对角矩阵

915
00:40:41,020 --> 00:40:43,290
那么高斯密度函数看起来

916
00:40:43,390 --> 00:40:44,880
会像是一块突起的形状

917
00:40:44,960 --> 00:40:47,050
我画的很烂

918
00:40:47,100 --> 00:40:49,950
在3D的情形下

919
00:40:50,000 --> 00:40:52,360
高斯密度函数看起来

920
00:40:52,480 --> 00:40:55,740
像是一块突起的形状

921
00:40:55,840 --> 00:40:57,740
--我画的真的很烂

922
00:40:57,810 --> 00:41:00,840
这里是x_1  x_2

923
00:41:00,980 --> 00:41:02,870
和P(x)的高

924
00:41:03,350 --> 00:41:05,400
这些图实际上

925
00:41:05,520 --> 00:41:08,470
是这个三维图形

926
00:41:09,420 --> 00:41:11,250
在二维平面上

927
00:41:11,340 --> 00:41:12,310
的轮廓投影

928
00:41:12,410 --> 00:41:13,850
S:我问的不是这些轮廓

929
00:41:13,900 --> 00:41:15,070
为什么会是这样的形状?

930
00:41:15,170 --> 00:41:15,930
对角矩阵

931
00:41:15,960 --> 00:41:17,930
和一般的协方差矩阵有什么区别?

932
00:41:17,970 --> 00:41:18,920
I:我明白了

933
00:41:19,020 --> 00:41:19,990
对不起

934
00:41:20,040 --> 00:41:23,220
这些轮廓和坐标轴平行意味着

935
00:41:23,320 --> 00:41:25,750
--我画的轮廓

936
00:41:25,830 --> 00:41:26,680
不是这样的

937
00:41:26,800 --> 00:41:29,760
因为这些轮廓的

938
00:41:29,830 --> 00:41:33,300
主轴和x_1  x_2是不平行的

939
00:41:33,350 --> 00:41:36,400
此时高斯分布的协方差矩阵的

940
00:41:36,480 --> 00:41:38,460
非对角线上有元素不为0

941
00:41:38,560 --> 00:41:39,920
明白吗?

942
00:41:39,990 --> 00:41:45,180
很好

943
00:41:45,250 --> 00:41:48,380
这样的做法是有效的

944
00:41:48,440 --> 00:41:49,140
事实证明

945
00:41:49,210 --> 00:41:50,480
这种方法对于给定的这两个

946
00:41:50,530 --> 00:41:52,470
训练样本

947
00:41:52,590 --> 00:41:54,110
是可以得到一个非奇异协方差矩阵的

948
00:41:54,240 --> 00:41:56,660
但是这样做会抛弃

949
00:41:56,720 --> 00:41:57,670
所有数据中的相关性质

950
00:41:57,750 --> 00:41:59,130
所以这并不是一个好模型

951
00:41:59,170 --> 00:42:07,320
实际上  你还可以

952
00:42:07,400 --> 00:42:08,760
我们

953
00:42:08,850 --> 00:42:09,550
稍后会

954
00:42:09,640 --> 00:42:10,390
再用到这个性质

955
00:42:10,470 --> 00:42:12,010
实际上  你可以进行

956
00:42:12,050 --> 00:42:12,660
更为严格的约束

957
00:42:12,730 --> 00:42:19,840
例如

958
00:42:19,930 --> 00:42:24,200
你可以令

959
00:42:24,270 --> 00:42:25,170
Σ=σ^2 I

960
00:42:25,240 --> 00:42:25,960
换句话说

961
00:42:26,040 --> 00:42:26,860
你可以将Σ限制

962
00:42:26,920 --> 00:42:27,810
为所有对角线元素

963
00:42:27,910 --> 00:42:33,310
都相同的

964
00:42:33,360 --> 00:42:35,580
对角矩阵

965
00:42:35,640 --> 00:42:38,200
也就是说你限制了

966
00:42:38,270 --> 00:42:40,880
高斯密度函数的轮廓

967
00:42:41,030 --> 00:42:42,180
必须是圆形的

968
00:42:42,240 --> 00:42:43,160
明白吗?

969
00:42:43,230 --> 00:42:44,860
这是一个

970
00:42:44,940 --> 00:42:45,770
更为严格的约束

971
00:42:45,840 --> 00:42:53,090
这些约束  不仅是将Σ约束为

972
00:42:53,180 --> 00:42:55,960
一般的对角化矩阵

973
00:42:55,990 --> 00:42:56,730
还是将其约束为常值对角化矩阵

974
00:42:56,780 --> 00:42:59,280
它们都是很强的假设

975
00:42:59,360 --> 00:43:01,270
如果你有足够的数据的话

976
00:43:01,340 --> 00:43:03,130
你也许希望

977
00:43:03,200 --> 00:43:04,700
你的模型能够体现出一些

978
00:43:04,750 --> 00:43:05,540
变量之间的关联性

979
00:43:05,590 --> 00:43:08,990
因子分析模型

980
00:43:09,050 --> 00:43:12,340
要做的就是这个事情

981
00:43:12,400 --> 00:43:14,770
它是这样做的

982
00:43:14,860 --> 00:43:37,380
因子分析模型

983
00:43:37,510 --> 00:43:39,700
是这样对数据进行建模的

984
00:43:39,760 --> 00:43:42,470
我们需要假设

985
00:43:42,530 --> 00:43:44,940
存在一个隐含的随机变量

986
00:43:45,060 --> 00:43:45,910
对吗?

987
00:43:46,000 --> 00:43:47,610
我们将这个变量设为z

988
00:43:47,680 --> 00:43:51,900
z应该服从高斯分布

989
00:43:51,970 --> 00:43:53,880
均值为0

990
00:43:53,970 --> 00:43:58,090
协方差矩阵是单位矩阵

991
00:43:58,150 --> 00:43:59,060
z是一个d维向量

992
00:43:59,130 --> 00:44:04,370
我们需要选择d

993
00:44:04,440 --> 00:44:06,740
使其小于数据

994
00:44:06,800 --> 00:44:08,300
x的维度

995
00:44:08,370 --> 00:44:09,050
明白吗?

996
00:44:09,130 --> 00:44:14,060
现在我假设

997
00:44:14,170 --> 00:44:15,590
x--

998
00:44:15,680 --> 00:44:20,250
让我这样写

999
00:44:20,330 --> 00:44:25,750
每个x^((i) )都--

1000
00:44:25,820 --> 00:44:27,080
对不起

1001
00:44:27,170 --> 00:44:34,850
我们要假设

1002
00:44:34,900 --> 00:44:38,850
x|z服从

1003
00:44:38,860 --> 00:44:41,450
另外一个高斯分布

1004
00:44:41,500 --> 00:44:47,350
均值是μ+Λz

1005
00:44:47,410 --> 00:44:52,560
协方差矩阵是Ψ

1006
00:44:52,630 --> 00:44:55,520
我们可以将这一行定义成

1007
00:44:55,600 --> 00:44:57,820
一个等价形式

1008
00:44:57,900 --> 00:45:02,550
我会将x建模成:

1009
00:45:02,620 --> 00:45:07,130
μ+Λz+ε

1010
00:45:07,200 --> 00:45:10,070
ε是一个噪声项

1011
00:45:10,190 --> 00:45:15,040
服从均值为0

1012
00:45:15,130 --> 00:45:23,310
协方差为Ψ的高斯分布

1013
00:45:23,380 --> 00:45:26,110
这个模型的参数

1014
00:45:26,200 --> 00:45:31,600
包括

1015
00:45:31,670 --> 00:45:35,510
n维向量μ

1016
00:45:35,590 --> 00:45:39,040
n*d的矩阵Λ

1017
00:45:39,120 --> 00:45:44,260
以及一个

1018
00:45:44,340 --> 00:45:47,750
n*n的协方差矩阵Ψ

1019
00:45:47,840 --> 00:45:56,850
我要

1020
00:45:56,890 --> 00:45:57,450
添加

1021
00:45:57,510 --> 00:45:59,910
一个约束:

1022
00:46:00,000 --> 00:46:01,790
Ψ是对角矩阵 明白吗?

1023
00:46:01,890 --> 00:46:06,210
我要举一些例子

1024
00:46:06,300 --> 00:46:08,550
使这个定义看起来

1025
00:46:08,630 --> 00:46:09,350
更为具体

1026
00:46:09,420 --> 00:46:10,820
让我们看一个

1027
00:46:10,880 --> 00:46:12,610
具体的例子

1028
00:46:12,690 --> 00:46:34,820
假设z是一维向量

1029
00:46:34,870 --> 00:46:39,790
x是二维向量

1030
00:46:39,860 --> 00:46:42,030
让我们看看模型是怎样的

1031
00:46:42,110 --> 00:46:50,450
这是

1032
00:46:50,480 --> 00:46:51,220
因子分析模型

1033
00:46:51,310 --> 00:46:52,050
的一个实例

1034
00:46:52,140 --> 00:46:53,770
让我们看看

1035
00:46:53,840 --> 00:46:55,220
我们是怎样对

1036
00:46:55,290 --> 00:46:56,380
P(x)进行建模的

1037
00:46:56,470 --> 00:47:01,450
让我看看

1038
00:47:01,520 --> 00:47:03,660
对于这个模型

1039
00:47:03,780 --> 00:47:05,650
让我们假设

1040
00:47:05,720 --> 00:47:13,870
Λ=[■(2@1)]

1041
00:47:13,920 --> 00:47:14,760
而Ψ是一个对角矩阵

1042
00:47:14,820 --> 00:47:15,980
等于这个

1043
00:47:16,080 --> 00:47:18,100
z是一个一维随机变量

1044
00:47:18,190 --> 00:47:24,060
我们画出一些

1045
00:47:24,140 --> 00:47:25,650
z的样本

1046
00:47:25,780 --> 00:47:34,730
如果z^((i) )服从高斯分布的话

1047
00:47:34,840 --> 00:47:37,570
那么对z进行

1048
00:47:37,760 --> 00:47:39,050
一系列随机取样后

1049
00:47:39,110 --> 00:47:41,130
可能得到这样的结果

1050
00:47:41,190 --> 00:47:42,130
这里我将它们标记成

1051
00:47:42,200 --> 00:47:46,200
z^((1) )  z^((2) )  z^((3) )

1052
00:47:46,280 --> 00:47:46,920
依此类推

1053
00:47:47,010 --> 00:47:48,830
如果这些样本是

1054
00:47:48,920 --> 00:47:50,390
对z的随机取样的话

1055
00:47:50,480 --> 00:47:51,410
那么中间的样本数会比较多

1056
00:47:51,490 --> 00:47:52,920
我将这些样本标上号

1057
00:47:53,010 --> 00:47:55,620
方便之后的讨论

1058
00:47:55,720 --> 00:47:57,080
这些样本来自于对z的随机取样

1059
00:47:57,200 --> 00:47:58,790
z服从均值为0

1060
00:47:58,850 --> 00:48:00,470
方差为1的

1061
00:48:00,540 --> 00:48:01,150
高斯分布

1062
00:48:01,240 --> 00:48:09,650
这个例子中

1063
00:48:09,710 --> 00:48:11,160
让我们假设μ=0

1064
00:48:11,260 --> 00:48:14,150
这样

1065
00:48:14,170 --> 00:48:15,130
比较方便讨论

1066
00:48:15,180 --> 00:48:22,710
让我们看看Λz

1067
00:48:22,770 --> 00:48:23,920
对于每一个数字

1068
00:48:23,950 --> 00:48:25,150
我们都乘上Λ

1069
00:48:25,220 --> 00:48:32,040
你会发现所有这些Λz

1070
00:48:32,090 --> 00:48:37,510
都会在

1071
00:48:37,560 --> 00:48:39,090
一条直线上

1072
00:48:39,160 --> 00:48:40,280
例如

1073
00:48:40,420 --> 00:48:43,080
这个点  一二三

1074
00:48:43,150 --> 00:48:44,420
四五六七

1075
00:48:44,480 --> 00:48:46,890
应该是z^((7) )

1076
00:48:47,020 --> 00:48:49,690
这个点应该是Λz^((7) )

1077
00:48:49,790 --> 00:48:54,090
它是一个二维向量

1078
00:48:54,190 --> 00:48:55,470
因为Λ是一个2*1的矩阵

1079
00:48:55,560 --> 00:48:58,270
我这里

1080
00:48:58,330 --> 00:48:59,170
画的是

1081
00:48:59,200 --> 00:49:00,820
对Λz进行随机取样

1082
00:49:00,910 --> 00:49:09,130
的结果

1083
00:49:09,200 --> 00:49:09,960
最后我们来看看对x随机取样的结果

1084
00:49:10,060 --> 00:49:14,350
x=μ+Λz+ε

1085
00:49:14,440 --> 00:49:16,810
ε服从均值为μ

1086
00:49:16,860 --> 00:49:21,490
协方差为Ψ的高斯分布

1087
00:49:21,580 --> 00:49:23,710
对吗?

1088
00:49:23,810 --> 00:49:25,470
最后我们

1089
00:49:25,600 --> 00:49:26,610
希望对

1090
00:49:26,680 --> 00:49:27,840
随机变量x进行取样

1091
00:49:27,950 --> 00:49:30,480
这些

1092
00:49:30,590 --> 00:49:32,620
点

1093
00:49:32,670 --> 00:49:33,810
就是μ+Λz  因为μ=0

1094
00:49:33,850 --> 00:49:35,190
在每个点周围

1095
00:49:35,290 --> 00:49:39,300
我都要画一

1096
00:49:39,390 --> 00:49:43,520
个和坐标轴平行的椭圆形区域

1097
00:49:43,620 --> 00:49:44,790
换句话说

1098
00:49:44,890 --> 00:49:46,140
我希望以

1099
00:49:46,220 --> 00:49:48,370
每个点为中心

1100
00:49:48,490 --> 00:49:51,500
创建一个高斯分布

1101
00:49:51,590 --> 00:49:53,510
我画的椭圆

1102
00:49:53,580 --> 00:49:55,120
对应着ε的

1103
00:49:55,200 --> 00:49:57,240
密度函数的轮廓

1104
00:49:57,330 --> 00:49:58,170
明白吗?

1105
00:49:58,240 --> 00:50:00,730
你可以想象

1106
00:50:00,790 --> 00:50:02,060
这里存在着一个高斯分布的曲面

1107
00:50:02,130 --> 00:50:06,310
对于这些小的高斯分布

1108
00:50:06,420 --> 00:50:07,620
我会画出一些样本

1109
00:50:07,760 --> 00:50:09,500
比如说这里

1110
00:50:09,580 --> 00:50:27,780
这里我也画一些

1111
00:50:27,870 --> 00:50:29,830
从这些高斯分布中

1112
00:50:29,940 --> 00:50:31,940
我们获得了一些样本

1113
00:50:32,030 --> 00:50:33,240
我画的

1114
00:50:33,350 --> 00:50:34,230
这些橙色的点

1115
00:50:34,320 --> 00:50:35,170
构成了

1116
00:50:35,250 --> 00:50:36,450
这个模型下对x的

1117
00:50:36,550 --> 00:50:37,320
一个典型的取样

1118
00:50:37,440 --> 00:50:45,380
什么问题?

1119
00:50:45,450 --> 00:50:46,470
S:你考虑均值了吗?

1120
00:50:46,540 --> 00:50:47,930
I:再说一遍

1121
00:50:47,990 --> 00:50:48,680
S:你这里需要加入均值吗?

1122
00:50:48,770 --> 00:50:49,880
I:是的

1123
00:50:49,970 --> 00:50:50,560
这个例子中

1124
00:50:50,640 --> 00:50:51,170
我们令μ=0

1125
00:50:51,240 --> 00:50:51,940
这样比较方便讨论

1126
00:50:52,010 --> 00:50:52,530
如果μ不为0的话

1127
00:50:52,600 --> 00:50:53,170
我们需要将整张图

1128
00:50:53,240 --> 00:50:53,860
按照μ

1129
00:50:53,940 --> 00:50:54,960
进行平移 什么问题?

1130
00:50:58,100 --> 00:50:59,790
那条水平的线的x

1131
00:50:59,900 --> 00:51:02,000
轴对应z

1132
00:51:02,100 --> 00:51:06,030
y轴

1133
00:51:06,090 --> 00:51:06,880
对应什么?

1134
00:51:08,160 --> 00:51:08,760
z是一维的

1135
00:51:08,820 --> 00:51:12,060
所以我这里画的是

1136
00:51:12,130 --> 00:51:15,010
对z的一个典型的采样

1137
00:51:15,100 --> 00:51:17,020
这里是0

1138
00:51:17,110 --> 00:51:18,540
这是z轴

1139
00:51:18,650 --> 00:51:20,460
z是一维数据

1140
00:51:20,570 --> 00:51:22,160
所以这里的点表示

1141
00:51:22,250 --> 00:51:25,860
对z 的典型的采样

1142
00:51:25,910 --> 00:51:26,870
什么问题?

1143
00:51:27,030 --> 00:51:32,250
S:这个坐标轴上的点

1144
00:51:32,340 --> 00:51:34,240
是取样的结果吗?

1145
00:51:34,270 --> 00:51:35,410
I:是的

1146
00:51:35,470 --> 00:51:38,260
S:是通过某种投影

1147
00:51:38,370 --> 00:51:39,450
将它变成二维点的吗?

1148
00:51:39,500 --> 00:51:40,480
I:我们暂时

1149
00:51:40,550 --> 00:51:41,140
不讨论投影

1150
00:51:41,240 --> 00:51:41,910
这些

1151
00:51:41,960 --> 00:51:43,210
点

1152
00:51:43,250 --> 00:51:44,480
这里的x^((1) )  x^((2) )

1153
00:51:44,560 --> 00:51:47,690
我看的

1154
00:51:47,760 --> 00:51:48,680
只有这些点

1155
00:51:48,740 --> 00:51:53,110
实际上你直接

1156
00:51:53,180 --> 00:51:54,310
看到的只有这些x

1157
00:51:54,380 --> 00:51:57,040
但是正像我

1158
00:51:57,100 --> 00:51:58,630
在混合高斯模型中

1159
00:51:58,740 --> 00:52:00,700
设计的情节一样

1160
00:52:00,770 --> 00:52:03,920
我想象这些数据来自于

1161
00:52:04,000 --> 00:52:05,610
两个高斯分布

1162
00:52:05,680 --> 00:52:06,450
通过一个隐含的随机变量z

1163
00:52:06,520 --> 00:52:07,070
由两个高斯分布生成

1164
00:52:07,140 --> 00:52:09,430
这里我同样设计了

1165
00:52:09,520 --> 00:52:10,150
一个情节

1166
00:52:10,230 --> 00:52:10,740
实际上所有的算法

1167
00:52:10,820 --> 00:52:11,850
只能看到这些橙色的点

1168
00:52:11,960 --> 00:52:12,680
但是我们设计了这些点

1169
00:52:12,800 --> 00:52:17,650
生成的详细情节

1170
00:52:17,780 --> 00:52:19,840
这构成了我们的

1171
00:52:19,950 --> 00:52:20,910
因子分析模型

1172
00:52:21,030 --> 00:52:25,710
一种对于该模型的非正式的

1173
00:52:25,780 --> 00:52:26,650
直观理解是

1174
00:52:26,730 --> 00:52:27,510
我们认为

1175
00:52:27,620 --> 00:52:31,220
这些数据

1176
00:52:31,300 --> 00:52:32,270
实际上是从

1177
00:52:32,400 --> 00:52:33,750
某些低维空间中生成的

1178
00:52:33,850 --> 00:52:35,210
所以我们认为

1179
00:52:35,340 --> 00:52:36,610
这里的x实际上

1180
00:52:36,770 --> 00:52:39,540
是由一维的直线空间

1181
00:52:39,680 --> 00:52:41,240
生成的

1182
00:52:41,330 --> 00:52:44,520
但是

1183
00:52:44,640 --> 00:52:46,160
在生成之后

1184
00:52:46,280 --> 00:52:48,790
要加上一点

1185
00:52:48,880 --> 00:52:51,260
随机噪声

1186
00:52:51,350 --> 00:52:52,350
所以我们得到了

1187
00:52:52,440 --> 00:52:53,190
二维的点

1188
00:52:53,330 --> 00:52:54,760
这是一种对因子分析的

1189
00:52:54,850 --> 00:52:55,810
非正式理解

1190
00:52:59,480 --> 00:53:10,280
我们时间控制的不是很好

1191
00:53:10,380 --> 00:53:18,690
让我

1192
00:53:18,770 --> 00:53:22,030
再举一个例子

1193
00:53:22,090 --> 00:53:22,970
这个例子中

1194
00:53:23,060 --> 00:53:26,430
我们

1195
00:53:26,490 --> 00:53:29,710
假设z是2维向量

1196
00:53:29,780 --> 00:53:30,820
x是3维向量

1197
00:53:30,900 --> 00:53:41,910
所以数据z

1198
00:53:41,980 --> 00:53:44,180
来自于2维平面

1199
00:53:44,280 --> 00:53:46,690
让我将它画在

1200
00:53:46,780 --> 00:53:47,590
这张纸上

1201
00:53:47,710 --> 00:53:51,880
假设这张纸的两个坐标轴

1202
00:53:51,920 --> 00:53:52,970
是z^((1) ) 和z^((2) )

1203
00:53:53,030 --> 00:53:57,440
所以这是一个典型的

1204
00:53:57,510 --> 00:53:58,980
取样

1205
00:53:59,100 --> 00:54:00,530
对吗?

1206
00:54:00,600 --> 00:54:04,730
之后我们将取样的结果

1207
00:54:04,840 --> 00:54:07,290
--也画在

1208
00:54:07,390 --> 00:54:12,200
这里

1209
00:54:12,260 --> 00:54:13,470
这是对变量z的一个

1210
00:54:13,540 --> 00:54:14,910
典型的取样

1211
00:54:15,020 --> 00:54:16,470
我想原点应该在这里

1212
00:54:16,510 --> 00:54:17,840
这些点以0为中心

1213
00:54:17,900 --> 00:54:21,720
之后我们会将这些点

1214
00:54:21,780 --> 00:54:25,410
利用μ+Λz进行映射

1215
00:54:25,490 --> 00:54:27,140
想象一下

1216
00:54:27,220 --> 00:54:28,500
我们的整个教室

1217
00:54:28,540 --> 00:54:29,830
就是一个三维空间

1218
00:54:29,910 --> 00:54:31,510
它的意思是

1219
00:54:31,560 --> 00:54:33,140
我们会用这个Z的例子

1220
00:54:33,210 --> 00:54:34,610
然后我们将把它映射到

1221
00:54:34,700 --> 00:54:37,270
空闲的位置

1222
00:54:37,370 --> 00:54:38,490
所以我们将用这张纸

1223
00:54:38,620 --> 00:54:39,360
把它移动到某个地方

1224
00:54:39,470 --> 00:54:40,130
3维空间的一些定位

1225
00:54:40,200 --> 00:54:43,010
最后一步是

1226
00:54:43,100 --> 00:54:47,180
由于x=μ+Λz+ε

1227
00:54:47,290 --> 00:54:50,220
所以你需要给

1228
00:54:50,290 --> 00:54:51,430
这些平面上的点

1229
00:54:51,520 --> 00:54:53,530
添加一些

1230
00:54:53,630 --> 00:54:55,170
噪声扰动

1231
00:54:55,260 --> 00:54:57,460
这些扰动对应着一些3维区域

1232
00:54:57,510 --> 00:54:59,060
每一个区域都来自于高斯分

1233
00:54:59,160 --> 00:55:01,020
而且和坐标轴平行

1234
00:55:01,080 --> 00:55:02,480
所以你会

1235
00:55:02,560 --> 00:55:03,910
得到一个看起来像

1236
00:55:04,010 --> 00:55:06,360
馅饼一样的区域

1237
00:55:06,440 --> 00:55:07,170
但是边缘比较模糊和不规则

1238
00:55:07,250 --> 00:55:08,310
这个例子的模型是这样的

1239
00:55:08,480 --> 00:55:16,130
我们稍后会来讨论

1240
00:55:16,200 --> 00:55:18,000
怎样拟合模型中的参数

1241
00:55:18,080 --> 00:55:31,990
为了描述模型的拟合方法

1242
00:55:32,040 --> 00:55:32,960
我们需要

1243
00:55:33,010 --> 00:55:36,420
将高斯分布

1244
00:55:36,460 --> 00:55:37,540
重新写成

1245
00:55:37,580 --> 00:55:38,710
一种不同的形式

1246
00:55:38,780 --> 00:55:41,360
具体地  比如说

1247
00:55:41,410 --> 00:55:43,670
对于向量x

1248
00:55:43,730 --> 00:55:46,750
我用这种方式

1249
00:55:46,840 --> 00:55:48,280
表示分块向量

1250
00:55:48,340 --> 00:55:54,090
如果x_1

1251
00:55:54,170 --> 00:55:55,530
是r维向量

1252
00:55:55,570 --> 00:55:59,780
x_2是s维向量

1253
00:55:59,880 --> 00:56:04,700
那么x就是一个r+s维的向量

1254
00:56:04,840 --> 00:56:07,020
我用

1255
00:56:07,130 --> 00:56:11,550
这种方式表示

1256
00:56:11,640 --> 00:56:12,400
讲一个向量

1257
00:56:12,470 --> 00:56:13,140
分成两部分

1258
00:56:13,230 --> 00:56:14,750
前一部分有r个元素

1259
00:56:14,820 --> 00:56:17,750
后一部分有s个元素

1260
00:56:17,840 --> 00:56:26,940
比如说x

1261
00:56:27,020 --> 00:56:30,330
服从均值为μ

1262
00:56:30,370 --> 00:56:31,320
协方差为Σ的高斯分布

1263
00:56:31,390 --> 00:56:32,320
μ本身是

1264
00:56:32,410 --> 00:56:40,400
一个分块向量

1265
00:56:40,460 --> 00:56:43,170
所以我们将其写作两个部分μ_1

1266
00:56:43,230 --> 00:56:43,860
和μ_2

1267
00:56:43,930 --> 00:56:48,100
而协方差矩阵Σ

1268
00:56:48,190 --> 00:56:50,750
是一个分块矩阵

1269
00:56:50,870 --> 00:56:56,470
这意味着

1270
00:56:56,550 --> 00:56:57,910
我会将协方差矩阵Σ

1271
00:56:58,000 --> 00:56:59,570
分成

1272
00:56:59,640 --> 00:57:00,500
四个部分

1273
00:57:00,560 --> 00:57:03,900
这里

1274
00:57:04,010 --> 00:57:05,130
有r个元素

1275
00:57:05,230 --> 00:57:07,250
这里

1276
00:57:07,380 --> 00:57:09,160
有s个元素

1277
00:57:09,240 --> 00:57:12,540
例如

1278
00:57:12,650 --> 00:57:16,190
Σ_12是一个

1279
00:57:16,270 --> 00:57:17,270
r*s的矩阵

1280
00:57:17,350 --> 00:57:20,720
高度为r

1281
00:57:20,780 --> 00:57:21,850
宽度为s

1282
00:57:21,970 --> 00:57:33,710
这个高斯分布实际上是

1283
00:57:33,760 --> 00:57:35,320
很多变量

1284
00:57:35,380 --> 00:57:36,570
的联合概率分布

1285
00:57:36,630 --> 00:57:37,880
对吗?

1286
00:57:37,980 --> 00:57:38,740
如果x是一个向量

1287
00:57:38,820 --> 00:57:40,830
那么x的概率分布

1288
00:57:40,920 --> 00:57:42,510
实际上应该是x_1

1289
00:57:42,610 --> 00:57:44,830
到x_n或者x_(r+s)的联合概率分布

1290
00:57:44,900 --> 00:57:49,090
所以我们可能想知道

1291
00:57:49,190 --> 00:57:50,360
这个高斯分布的边际分布

1292
00:57:50,440 --> 00:57:51,310
和条件分布

1293
00:57:51,380 --> 00:57:53,210
例如

1294
00:57:53,310 --> 00:57:54,670
对于高斯分布

1295
00:57:54,770 --> 00:57:55,740
我知道P(x)

1296
00:57:55,810 --> 00:57:58,300
那么我该如何计算

1297
00:57:58,380 --> 00:58:00,770
得到边际分布P(x_1)?

1298
00:58:00,860 --> 00:58:02,340
它应该等于

1299
00:58:02,420 --> 00:58:04,290
这个

1300
00:58:04,410 --> 00:58:09,610
式子

1301
00:58:09,700 --> 00:58:11,920
如果你进行了

1302
00:58:12,000 --> 00:58:13,330
这个计算

1303
00:58:13,380 --> 00:58:14,670
你会得到

1304
00:58:14,770 --> 00:58:16,040
这个结果:

1305
00:58:16,090 --> 00:58:21,940
x_1服从均值为μ_1

1306
00:58:21,990 --> 00:58:24,760
协方差矩阵为Σ_11的高斯分布

1307
00:58:24,830 --> 00:58:26,120
这个结果并不是很出人意料

1308
00:58:26,190 --> 00:58:30,030
高斯分布的边际分布

1309
00:58:30,120 --> 00:58:31,770
也是高斯分布

1310
00:58:31,830 --> 00:58:32,690
参数为协方差矩阵中

1311
00:58:32,760 --> 00:58:37,050
对应的子矩阵

1312
00:58:37,150 --> 00:58:38,380
和向量μ中

1313
00:58:38,470 --> 00:58:39,910
对应的

1314
00:58:40,000 --> 00:58:43,240
子向量

1315
00:58:43,330 --> 00:58:48,230
你还可以计算条件概率

1316
00:58:48,330 --> 00:58:50,570
你可能想知道P(x_1 |x_2)

1317
00:58:50,680 --> 00:58:56,580
对吗?

1318
00:58:56,700 --> 00:58:58,790
可以用

1319
00:58:58,870 --> 00:59:01,090
这个公式

1320
00:59:01,210 --> 00:59:07,640
计算

1321
00:59:07,750 --> 00:59:10,510
每个公式

1322
00:59:10,600 --> 00:59:11,890
你都知道

1323
00:59:11,960 --> 00:59:12,620
对吗?

1324
00:59:12,690 --> 00:59:14,190
分子就是

1325
00:59:14,280 --> 00:59:15,080
一般的高斯分布

1326
00:59:15,180 --> 00:59:18,560
x_1 和x_2的联合分布

1327
00:59:18,640 --> 00:59:21,360
就是以μ为均值

1328
00:59:21,460 --> 00:59:23,300
以Σ为协方差的高斯分布

1329
00:59:23,390 --> 00:59:27,860
这里的边际分布

1330
00:59:27,930 --> 00:59:34,490
我刚才已经求出来了

1331
00:59:34,610 --> 00:59:37,040
之后你需要将

1332
00:59:37,130 --> 00:59:37,690
这两个高斯密度函数代入

1333
00:59:37,780 --> 00:59:38,370
并且进行简化

1334
00:59:38,490 --> 00:59:39,210
简化过程并

1335
00:59:39,260 --> 00:59:40,070
不是非常简单

1336
00:59:40,130 --> 00:59:41,240
如果你之前没有见过

1337
00:59:41,300 --> 00:59:42,260
那么看起来


1338
00:59:42,360 --> 00:59:42,860
可能会

1339
00:59:42,930 --> 00:59:43,650
有些吃力

1340
00:59:43,720 --> 00:59:47,030
如果你将这些公式

1341
00:59:47,070 --> 00:59:47,880
代入

1342
00:59:47,950 --> 00:59:50,270
并且进行简化的话

1343
00:59:50,350 --> 00:59:53,380
你会发现

1344
00:59:53,490 --> 00:59:54,590
x_1 |x_2

1345
00:59:54,710 --> 00:59:59,420
服从均值为μ_(1|2)

1346
00:59:59,470 --> 01:00:02,590
协方差为

1347
01:00:02,700 --> 01:00:09,280
Σ_(1|2)

1348
01:00:09,370 --> 01:00:10,800
的高斯分布

1349
01:00:10,890 --> 01:00:16,270
μ_(1|2)

1350
01:00:16,370 --> 01:00:17,440
是

1351
01:00:17,520 --> 01:00:19,040
这样定义的

1352
01:00:19,120 --> 01:00:21,390
Σ_(1|2)

1353
01:00:21,470 --> 01:00:23,010
是

1354
01:00:23,090 --> 01:00:45,150
这样定义的

1355
01:00:45,240 --> 01:00:46,780
明白吗?

1356
01:00:46,870 --> 01:00:49,590
这些公式

1357
01:00:49,670 --> 01:00:53,490
对于

1358
01:00:53,540 --> 01:00:55,550
计算高斯分布

1359
01:00:55,650 --> 01:00:56,750
的条件分布

1360
01:00:56,820 --> 01:00:57,670
和边际分布

1361
01:00:57,730 --> 01:00:58,770
是非常有用的

1362
01:00:58,820 --> 01:00:59,830
推导过程

1363
01:00:59,900 --> 01:01:00,580
我这里就不讲了

1364
01:01:00,670 --> 01:01:13,640
S:你能再

1365
01:01:13,720 --> 01:01:14,260
重复一遍吗?

1366
01:01:14,300 --> 01:01:14,980
I:当然

1367
01:01:15,050 --> 01:01:15,880
μ_(1|2)

1368
01:01:15,940 --> 01:01:16,770
=μ_1+Σ_12

1369
01:01:16,830 --> 01:01:19,790
Σ_22^(-1) (x_2-μ_2)

1370
01:01:19,880 --> 01:01:22,870
Σ_(1|2)=

1371
01:01:22,980 --> 01:01:24,920
Σ_11-Σ_12

1372
01:01:25,020 --> 01:01:26,860
Σ_22^(-1)

1373
01:01:26,960 --> 01:01:34,510
Σ_21

1374
01:01:34,590 --> 01:01:36,600
这些在讲义里有

1375
01:01:36,660 --> 01:01:52,580
我想

1376
01:01:52,710 --> 01:01:55,230
可能时间

1377
01:01:55,350 --> 01:02:01,430
不够了

1378
01:02:01,490 --> 01:02:21,900
为了节省时间

1379
01:02:22,010 --> 01:02:23,050
我可能要跳过这里

1380
01:02:23,110 --> 01:02:24,130
让我们将这些公式

1381
01:02:24,220 --> 01:02:28,350
应用到因子

1382
01:02:28,420 --> 01:02:30,330
分析模型中

1383
01:02:30,400 --> 01:02:32,680
实际上

1384
01:02:32,770 --> 01:02:39,340
--我需要讲吗?

1385
01:02:39,450 --> 01:02:47,340
可能需要

1386
01:02:47,450 --> 01:02:50,070
让我们先看看

1387
01:02:50,150 --> 01:02:53,210
因子分析模型

1388
01:02:53,290 --> 01:02:55,920
假设的

1389
01:02:56,070 --> 01:02:57,420
z和x的联合分布

1390
01:02:57,490 --> 01:03:01,760
在因子分析模型中

1391
01:03:01,870 --> 01:03:04,980
随机变量z和x的

1392
01:03:05,030 --> 01:03:08,860
联合分布应该

1393
01:03:08,890 --> 01:03:10,980
等于--我这里

1394
01:03:11,040 --> 01:03:13,290
写作μ_zx

1395
01:03:13,380 --> 01:03:15,440
协方差矩阵是Σ

1396
01:03:15,580 --> 01:03:18,550
我们来看看

1397
01:03:18,650 --> 01:03:20,420
μ_zx和Σ都是什么

1398
01:03:20,490 --> 01:03:21,660
我们

1399
01:03:21,770 --> 01:03:23,910
会用到

1400
01:03:24,000 --> 01:03:25,680
分块向量

1401
01:03:25,750 --> 01:03:26,870
和分块矩阵

1402
01:03:26,930 --> 01:03:30,120
提醒一下

1403
01:03:30,190 --> 01:03:32,570
z~N(0  I)

1404
01:03:32,650 --> 01:03:33,340
x=μ+Λz+ε

1405
01:03:33,400 --> 01:03:35,590
ε~N(0  Ψ)

1406
01:03:35,680 --> 01:03:37,540
z~N(0  I)

1407
01:03:37,620 --> 01:03:41,240
x=μ+Λz+ε

1408
01:03:41,330 --> 01:03:43,110
ε~N(0  Ψ)

1409
01:03:43,170 --> 01:03:44,440
我再把

1410
01:03:44,560 --> 01:03:45,690
这些公式

1411
01:03:45,800 --> 01:03:47,330
写一遍

1412
01:03:47,400 --> 01:03:48,250
让我们看看

1413
01:03:48,320 --> 01:03:49,920
μ_zx是什么

1414
01:03:49,990 --> 01:03:55,050
Ez=0应该等于

1415
01:03:55,150 --> 01:03:58,290
我这里

1416
01:03:58,350 --> 01:04:00,630
再一次省略了

1417
01:04:00,690 --> 01:04:06,630
方括号

1418
01:04:06,820 --> 01:04:07,350
Ex

1419
01:04:07,440 --> 01:04:08,290
=E[x=μ+Λz+ε]

1420
01:04:08,400 --> 01:04:10,130
Ex=E[x=μ+Λz+ε]

1421
01:04:10,210 --> 01:04:15,800
这两项的期望值

1422
01:04:15,880 --> 01:04:16,830
都是0

1423
01:04:16,910 --> 01:04:18,700
所以Ex=μ

1424
01:04:18,760 --> 01:04:26,720
模型中的

1425
01:04:26,830 --> 01:04:29,110
参数向量

1426
01:04:29,190 --> 01:04:31,800
μ_zx=E[■(z@x)]=[■(0 ?@μ)]

1427
01:04:31,930 --> 01:04:34,280
μ_zx=E[■(z@x)]=[■(0 ?@μ)]

1428
01:04:34,420 --> 01:04:35,640
μ_zx=E[■(z@x)]=[■(0 ?@μ)]

1429
01:04:35,750 --> 01:04:38,740
μ_zx=E[■(z@x)]=[■(0 ?@μ)]

1430
01:04:38,900 --> 01:04:43,170
μ_zx=E[■(z@x)]=[■(0 ?@μ)]

1431
01:04:43,270 --> 01:04:46,340
μ_zx=E[■(z@x)]=[■(0 ?@μ)]

1432
01:04:46,560 --> 01:04:47,830
所以这里是一个d维的0向量

1433
01:04:47,920 --> 01:04:53,530
和一个n维的向量μ

1434
01:04:53,630 --> 01:04:58,160
我们还没有求出

1435
01:04:58,230 --> 01:04:59,590
协方差矩阵Σ

1436
01:04:59,680 --> 01:05:22,620
根据

1437
01:05:22,730 --> 01:05:28,030
分块矩阵

1438
01:05:28,130 --> 01:05:28,940
的定义

1439
01:05:29,020 --> 01:05:49,180
--这写

1440
01:05:49,200 --> 01:06:06,920
都是矩阵块

1441
01:06:07,000 --> 01:06:08,000
协方差矩阵

1442
01:06:08,050 --> 01:06:08,910
包含四个矩阵块

1443
01:06:08,980 --> 01:06:12,040
所以左上角的矩阵块

1444
01:06:12,140 --> 01:06:13,430
也就是Σ_11

1445
01:06:13,520 --> 01:06:16,140
等于z的

1446
01:06:16,220 --> 01:06:19,910
协方差矩阵

1447
01:06:19,970 --> 01:06:22,510
也就是I

1448
01:06:22,530 --> 01:06:25,690
我会简单地

1449
01:06:25,790 --> 01:06:27,060
介绍其他块的推导过程

1450
01:06:27,110 --> 01:06:28,790
Σ_12--

1451
01:06:28,890 --> 01:06:43,450
对不起

1452
01:06:43,450 --> 01:06:44,670
Σ_21

1453
01:06:44,760 --> 01:06:46,370
也就是左下角的矩阵块

1454
01:06:46,430 --> 01:06:51,330
应该等于

1455
01:06:51,410 --> 01:06:53,280
E(x-Ex) (z-Ez)^T

1456
01:06:53,350 --> 01:06:59,900
应该等于

1457
01:07:00,000 --> 01:07:04,600
E[(μ+Λz+ε-μ)z]

1458
01:07:04,690 --> 01:07:08,250
因为

1459
01:07:08,350 --> 01:07:12,850
Ez=0

1460
01:07:12,950 --> 01:07:15,420
所以这一项等于0

1461
01:07:15,500 --> 01:07:20,980
进行化简

1462
01:07:21,100 --> 01:07:22,720
正负μ抵消

1463
01:07:22,800 --> 01:07:24,960
所以

1464
01:07:25,070 --> 01:07:29,170
应该等于

1465
01:07:29,280 --> 01:07:33,770
--对不起

1466
01:07:33,890 --> 01:07:40,630
应该等于

1467
01:07:40,750 --> 01:07:53,580
E[Λzz^T ]-E[εz]

1468
01:07:53,680 --> 01:08:00,830
所以应该等于这个式子

1469
01:08:00,930 --> 01:08:03,670
所以等于Λ乘以单位矩阵

1470
01:08:03,770 --> 01:08:10,040
明白了吗?

1471
01:08:10,130 --> 01:08:14,140
这一项等于0

1472
01:08:14,210 --> 01:08:16,180
因为这两个变量都是独立的

1473
01:08:16,310 --> 01:08:17,400
而且期望值为0

1474
01:08:17,510 --> 01:08:18,490
而且期望值为0

1475
01:08:18,600 --> 01:08:50,270
最后一块Σ_22

1476
01:08:50,350 --> 01:08:52,530
应该

1477
01:08:52,640 --> 01:08:55,200
等于

1478
01:08:55,320 --> 01:08:59,910
这个式子

1479
01:08:59,990 --> 01:09:10,260
简化过程我就省略了

1480
01:09:10,330 --> 01:09:11,670
最后结果应该

1481
01:09:11,750 --> 01:09:15,100
是这个式子

1482
01:09:15,200 --> 01:09:22,350
将所有这些合到一起

1483
01:09:22,430 --> 01:09:23,700
[■(z@x)]服从

1484
01:09:23,780 --> 01:09:29,690
高斯分布

1485
01:09:29,770 --> 01:09:35,440
均值向量是这个向量

1486
01:09:35,550 --> 01:09:37,350
也就是我们之前

1487
01:09:37,450 --> 01:09:40,500
求出的

1488
01:09:40,580 --> 01:09:41,620
μ_zx

1489
01:09:41,710 --> 01:09:43,260
协方差矩阵是这个矩阵

1490
01:09:43,400 --> 01:10:06,010
原则上

1491
01:10:06,110 --> 01:10:09,100
我们的模型的参数

1492
01:10:09,150 --> 01:10:10,610
是μ  Λ和Ψ

1493
01:10:10,690 --> 01:10:16,370
为了求出

1494
01:10:16,460 --> 01:10:17,880
这些参数

1495
01:10:17,990 --> 01:10:19,770
对于一个给定的

1496
01:10:19,910 --> 01:10:21,210
训练集合

1497
01:10:21,300 --> 01:10:25,860
我们可以进行大量的

1498
01:10:25,950 --> 01:10:27,470
极大似然估计

1499
01:10:27,570 --> 01:10:30,350
原则上

1500
01:10:30,430 --> 01:10:31,740
你可以

1501
01:10:31,840 --> 01:10:36,490
写出P(x^((i) ))

1502
01:10:36,580 --> 01:10:41,840
它应该

1503
01:10:41,980 --> 01:10:44,380
服从x的概率分布

1504
01:10:44,410 --> 01:10:45,410
如果

1505
01:10:45,520 --> 01:10:48,110
你求高斯分布的边际分布

1506
01:10:48,300 --> 01:10:50,800
你可以求出x的分布

1507
01:10:50,900 --> 01:10:52,350
x是下面的

1508
01:10:52,450 --> 01:10:53,870
这部分向量

1509
01:10:53,980 --> 01:10:59,710
所以它应该满足

1510
01:10:59,800 --> 01:11:01,250
这样的高斯分布

1511
01:11:01,340 --> 01:11:03,770
对吗?

1512
01:11:03,860 --> 01:11:06,050
这就是我们对P(x)

1513
01:11:06,110 --> 01:11:09,650
的概率分布进行的建模

1514
01:11:09,730 --> 01:11:14,070
原则上

1515
01:11:14,170 --> 01:11:15,380
你可以写出

1516
01:11:15,460 --> 01:11:19,270
参数的对数似然性

1517
01:11:19,320 --> 01:11:20,520
对吗?

1518
01:11:20,570 --> 01:11:22,520
它应该等于这个式子

1519
01:11:22,580 --> 01:11:25,900
这里P(x^((i) ))

1520
01:11:26,000 --> 01:11:31,340
P(x^((i) ))

1521
01:11:31,410 --> 01:11:35,200
是高斯密度函数

1522
01:11:35,270 --> 01:11:37,800
我用θ简略地

1523
01:11:37,890 --> 01:11:39,010
表示所有的参数

1524
01:11:39,090 --> 01:11:41,340
你已经知道了

1525
01:11:41,410 --> 01:11:42,720
高斯概率密度函数

1526
01:11:42,800 --> 01:11:47,340
这个

1527
01:11:47,410 --> 01:11:48,480
高斯分布

1528
01:11:48,540 --> 01:11:50,080
表示成

1529
01:11:50,160 --> 01:11:51,530
这个式子

1530
01:11:51,580 --> 01:11:53,430
如果你写出了

1531
01:11:53,510 --> 01:11:55,240
参数的对数似然性

1532
01:11:55,330 --> 01:11:58,210
你就可以

1533
01:11:58,280 --> 01:11:59,730
相对于参数求导

1534
01:11:59,820 --> 01:12:00,800
并求解使得

1535
01:12:00,860 --> 01:12:02,720
对数似然性

1536
01:12:02,860 --> 01:12:04,990
最大化

1537
01:12:05,070 --> 01:12:06,270
如果你这样做的话

1538
01:12:06,330 --> 01:12:08,750
你会得到一个

1539
01:12:09,070 --> 01:12:09,660
很难解的问题

1540
01:12:23,610 --> 01:12:25,020
无法找到

1541
01:12:25,100 --> 01:12:27,210
解析形式

1542
01:12:27,280 --> 01:12:28,240
的解

1543
01:12:28,320 --> 01:12:31,740
所以我们要做的

1544
01:12:31,790 --> 01:12:33,070
是

1545
01:12:33,170 --> 01:12:44,260
为了拟合出

1546
01:12:44,360 --> 01:12:45,340
模型的参数

1547
01:12:45,440 --> 01:12:47,710
我们需要使用EM算法

1548
01:12:47,820 --> 01:13:00,080
在E-step

1549
01:13:00,170 --> 01:13:07,370
我们需要计算这个式子

1550
01:13:07,410 --> 01:13:12,700
这个式子看起来

1551
01:13:12,790 --> 01:13:15,320
和之前的形式差不多

1552
01:13:15,430 --> 01:13:16,470
除了现在z是一个连续的随机变量

1553
01:13:16,590 --> 01:13:20,780
所以在E-step

1554
01:13:20,840 --> 01:13:22,540
我们需要求出

1555
01:13:22,610 --> 01:13:23,610
概率密度Q(z^((i) ) )

1556
01:13:23,720 --> 01:13:24,950
在E-step

1557
01:13:25,030 --> 01:13:27,550
我们需要求出后验概率

1558
01:13:27,610 --> 01:13:30,830
也就是变量z^((i) )的

1559
01:13:30,890 --> 01:13:34,510
概率密度

1560
01:13:34,580 --> 01:13:35,500
在M-step

1561
01:13:35,600 --> 01:13:38,580
我们需要求解

1562
01:13:38,650 --> 01:13:42,540
这个最优化问题

1563
01:13:42,630 --> 01:13:45,530
因为现在z是连续变量

1564
01:13:45,590 --> 01:13:59,280
所以我们现在需要对z求积分

1565
01:13:59,400 --> 01:14:00,310
在M-step

1566
01:14:00,400 --> 01:14:01,710
由于z^((i) )是连续变量

1567
01:14:01,870 --> 01:14:02,880
所以我们需要对z^((i) )求积分

1568
01:14:02,950 --> 01:14:03,840
而不是求和

1569
01:14:03,930 --> 01:14:04,750
明白吗?

1570
01:14:04,810 --> 01:14:06,240
关于推导过程我希望

1571
01:14:06,340 --> 01:14:08,130
讲的更详细一些

1572
01:14:08,170 --> 01:14:09,100
但是今天没有时间了

1573
01:14:09,150 --> 01:14:10,270
我们下次课会

1574
01:14:10,320 --> 01:14:12,560
讲完这部分内容

1575
01:14:12,630 --> 01:14:13,890
结束之前

1576
01:14:14,010 --> 01:14:14,710
关于因子分析模型

1577
01:14:14,800 --> 01:14:17,380
你们还有什么问题吗?

1578
01:14:17,500 --> 01:14:26,490
好的

1579
01:14:26,600 --> 01:14:29,320
我们下次课

1580
01:14:29,420 --> 01:14:30,250
会讲完这部分内容

1581
01:14:30,390 --> 01:14:32,570
我会深入地

1582
01:14:32,660 --> 01:14:34,410
讲解一下

1583
01:14:34,470 --> 01:14:35,550
E-step和M-step

1584
01:14:35,630 --> 01:14:37,250
因为对于因子分析模型来说

1585
01:14:37,320 --> 01:14:38,020
这两部分有一些

1586
01:14:38,090 --> 01:14:39,610
有趣的内容

1587
01:14:39,700 --> 01:14:41,520
几天后见

