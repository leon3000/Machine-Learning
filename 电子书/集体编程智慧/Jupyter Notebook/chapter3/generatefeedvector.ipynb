{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to parse feed http://battellemedia.com/index.xml\n",
      "\n",
      "Failed to parse feed http://blog.guykawasaki.com/index.rdf\n",
      "\n",
      "Failed to parse feed http://feeds.searchenginewatch.com/sewblog\n",
      "\n",
      "Failed to parse feed http://blog.topix.net/index.rdf\n",
      "\n",
      "Failed to parse feed http://blogs.abcnews.com/theblotter/index.rdf\n",
      "\n",
      "Failed to parse feed http://feeds.feedburner.com/ConsumingExperienceFull\n",
      "\n",
      "Failed to parse feed http://flagrantdisregard.com/index.php/feed/\n",
      "\n",
      "Failed to parse feed http://featured.gigaom.com/feed/\n",
      "\n",
      "Failed to parse feed http://gizmodo.com/index.xml\n",
      "\n",
      "Failed to parse feed http://feeds.feedburner.com/instapundit/main\n",
      "\n",
      "Failed to parse feed http://jeremy.zawodny.com/blog/rss2.xml\n",
      "\n",
      "Failed to parse feed http://michellemalkin.com/index.rdf\n",
      "\n",
      "Failed to parse feed http://beta.blogger.com/feeds/27154654/posts/full?alt=rss\n",
      "\n",
      "Failed to parse feed http://powerlineblog.com/index.rdf\n",
      "\n",
      "Failed to parse feed http://feeds.feedburner.com/Publishing20\n",
      "\n",
      "Failed to parse feed http://scienceblogs.com/pharyngula/index.xml\n",
      "\n",
      "Failed to parse feed http://www.bloglines.com/rss/about/news\n",
      "\n",
      "Failed to parse feed http://www.buzzmachine.com/index.xml\n",
      "\n",
      "Failed to parse feed http://www.coolhunting.com/index.rdf\n",
      "\n",
      "Failed to parse feed http://www.downloadsquad.com/rss.xml\n",
      "\n",
      "Failed to parse feed http://www.gapingvoid.com/index.rdf\n",
      "\n",
      "Failed to parse feed http://www.gawker.com/index.xml\n",
      "\n",
      "Failed to parse feed http://www.joystiq.com/rss.xml\n",
      "\n",
      "Failed to parse feed http://littlegreenfootballs.com/weblog/lgf-rss.php\n",
      "\n",
      "Failed to parse feed http://www.makezine.com/blog/index.xml\n",
      "\n",
      "Failed to parse feed http://xml.metafilter.com/rss.xml\n",
      "\n",
      "Failed to parse feed http://www.micropersuasion.com/index.rdf\n",
      "\n",
      "Failed to parse feed http://www.readwriteweb.com/rss.xml\n",
      "\n",
      "Failed to parse feed http://scienceblogs.com/sample/combined.xml\n",
      "\n",
      "Failed to parse feed http://www.shoemoney.com/feed/\n",
      "\n",
      "Failed to parse feed http://www.sifry.com/alerts/index.rdf\n",
      "\n",
      "Failed to parse feed http://www.simplebits.com/xml/rss.xml\n",
      "\n",
      "Failed to parse feed http://www.talkingpointsmemo.com/index.xml\n",
      "\n",
      "Failed to parse feed http://www.techeblog.com/index.php/feed/\n",
      "\n",
      "Failed to parse feed http://www.thesuperficial.com/index.xml\n",
      "\n",
      "Failed to parse feed http://www.treehugger.com/index.rdf\n",
      "\n",
      "Failed to parse feed http://www.valleywag.com/index.xml\n",
      "\n",
      "Failed to parse feed http://www.we-make-money-not-art.com/index.rdf\n",
      "\n",
      "Failed to parse feed http://www.wonkette.com/index.xml\n",
      "\n",
      "Schneier on Security\n",
      "PaulStamatiou.com - Technology, Design and Photography\n",
      "Search Engine Roundtable\n",
      "Copyblogger\n",
      "Joi Ito's Web\n",
      "Engadget RSS Feed\n",
      "NewsBusters\n",
      "ProBlogger\n",
      "Steve Pavlina\n",
      "mezzoblue\n",
      "Eschaton\n",
      "Slashdot\n",
      "Matt Cutts: Gadgets, Google, and SEO\n",
      "Gothamist\n",
      "Techdirt.\n",
      "PerezHilton\n",
      "Joho the Blog\n",
      "ongoing by Tim Bray\n",
      "The Viral Garden\n",
      "SpikedHumor - Today's Videos and Pictures\n",
      "The Official Google Blog\n",
      "Neil Gaiman's Journal\n",
      "Signal v. Noise - Medium\n",
      "456 Berea Street\n",
      "Joel on Software\n",
      "Boing Boing\n",
      "The Full Feed from HuffingtonPost.com\n",
      "Wired\n",
      "WIL WHEATON dot NET\n",
      "Latest from Crooks and Liars\n",
      "Creating Passionate Users\n",
      "Kotaku\n",
      "The Write News\n",
      "Scobleizer\n",
      "Derek Powazek\n",
      "Captain's Quarters\n",
      "ThinkProgress\n",
      "blog maverick\n",
      "plasticbag.org\n",
      "43 Folders\n",
      "Autoblog\n",
      "Daily Kos\n",
      "Google Blogoscoped\n",
      "Deadspin\n",
      "The Dish\n",
      "kottke.org\n",
      "O'Reilly Radar\n",
      "Lifehack\n",
      "Lifehacker\n",
      "Google Operating System\n",
      "Celebslam\n",
      "Mashable\n",
      "TechCrunch\n",
      "Quick Online Tips\n",
      "Oilman\n",
      "TMZ.com\n",
      "Seth Godin's Blog on marketing, tribes and respect\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "import re\n",
    "\n",
    "# Returns title and dictionary of word counts for an RSS feed\n",
    "def getwordcounts(url):\n",
    "  # Parse the feed\n",
    "  d=feedparser.parse(url)\n",
    "  wc={}\n",
    "\n",
    "  # Loop over all the entries\n",
    "  for e in d.entries:\n",
    "    if 'summary' in e: summary=e.summary\n",
    "    else: summary=e.description\n",
    "\n",
    "    # Extract a list of words\n",
    "    words=getwords(e.title+' '+summary)\n",
    "    for word in words:\n",
    "      wc.setdefault(word,0)\n",
    "      wc[word]+=1\n",
    "  return d.feed.title,wc\n",
    "\n",
    "def getwords(html):\n",
    "  # Remove all the HTML tags\n",
    "  txt=re.compile(r'<[^>]+>').sub('',html)\n",
    "\n",
    "  # Split words by all non-alpha characters\n",
    "  words=re.compile(r'[^A-Z^a-z]+').split(txt)\n",
    "\n",
    "  # Convert to lowercase\n",
    "  return [word.lower() for word in words if word!='']\n",
    "\n",
    "\n",
    "apcount={}\n",
    "wordcounts={}\n",
    "feedlist=[line for line in file('feedlist.txt')]\n",
    "for feedurl in feedlist:\n",
    "  try:\n",
    "    title,wc=getwordcounts(feedurl)\n",
    "    wordcounts[title]=wc\n",
    "    for word,count in wc.items():\n",
    "      apcount.setdefault(word,0)\n",
    "      if count>1:\n",
    "        apcount[word]+=1\n",
    "  except:\n",
    "    print 'Failed to parse feed %s' % feedurl\n",
    "\n",
    "wordlist=[]\n",
    "for w,bc in apcount.items():\n",
    "  frac=float(bc)/len(feedlist)\n",
    "  if frac>0.1 and frac<0.5:\n",
    "    wordlist.append(w)\n",
    "\n",
    "out=file('blogdata1.txt','w')\n",
    "out.write('Blog')\n",
    "for word in wordlist: out.write('\\t%s' % word)\n",
    "out.write('\\n')\n",
    "for blog,wc in wordcounts.items():\n",
    "  print blog\n",
    "  out.write(blog)\n",
    "  for word in wordlist:\n",
    "    if word in wc: out.write('\\t%d' % wc[word])\n",
    "    else: out.write('\\t0')\n",
    "  out.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
